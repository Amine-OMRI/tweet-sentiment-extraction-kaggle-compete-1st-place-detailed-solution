{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "roberta_base.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BmUw-vAr6c_6",
        "Jro8AaTYD78D",
        "gtM5UFGcEAxb",
        "-_Q6Y5KPFUGh",
        "etmylaX2Fb-j",
        "BrP6RBNKFqd9",
        "ZUTPKlGDGpj8",
        "sPit1dlVHEIs",
        "QDzmFycLG6Rc"
      ],
      "mount_file_id": "1DSDVX5Zs9k8YqjQf2e-7iBNrkk0J43x2",
      "authorship_tag": "ABX9TyNHAWTEjuDp9/ir43LjPiJW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a5a6a4853c647d5ab4e6f2e421c5b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea33407f48d84529a3cedce8ff4eb717",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86e84d68c27d472b8a7a0d57a6e22c43",
              "IPY_MODEL_a042d53d0d374fbba87c5126bc89edb1"
            ]
          }
        },
        "ea33407f48d84529a3cedce8ff4eb717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86e84d68c27d472b8a7a0d57a6e22c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb2ad4da78f8468f8b5e0bacdfdb6a44",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67b4d3d78dee4cc39c7679217f24bca9"
          }
        },
        "a042d53d0d374fbba87c5126bc89edb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7174c2b850b4684b80adf245f073187",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:49&lt;00:00, 11.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b40d221cc11e42abacb6d79d87b64e15"
          }
        },
        "fb2ad4da78f8468f8b5e0bacdfdb6a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67b4d3d78dee4cc39c7679217f24bca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7174c2b850b4684b80adf245f073187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b40d221cc11e42abacb6d79d87b64e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da3165f8a7bb4f1ba6002a3dd1839b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad49480862ce44e696e8ab8d60f4850c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd76536cf49f4f9e9dcca7b8c6c9c804",
              "IPY_MODEL_97fb8388273247cea7095fce3ccd4789"
            ]
          }
        },
        "ad49480862ce44e696e8ab8d60f4850c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd76536cf49f4f9e9dcca7b8c6c9c804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fdf7552d81344c6b23bbd1e82f34b80",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 496313727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 496313727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6991e98fa56846f98fdf918568cafd89"
          }
        },
        "97fb8388273247cea7095fce3ccd4789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79c265a4eeda434db25543b711583219",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 496M/496M [00:11&lt;00:00, 44.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5c53ebd65b84df79429c42c41a456f0"
          }
        },
        "2fdf7552d81344c6b23bbd1e82f34b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6991e98fa56846f98fdf918568cafd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79c265a4eeda434db25543b711583219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5c53ebd65b84df79429c42c41a456f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "311e02e4ab79455f96a6a69d882cf44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fbea1556436405c82e84a37e15ee0c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be8768226ed74c338a38576cc1639b61",
              "IPY_MODEL_f195b12fa5be48fca00f7c2056222609"
            ]
          }
        },
        "8fbea1556436405c82e84a37e15ee0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be8768226ed74c338a38576cc1639b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d40ab0eeaee6478aa0eec0bc7a5d883f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f1b9d41b21047ec94130b11e14337d6"
          }
        },
        "f195b12fa5be48fca00f7c2056222609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e0c96ecb90475a9767aa517b1ff34d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [01:13&lt;00:00,  2.33it/s, jaccard=0.716]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83643d9c675e43d0adf21bb7e7bb4bd2"
          }
        },
        "d40ab0eeaee6478aa0eec0bc7a5d883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f1b9d41b21047ec94130b11e14337d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e0c96ecb90475a9767aa517b1ff34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83643d9c675e43d0adf21bb7e7bb4bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e67e719ed34a4b07a0591d376313ceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19299dbe1cb457fb61a2bd60a044123",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2037ef67ba3407e9883a32f1a9ae9e9",
              "IPY_MODEL_ef8f28882f6a4689ac35c8b7dc69dc8a"
            ]
          }
        },
        "a19299dbe1cb457fb61a2bd60a044123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2037ef67ba3407e9883a32f1a9ae9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80baee64c83f4c05b13026fdd6c3928f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95fe9696a2b74d7ea8c85a71ed0ea401"
          }
        },
        "ef8f28882f6a4689ac35c8b7dc69dc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1dd0410fc9704a9caa064a47ee8936bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [00:29&lt;00:00,  5.74it/s, jaccard=0.711]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba08cfa1331d47489b03c860ed273728"
          }
        },
        "80baee64c83f4c05b13026fdd6c3928f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95fe9696a2b74d7ea8c85a71ed0ea401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dd0410fc9704a9caa064a47ee8936bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba08cfa1331d47489b03c860ed273728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c649b48206e8461ab986a31eff41663d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de48ecab2e9a43a2984091f852f12b25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9ccaad734f8466f9c609ba4c19ae320",
              "IPY_MODEL_79deeeeeaa964a06bc9f3ad5462ca312"
            ]
          }
        },
        "de48ecab2e9a43a2984091f852f12b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9ccaad734f8466f9c609ba4c19ae320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1790d4b810e6479fb0986a33c7d6d89d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e0abbd9b372444a9ecb25a616239688"
          }
        },
        "79deeeeeaa964a06bc9f3ad5462ca312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8388209c0eea421a864e786bf0e88db2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [01:10&lt;00:00,  2.42it/s, jaccard=0.716]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e28785f8a2c4d26b9dedb98f993c35c"
          }
        },
        "1790d4b810e6479fb0986a33c7d6d89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e0abbd9b372444a9ecb25a616239688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8388209c0eea421a864e786bf0e88db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e28785f8a2c4d26b9dedb98f993c35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ae593eea4ea4bf29ccb9207bf39a987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a8fc24b90b944d1ba355ecbb00bfa58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc414fdaee294c9db8c677b27a81707f",
              "IPY_MODEL_b53ea0fc5b7e42f6961cc98b3b257128"
            ]
          }
        },
        "0a8fc24b90b944d1ba355ecbb00bfa58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc414fdaee294c9db8c677b27a81707f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f73581c6f304a2381a54c3aded4fb52",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad0874d836e3493cb84f49eb88448e72"
          }
        },
        "b53ea0fc5b7e42f6961cc98b3b257128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86d93fca9e4a417187f9512e505ccf8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [00:29&lt;00:00,  5.74it/s, jaccard=0.717]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c571a2eff364548b85ad2d1a1ccc4cd"
          }
        },
        "9f73581c6f304a2381a54c3aded4fb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad0874d836e3493cb84f49eb88448e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d93fca9e4a417187f9512e505ccf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c571a2eff364548b85ad2d1a1ccc4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e34c097bd1a8400cab7a702b06a9143c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1eb203e1db144517ae6bf803be68d76b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c555a66b7f44451e82c325428f234bc4",
              "IPY_MODEL_5ac0aaff737641eca49308824bb94603"
            ]
          }
        },
        "1eb203e1db144517ae6bf803be68d76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c555a66b7f44451e82c325428f234bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec1aa1825834a7c96fddcafac8ee72b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae9af73a41084fc2bbf736f4afd9f5dd"
          }
        },
        "5ac0aaff737641eca49308824bb94603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24ea29ea46fe45f5876e16e9bbc5daca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [29:37&lt;00:00, 10.33s/it, jaccard=0.711]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_806bf2cfe63e4b909522ad2c6b6f6d8c"
          }
        },
        "1ec1aa1825834a7c96fddcafac8ee72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae9af73a41084fc2bbf736f4afd9f5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ea29ea46fe45f5876e16e9bbc5daca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "806bf2cfe63e4b909522ad2c6b6f6d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1023bec17f3048f2994587ab2ca923ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f836dfd3d614d37a6e12828b9e26dea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0288fee9c3674c198d5e21621aac5273",
              "IPY_MODEL_56eabcc0b14d4fa6a0b5b2323b3a27a5"
            ]
          }
        },
        "4f836dfd3d614d37a6e12828b9e26dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0288fee9c3674c198d5e21621aac5273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c97ceae839b48029d9f89ed8021d1a2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0732c192a784c53b86a68f3a16254a6"
          }
        },
        "56eabcc0b14d4fa6a0b5b2323b3a27a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_556a4510c3234b38a87c3743b8df9c97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:08&lt;00:00, 69.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec4bd0f01be341e88fc41673825fbaca"
          }
        },
        "9c97ceae839b48029d9f89ed8021d1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0732c192a784c53b86a68f3a16254a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "556a4510c3234b38a87c3743b8df9c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec4bd0f01be341e88fc41673825fbaca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d6a2ea3e1454d28bd5a9760e19a4ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cad7320919248cab53cba7a3eb47225",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18287140c5324a7e85b01460e5e889f5",
              "IPY_MODEL_fb4870326d1545dcaab261730965bc99"
            ]
          }
        },
        "6cad7320919248cab53cba7a3eb47225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18287140c5324a7e85b01460e5e889f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11cd33748ed9445c921d533c922a2128",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 496313727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 496313727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ae80b3c967142b1b773b080ed310264"
          }
        },
        "fb4870326d1545dcaab261730965bc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31bf737378c04156a4ced60a3b781572",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 496M/496M [00:07&lt;00:00, 62.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8344b11a1c42484883bb312ebfa677c6"
          }
        },
        "11cd33748ed9445c921d533c922a2128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ae80b3c967142b1b773b080ed310264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31bf737378c04156a4ced60a3b781572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8344b11a1c42484883bb312ebfa677c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/roberta_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOeAFVsEAUTq"
      },
      "source": [
        "La solution a Ã©tÃ© implÃ©mentÃ©e en utilisant une version antÃ©rieure des bibliothÃ¨ques \n",
        "\n",
        "1.   tokenizers==0.7.0\n",
        "2.   transformers==2.9.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mk0dtujy2tO"
      },
      "source": [
        "!pip install tokenizers==0.7.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N29Szb61GEts"
      },
      "source": [
        "!pip install transformers==2.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfeg6bkPHNbj"
      },
      "source": [
        "!pip install torchcontrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Cxkuo8DM_r"
      },
      "source": [
        "[torchcontrib](https://github.com/pytorch/contrib) librairie contient des implÃ©mentations d'idÃ©es issues de rÃ©cents articles sur l'apprentissage machine, ici elle a Ã©tÃ© utilisÃ©e pour rÃ©aliser #Stochastic Weight Averaging (SWA) Que je vous prÃ©senteai ultÃ©rieurement dans le Notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVg2eB1FOZqE",
        "outputId": "22c9ba39-d7bf-4264-a2e6-a2f2cde79b43"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmUw-vAr6c_6"
      },
      "source": [
        "#Pour Commencer\n",
        "**Ce notebook reprÃ©sente l'un des modÃ¨les de premier niveau rÃ©alisÃ© par [Heartkilla](https://www.kaggle.com/aruchomu) : Artsem Zhyvalkouski le code source est sous `src/1st_level/roberta_base/` sur le [repo git](https://github.com/heartkilla/kaggle_tweet/tree/master/src/1st_level/roberta_base) oÃ¹ ils ont mis le code de leur solution**\n",
        "\n",
        "---\n",
        "Pour faire tourner la solution de la compÃ©tition, j'ai chargÃ© quelques fichiers sur mon Gdrive qui sont : \n",
        "\n",
        "\n",
        "*   Les fichiers de donnÃ©es :</br>\n",
        "    TRAINING_FILE = /content/drive/MyDrive/very_final/data/**train_folds.csv**</br>\n",
        "    TEST_FILE = /content/drive/MyDrive/very_final/data/**test.csv**</br>\n",
        " \n",
        "\n",
        "*   Les fichiers de configuration du tokeniser :</br>\n",
        "\n",
        "    /content/drive/MyDrive/very_final/roberta_tokenizer/**vocab.json**</br>\n",
        "    /content/drive/MyDrive/very_final/roberta_tokenizer/**merges.txt**</br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyIIjztjWy5O"
      },
      "source": [
        "J'ai Ã©galement transfÃ©rÃ© les fichiers de **code** directement sur **Colab** en tant que fichiers d'entrÃ©e afin de pouvoir les importer et les utiliser, en mÃªme temps que j'ai copiÃ© leur code afin de pouvoir le commenter et remplir l'objectif de travail demandÃ©.\n",
        "* config.py\n",
        "* dataset.py\n",
        "* engine.py\n",
        "* evaluate.py\n",
        "* infer.py\n",
        "* models.py\n",
        "* train.py\n",
        "* utils.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jro8AaTYD78D"
      },
      "source": [
        "#config.py\n",
        "\n",
        "---\n",
        "\n",
        "Le fichier **config.py** (configuration) contient les paramÃ¨tres et les rÃ©glages initiaux des modules et des mÃ©thodes de la solution. L'importation du fichier config.py permet d'utiliser les variables et les fonctions du fichier config.py dans les autres fichiers de la solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljAHrlvLDKkS"
      },
      "source": [
        "import tokenizers\n",
        "\n",
        "# Paths\n",
        "\n",
        "TOKENIZER_PATH = '/content/drive/MyDrive/very_final/roberta_tokenizer'\n",
        "TRAINING_FILE = '/content/drive/MyDrive/very_final/data/train_folds.csv'\n",
        "TEST_FILE = '/content/drive/MyDrive/very_final/data/test.csv'\n",
        "SUB_FILE = '/content/drive/MyDrive/very_final/data/sample_submission.csv'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/very_final/roberta_base/model_save'\n",
        "TRAINED_MODEL_PATH = '/content/drive/MyDrive/very_final/roberta_base/model_save'\n",
        "\n",
        "# Model config\n",
        "##    Le tout premier modÃ¨le qui a Ã©tÃ© utilisÃ© dans les modÃ¨les de 1er niveau\n",
        "##    est roberta-base pour le modÃ¨le d'AQ par deepset.ai (Squad pretrained \n",
        "##    weights)) prÃ©-entrainÃ© sur la base SQuAD 2.0\n",
        "MODEL_CONFIG = 'deepset/roberta-base-squad2'\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# Model params\n",
        "# Global Seed to initialize the pseudo-random number generator\n",
        "# Pour assurer d'avoir les memes resultats d'une lancÃ©e a une autre\n",
        "SEED = 25\n",
        "# Nombre des folds pour l'entrainement par fold\n",
        "N_FOLDS = 5\n",
        "# Nombre d'EPOCHS de lentrainment des modÃ©les \n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 4e-5\n",
        "PATIENCE = None\n",
        "EARLY_STOPPING_DELTA = None\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "MAX_LEN = 96  # actually = 86\n",
        "\n",
        "## ExpliquÃ© ci-dessous\n",
        "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file=f'{TOKENIZER_PATH}/vocab.json',\n",
        "    merges_file=f'{TOKENIZER_PATH}/merges.txt',\n",
        "    lowercase=True,\n",
        "    add_prefix_space=True)\n",
        "# 768 est la dimension des Embeddings \n",
        "HIDDEN_SIZE = 768\n",
        "N_LAST_HIDDEN = 12\n",
        "HIGH_DROPOUT = 0.5\n",
        "SOFT_ALPHA = 0.6\n",
        "WARMUP_RATIO = 0.25\n",
        "WEIGHT_DECAY = 0.001\n",
        "#Stochastic Weight Averaging (SWA) :\n",
        "# les paramÃ©tres de l'optimiser \n",
        "USE_SWA = False\n",
        "SWA_RATIO = 0.9\n",
        "SWA_FREQ = 30"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R42twUwALMX7"
      },
      "source": [
        "Source : **huggingface tokenizers**\n",
        "Fournit une implÃ©mentation des tokenizers les plus utilisÃ©s aujourd'hui, en mettant l'accent sur les performances et la polyvalence.\n",
        "UtilisÃ© pour :\n",
        "* EntraÃ®ner de nouveaux vocabulaires et tokeniser Ã  l'aide de 4 tokenizers pre-made (Bert WordPiece et les 3 versions les plus courantes de BPE).\n",
        "* ExtrÃªmement rapide (tant pour l'entraÃ®nement que pour la tokenisation), grÃ¢ce Ã  l'implÃ©mentation de Rust. Il le faut moins de 20 secondes pour convertir un Go de texte en tokens sur le processeur d'un serveur.\n",
        "* Facile Ã  utiliser, mais aussi extrÃªmement polyvalent.\n",
        "* ConÃ§u pour la recherche et la production.\n",
        "* La normalisation s'accompagne d'un suivi des alignements. Il est toujours possible d'obtenir la partie de la phrase originale qui correspond Ã  un jeton donnÃ©.\n",
        "* Effectue tout le prÃ©traitement : Tronquer, Pad, ajouter les tokens spÃ©ciaux dont votre modÃ¨le a besoin.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lulkLxMkWKEh"
      },
      "source": [
        "\n",
        "Le tokenizer de RoBERTa est basÃ© sur le tokenizer GPT-2, les fichiers vocab/merges sont constituÃ©s lors de l'entrainement du BBPE [(Byte-level Byte-Pair-Encoding)](https://arxiv.org/pdf/1909.03341.pdf) et utilisÃ©s pour encoder les sentences, le tokenizer tokenize d'abord en se basant sur le fichier **merges.txt**.</br>\n",
        "\n",
        "Voici un exemple :</br>\n",
        "\n",
        "```\n",
        "['What', \"'s\", 'Ä up', 'Ä with', 'Ä the', 'Ä token', 'izer', '?']</br>\n",
        "\n",
        "```\n",
        "le caractÃ¨re ```Ä ``` signifie un espace</br>\n",
        "\n",
        "\n",
        "Et ensuite, selon les valeurs dans le fichier **vocab.json**, ces tokens sont alors remplacÃ©s par leurs indices :</br>\n",
        "```\n",
        "[   'What',     \"'s\",    'Ä up',  'Ä with',   'Ä the', 'Ä token',   'izer',      '?']\n",
        "---- becomes ----\n",
        "[     2061,      338,      510,      351,      262,    11241,     7509,       30]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtM5UFGcEAxb"
      },
      "source": [
        "#dataset.py\n",
        "\n",
        "---\n",
        "le fichier dataset.py pour assurer que toutes les donnÃ©es des tweets soient stockÃ©es au mÃªme endroit et soient utilisÃ©es pour charger les donnÃ©es avec le **dataloader** par la suite.\n",
        "\n",
        "* Il contient Ã©galement une implÃ©mentation d'un  Map-style datasets (the **TweetDataset** class)  qui implÃ©mente les mÃ©thodes **__getitem__()** et **__len__()** et qui reprÃ©sente toutes les propriÃ©tÃ©s des ids des tweets, les offsets, orig_start/orig_end, start_labels/end_labels, mask, token_type_ids, ...\n",
        "\n",
        "* Egalement une implÃ©mentation de la mÃ©thode **process_data** qui traitera qui calculera toutes ces propriÃ©tÃ©s et les extraira des tweets, selected_text, sentiment en utilisant le tokeniser crÃ©e dans le fichier config.py.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocl0o4iYUoaa"
      },
      "source": [
        "Voyons voir a quoi ressemblent les donnÃ©es d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "AAihgxQaUp0e",
        "outputId": "eb61e663-da7a-406a-909f-5c94fb0c916e"
      },
      "source": [
        "import config\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(config.TRAINING_FILE)\n",
        "df_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d0c214ad3a</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7d093817af</td>\n",
              "      <td>LOL. You know me. I aim to please.</td>\n",
              "      <td>I aim to please.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21eacf7e58</td>\n",
              "      <td>Was at Ruby Skye last night as well! Superb s...</td>\n",
              "      <td>Superb set by Steve.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d0f94d66ab</td>\n",
              "      <td>does not like ups much today...</td>\n",
              "      <td>does not like</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a025e21634</td>\n",
              "      <td>Nothing like In `n` Out and a LOST marathon af...</td>\n",
              "      <td>long day of work.</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... kfold\n",
              "0  d0c214ad3a  ...     0\n",
              "1  7d093817af  ...     0\n",
              "2  21eacf7e58  ...     0\n",
              "3  d0f94d66ab  ...     0\n",
              "4  a025e21634  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvUeziUUXrR6"
      },
      "source": [
        "**===>  `selected_text` est la valeur Ã  prÃ©dire**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3zseDwveZ9Z",
        "outputId": "84298617-2a5f-48d1-a42b-6ce7f9377ec8"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27480, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aArwkeaidCEs",
        "outputId": "4f13af67-6240-40b5-b497-ae06af659663"
      },
      "source": [
        "tweet = df_train.text.values[3]\n",
        "selected_text = df_train.selected_text[3]\n",
        "tweet = ' ' + ' '.join(str(tweet).split())\n",
        "selected_text = ' ' + ' '.join(str(selected_text).split())\n",
        "tweet"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like ups much today...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lurbGoDRlWTg",
        "outputId": "7f6bb480-2097-48ca-8fdc-c1fe83bf9407"
      },
      "source": [
        "selected_text "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhAPoBb1eJ4_",
        "outputId": "cbb34778-1d64-4845-8e36-979da150c475"
      },
      "source": [
        "len_sel_text = len(selected_text) - 1\n",
        "## rÃ©cpÃ¨rerl'idice de dÃ©but et de fin de selected_text\n",
        "idx_0 = None\n",
        "idx_1 = None\n",
        "## i : indice du caractÃ©re, e c'est le caractÃ©re SI e est le caractÃ©re \n",
        "## d'indice 1 (just aprÃ© lespace quona rajoutÃ©)\n",
        "for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
        "  if ' ' + tweet[ind:ind + len_sel_text] == selected_text:\n",
        "    idx_0 = ind\n",
        "    idx_1 = ind + len_sel_text - 1\n",
        "    break\n",
        "print('l\\'indexe de dÃ©but:',idx_0,'l\\'indexe de fin:', idx_1, 'du text sÃ©lÃ©ctionnÃ© qui reprÃ©sente le target')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l'indexe de dÃ©but: 1 l'indexe de fin: 13 du text sÃ©lÃ©ctionnÃ© qui reprÃ©sente le target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo9w6FBTzzGV"
      },
      "source": [
        "Assigner `1` Ã  chaque caractÃ¨re du tweet s'il fait partie du selected_text sinon `0`, comme dans l'exemple ci-dessus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8TAUopaxQwT",
        "outputId": "f0dabed7-cb5a-4513-ce8a-ee8bbfb80f30"
      },
      "source": [
        "# Assign 1 as target for each char in sel_text\n",
        "char_targets = [0] * len(tweet)\n",
        "if idx_0 is not None and idx_1 is not None:\n",
        "  for ct in range(idx_0, idx_1 + 1):\n",
        "    char_targets[ct] = 1\n",
        "char_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HSAaSoETzWlq",
        "outputId": "ebd72489-f65f-4093-8fdf-0ec31ea1af15"
      },
      "source": [
        "tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like ups much today...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKrcw3qNzELF",
        "outputId": "e10a9096-b7ab-403d-e2d1-cca7754d4b9c"
      },
      "source": [
        "tokenized_tweet = TOKENIZER.encode(tweet)\n",
        "input_ids_original = tokenized_tweet.ids\n",
        "input_ids_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[473, 45, 101, 12744, 203, 452, 734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKtJb3Hk0t4F"
      },
      "source": [
        "Une **nouvelle mÃ©thode** pour les tokenizers : **tokenize_with_offsets**. En plus de renvoyer les tokens, elle renvoie les intervalles dans le texte original auxquels les tokens correspondent, cette mÃ©thode nous permet de rÃ©cupÃ©rer le token ou le mot qui correspond a un **id** donnÃ©."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIrwQTaSztnP",
        "outputId": "7a9b3be8-2445-46a2-d911-98a18ebd4b8f"
      },
      "source": [
        "tweet_offsets = tokenized_tweet.offsets\n",
        "tweet_offsets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 5), (5, 9), (9, 14), (14, 18), (18, 23), (23, 29), (29, 32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nI3hgd0PAB"
      },
      "source": [
        "RÃ©cupÃ©rer le texte (les tokens) original en se basant sur les offsets (leur intervalle) : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ar3yFd101EBi",
        "outputId": "c73b8326-e154-43d3-d3c3-b3da9fa0e523"
      },
      "source": [
        "tweet[tweet_offsets[0][0]:tweet_offsets[0][1]] + tweet[tweet_offsets[1][0]:tweet_offsets[1][1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjfwO6vQ45Pj"
      },
      "source": [
        "Ce code rÃ©cupÃ¨re les **target_ids** qui sont les id des tokens cibles qui reprÃ©sentent le texte sÃ©lectionnÃ© (chaque caractÃ¨re est reprÃ©sentÃ© (codÃ©) par le chiffre `\"1\"`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUOFWQ1k1GWR",
        "outputId": "b8f8ad02-1c95-4063-fdef-cd20e2c392e0"
      },
      "source": [
        "target_ids = []\n",
        "for i, (offset_0, offset_1) in enumerate(tweet_offsets):\n",
        "  print(i,'offset (',offset_0,',', offset_1,')')\n",
        "  print(char_targets[offset_0:offset_1])\n",
        "  print(sum(char_targets[offset_0:offset_1]))\n",
        "  if sum(char_targets[offset_0:offset_1]) > 0:\n",
        "    target_ids.append(i)\n",
        "print('target_ids : ',target_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 offset ( 0 , 5 )\n",
            "[0, 1, 1, 1, 1]\n",
            "4\n",
            "1 offset ( 5 , 9 )\n",
            "[1, 1, 1, 1]\n",
            "4\n",
            "2 offset ( 9 , 14 )\n",
            "[1, 1, 1, 1, 1]\n",
            "5\n",
            "3 offset ( 14 , 18 )\n",
            "[0, 0, 0, 0]\n",
            "0\n",
            "4 offset ( 18 , 23 )\n",
            "[0, 0, 0, 0, 0]\n",
            "0\n",
            "5 offset ( 23 , 29 )\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "0\n",
            "6 offset ( 29 , 32 )\n",
            "[0, 0, 0]\n",
            "0\n",
            "target_ids :  [0, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmpceIfOAIwz"
      },
      "source": [
        "* **Soft Jaccard labels :**</br>\n",
        "Custom loss Jaccard-based Soft Labels: Ã‰tant donnÃ© que la Cross Entropy n'optimise pas directement l'indice de Jaccard, Heartkilla a essayÃ© diffÃ©rentes fonctions de Loss pour pÃ©naliser davantage les prÃ©dictions lointaines que les prÃ©dictions proches, il a donc trouvÃ© une Loss personnalisÃ©e en calculant l'indice de Jaccard au niveau du token. Il a ensuite utilisÃ© ces nouveaux labels cibles et a optimisÃ© la divergence.</br> \n",
        "Alpha c'est un paramÃ¨tre permettant d'Ã©quilibrer l'Ã©tiquetage habituel basÃ© sur la Cross Entropy et l'indice de Jaccard </br>\n",
        "<img src = 'https://camo.githubusercontent.com/3925753ce615ec71960dad457401aedefc7b611a2b11a3cb86eb060772dce880/68747470733a2f2f7777772e676f6f676c65617069732e636f6d2f646f776e6c6f61642f73746f726167652f76312f622f6b6167676c652d757365722d636f6e74656e742f6f2f696e626f7825324632303030353435253246393334316265646532383236336263663065396262323539616337393033333825324653637265656e25323053686f74253230323032302d30352d3330253230617425323031372e33312e32322e706e673f67656e65726174696f6e3d3135393234303530323835353638343226616c743d6d65646961'></br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5aOqwjyBi6m"
      },
      "source": [
        "## La mesure d'Ã©valuation qui a Ã©tÃ© mentionnÃ©e sur le prÃ©sent de la competition \n",
        "def jaccard_array(a, b):answer\n",
        "    \"\"\"Calculates Jaccard on arrays.\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHfYQVO51D_"
      },
      "source": [
        "import numpy as np\n",
        "targets_start = target_ids[0]\n",
        "targets_end = target_ids[-1]\n",
        "n = len(input_ids_original)\n",
        "## id des tokens dans le tweet\n",
        "sentence = np.arange(n)\n",
        "## id  des tokens qui forment le label (le selected_text)\n",
        "answer = sentence[targets_start:targets_end + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR-6ZPNr6FmR",
        "outputId": "8b115a18-fc34-40b7-86d4-d2f58d423895"
      },
      "source": [
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecJSNNGiewI"
      },
      "source": [
        "Le tableaux retournÃ© a ce niveau reprÃ©sente les indices du target (text sÃ©lÃ©ctionnÃ©) dans la sentence orginal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBehZdAO6I1s",
        "outputId": "4e45f7d4-3fdf-4955-df4f-ffa42550fe78"
      },
      "source": [
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDUUnvWKjKQb"
      },
      "source": [
        "C'est bien la target selected_text: '` does not like` '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alRiyywnGFXw",
        "outputId": "1367f68c-2af8-4b85-8922-b419c5e21b33"
      },
      "source": [
        "sentence[targets_start:targets_end + 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QKyPhqaB-sl",
        "outputId": "39ae3138-76a2-4e75-90b4-9cd97bc12b27"
      },
      "source": [
        "for i in range(targets_end + 1):\n",
        "  ## calculate the jaccard indexe\n",
        "  ## answer = array([0, 1, 2]) qui est les indice du atrget selected_text: 'does not like'\n",
        "  jac = jaccard_array(answer, sentence[i:targets_end + 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jaccard indexe du token (0,2) =1.0\n",
            "jaccard indexe du token (1,2) =0.6666666666666666\n",
            "jaccard indexe du token (2,2) =0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijAn528-kDk6"
      },
      "source": [
        "jaccard indexe du token (0,2) =1.0 puisque le texte correspondant Ã  l'index de **(0)** jusqu'Ã  la target_end **(2)** dans la phrase originale (`' does not like ups much today...'`) est exactement le taget qui est `'does not like'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtoxHWZvBmY9",
        "outputId": "3b7cc9a6-1ee9-4aff-db1a-3a939984c872"
      },
      "source": [
        "start_labels = np.zeros(n)\n",
        "for i in range(targets_end + 1):\n",
        "    ## calculate the jaccard indexe \n",
        "    jac = jaccard_array(answer, sentence[i:targets_end + 1])\n",
        "    print('jaccard indexe du token ('+ str(i) +','+ str(targets_end)+') ='+ str(jac))\n",
        "    start_labels[i] = jac + jac ** 2\n",
        " \n",
        "## Alpha est un paramÃ¨tre d'Ã©quilibre entre la CE et le Jaccard-based labeling\n",
        "start_labels = (1 - config.SOFT_ALPHA) * start_labels / start_labels.sum()\n",
        "start_labels[targets_start] += config.SOFT_ALPHA\n",
        "start_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "jaccard indexe du token (0,2) =1.0\n",
            "jaccard indexe du token (1,2) =0.6666666666666666\n",
            "jaccard indexe du token (2,2) =0.3333333333333333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.825, 0.125, 0.05 , 0.   , 0.   , 0.   , 0.   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRAPl9oODntS"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import config\n",
        "\n",
        "## La mesure d'Ã©valuation qui a Ã©tÃ© mentionnÃ©e sur le prÃ©sent de la competition \n",
        "def jaccard_array(a, b):\n",
        "    \"\"\"Calculates Jaccard on arrays.\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "\n",
        "def process_data(tweet, selected_text, sentiment,\n",
        "                 tokenizer, max_len):\n",
        "    \"\"\"Preprocesses one data sample and returns a dict\n",
        "    with targets and other useful info.\n",
        "    \"\"\"\n",
        "    ## Pour un tweet donnÃ©:\n",
        "    ## rÃ©cpÃ¨rer le text des tweet sous forme d'une str sÃ©parÃ©e par espace (commence par ' ' dÃ©ja)\n",
        "    tweet = ' ' + ' '.join(str(tweet).split())\n",
        "    ## rÃ©cpÃ¨rer le text des selected_text\n",
        "    selected_text = ' ' + ' '.join(str(selected_text).split())\n",
        "\n",
        "    ## rÃ©cpÃ¨rer le len de selected_text (-1 puisque python commence Ã  partir de 0)\n",
        "    len_sel_text = len(selected_text) - 1\n",
        "\n",
        "    ## rÃ©cpÃ¨rer l'idice de dÃ©but et de fin de selected_text\n",
        "    idx_0 = None\n",
        "    idx_1 = None\n",
        "    ## i : indice du caractÃ©re, e c'est le caractÃ©re SI e est le caractÃ©re \n",
        "    ## d'indice 1 (just aprÃ© lespace qu'ona rajoutÃ© au dÃ©but de selected_text)\n",
        "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
        "        ## rÃ©cupÃ©rer l'idx de dÃ©but et fin du selected_text dans le text du tweet\n",
        "        if ' ' + tweet[ind:ind + len_sel_text] == selected_text:\n",
        "            idx_0 = ind\n",
        "            idx_1 = ind + len_sel_text - 1\n",
        "            break\n",
        "\n",
        "    ## Assignez 1 Ã  chaque caractÃ¨re du tweet s'il fait partie du selected_text\n",
        "    ## sinon 0, comme dans l'exemple ci-dessus.    \n",
        "    char_targets = [0] * len(tweet)\n",
        "    if idx_0 is not None and idx_1 is not None:\n",
        "        for ct in range(idx_0, idx_1 + 1):\n",
        "            char_targets[ct] = 1\n",
        "\n",
        "    ## tokeniser le texte du tweet en utilisant le tokeniser que nous avons \n",
        "    ## crÃ©Ã© sur le fichier config.py\n",
        "    tokenized_tweet = tokenizer.encode(tweet)\n",
        "    ## rÃ©cupÃ©rer les indices affectÃ©s par le tokeniser Ã  chaque jeton\n",
        "    input_ids_original = tokenized_tweet.ids\n",
        "    ## Cette methode \".offsets\" permet de rÃ©cupÃ©rer les intervalles dans le\n",
        "    ## texte original auxquels les tokens correspondent.\n",
        "    tweet_offsets = tokenized_tweet.offsets\n",
        "\n",
        "    ## Ce code rÃ©cupÃ¨re les target_ids qui sont les id des tokens cibles qui\n",
        "    ## reprÃ©sentent le texte sÃ©lectionnÃ© (chaque caractÃ¨re est reprÃ©sentÃ© par 1)\n",
        "    target_ids = []\n",
        "    for i, (offset_0, offset_1) in enumerate(tweet_offsets):\n",
        "        if sum(char_targets[offset_0:offset_1]) > 0:\n",
        "            target_ids.append(i)\n",
        "    ## idx dÃ©but du text du target\n",
        "    targets_start = target_ids[0]\n",
        "    ## idx fin du text du target\n",
        "    targets_end = target_ids[-1]\n",
        "\n",
        "    # Sentimadd_prefix_spaceent 'word' id in vocab\n",
        "    ## Encoder le feature de sentiment\n",
        "    sentiment_id = {'positive': 1313,\n",
        "                    'negative': 2430,\n",
        "                    'neutral': 7974}\n",
        "\n",
        "    # Soft Jaccard labels\n",
        "    #C'est la mÃ©thode d'Ã©tiquetage personnalisÃ©e qui a Ã©tÃ© adoptÃ©e par les compÃ©titeurs. \n",
        "    # ----------------------------------\n",
        "    n = len(input_ids_original)\n",
        "    sentence = np.arange(n)\n",
        "    answer = sentence[targets_start:targets_end + 1]\n",
        "    start_labels = np.zeros(n)\n",
        "    for i in range(targets_end + 1):\n",
        "        jac = jaccard_array(answer, sentence[i:targets_end + 1])\n",
        "        start_labels[i] = jac + jac ** 2\n",
        "        \n",
        "    ## Alpha est un paramÃ¨tre d'Ã©quilibre entre l'Ã©tiquetage (labeling) Cross Enthropy \n",
        "    ## habituel et l'Ã©tiquetage basÃ© sur la carte Jaccard (Jaccard-based labeling).\n",
        "    start_labels = (1 - config.SOFT_ALPHA) * start_labels / start_labels.sum()\n",
        "    start_labels[targets_start] += config.SOFT_ALPHA\n",
        "\n",
        "    end_labels = np.zeros(n)\n",
        "    for i in range(targets_start, n):\n",
        "        jac = jaccard_array(answer, sentence[targets_start:i + 1])\n",
        "        end_labels[i] = jac + jac ** 2\n",
        "    end_labels = (1 - config.SOFT_ALPHA) * end_labels / end_labels.sum()\n",
        "    end_labels[targets_end] += config.SOFT_ALPHA\n",
        "    ## Les nouveaux labels qui seront utilisÃ©s pour amÃ©liorer et garantir que le modÃ¨le apprendra correctement\n",
        "    start_labels = [0, 0, 0, 0] + list(start_labels) + [0]\n",
        "    end_labels = [0, 0, 0, 0] + list(end_labels) + [0]\n",
        "    # ----------------------------------\n",
        "\n",
        "    ## l'input pour RoBERTa\n",
        "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + \\\n",
        "                [2] + input_ids_original + [2]\n",
        "    ## Pas de types de token dans RoBERTa (tous a 0)\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_original) + 1)\n",
        "    ## Mask de l'input sans padding\n",
        "    mask = [1] * len(token_type_ids)\n",
        "    ## Identifiants des caractÃ¨res de dÃ©but et de fin pour chaque mot, y compris les nouveaux tokens\n",
        "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
        "    ## Ids des mots dans le tweet qui ont un caractÃ¨re cible, y compris les nouveaux tokens\n",
        "    targets_start += 4\n",
        "    targets_end += 4\n",
        "    orig_start = 4\n",
        "    orig_end = len(input_ids_original) + 3\n",
        "\n",
        "    ## Avant que RoBERTa puisse traiter ces donnÃ©es en entrÃ©e, nous devrons rendre \n",
        "    ## tous les vecteurs de mÃªme taille en ajoutant (padding ) des phrases plus courtes avec le token id 0. \n",
        "    ## AprÃ¨s le padding, nous avons une matrice / un tenseur \n",
        "    ## qui est prÃªt Ã  Ãªtre passÃ© Ã  RoBERTa.\n",
        "    ## Input padding: new mask, token type ids, tweet offsets\n",
        "    ## s'il y'en Ã  du padding \n",
        "    padding_len = max_len - len(input_ids)\n",
        "    if padding_len > 0:\n",
        "      ## on rÃ©cupÃ¨re les input_ids, mask, token_type_ids, tweet_offsets, end_offsets\n",
        "      input_ids = input_ids + ([1] * padding_len)\n",
        "      mask = mask + ([0] * padding_len)\n",
        "      token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "      tweet_offsets = tweet_offsets + ([(0, 0)] * padding_len)\n",
        "      start_labels = start_labels + ([0] * padding_len)\n",
        "      end_labels = end_labels + ([0] * padding_len)\n",
        "    ## Compute le targets_select\n",
        "    targets_select = [0] * len(token_type_ids)\n",
        "    for i in range(len(targets_select)):\n",
        "        if i in target_ids:\n",
        "            targets_select[i + 4] = 1\n",
        "\n",
        "    ## la sortie pour un tweet donnÃ©\n",
        "    return {'ids': input_ids,\n",
        "            'mask': mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'start_labels': start_labels,\n",
        "            'end_labels': end_labels,\n",
        "            'orig_start': orig_start,\n",
        "            'orig_end': orig_end,\n",
        "            'orig_tweet': tweet,\n",
        "            'orig_selected': selected_text,\n",
        "            'sentiment': sentiment,\n",
        "            'offsets': tweet_offsets,\n",
        "            'targets_select': targets_select}\n",
        "\n",
        "\n",
        "## Une classe de pratique pour que toutes les donnÃ©es des tweets soient stockÃ©es \n",
        "## au mÃªme endroit et qui sera utilisÃ© pour charger les donÃ©Ã©es avec dataloader aprÃ©s\n",
        "\n",
        "## Map-style datasets\n",
        "## A map-style dataset is one that implements the __getitem__() and __len__() \n",
        "## protocols, and represents a map from (possibly non-integral) indices/keys to data samples.\n",
        "class TweetDataset:\n",
        "    '''\n",
        "    dÃ©finir un objet(classe) qui contient toutes les donnÃ©es des tweets et implÃ©menter \n",
        "    la mÃ©thode (pre-buil) _len_  qui retourne le nombre de tweets et la mÃ©thode \n",
        "    __getitem__ qui traite les donnÃ©es des tweets et calcule toutes les  tenseur \n",
        "    (torch.tensor) qui sera alimentÃ© par le modÃ¨le : 'ids', 'mask', 'token_type_ids', \n",
        "    'start_labels', 'end_labels', 'orig_start', 'orig_end', 'orig_tweet', \n",
        "    'orig_selected', 'sentiment', 'offsets', 'targets_select'.\n",
        "    '''\n",
        "    def __init__(self, tweets, sentiments, selected_texts):\n",
        "        self.tweets = tweets\n",
        "        self.sentiments = sentiments\n",
        "        self.selected_texts = selected_texts\n",
        "        self.max_len = config.MAX_LEN\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"Returns preprocessed data sample as dict with\n",
        "        data converted to tensors.\n",
        "        \"\"\"\n",
        "        data = process_data(self.tweets[item],\n",
        "                            self.selected_texts[item],\n",
        "                            self.sentiments[item],\n",
        "                            self.tokenizer,\n",
        "                            self.max_len)\n",
        "\n",
        "        return {'ids': torch.tensor(data['ids'], dtype=torch.long),\n",
        "                'mask': torch.tensor(data['mask'], dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(data['token_type_ids'],\n",
        "                                               dtype=torch.long),\n",
        "                'start_labels': torch.tensor(data['start_labels'],\n",
        "                                             dtype=torch.float),\n",
        "                'end_labels': torch.tensor(data['end_labels'],\n",
        "                                           dtype=torch.float),\n",
        "                'orig_start': data['orig_start'],\n",
        "                'orig_end': data['orig_end'],\n",
        "                'orig_tweet': data['orig_tweet'],\n",
        "                'orig_selected': data['orig_selected'],\n",
        "                'sentiment': data['sentiment'],\n",
        "                'offsets': torch.tensor(data['offsets'], dtype=torch.long),\n",
        "                'targets_select': torch.tensor(data['targets_select'],\n",
        "                                               dtype=torch.float)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OkiOiOzHEql"
      },
      "source": [
        "deux techniques ont Ã©tÃ© utilisÃ©es afin d'assurer la mÃªme longueur des sÃ©quences d'entrÃ©e:\n",
        "* **Le masquage (Masking):** est un moyen d'indiquer aux couches de traitement des sÃ©quences que certains blocs sont manquants dans une entrÃ©e et qu'ils doivent donc Ãªtre ignorÃ©s lors du traitement des donnÃ©es.\n",
        "\n",
        "* **Le padding** est une forme spÃ©ciale de masquage oÃ¹ les Ã©tapes masquÃ©es se trouvent au au dÃ©but d'une sÃ©quence. Le remplissage (padding) vient de la nÃ©cessitÃ© de coder les donnÃ©es de la sÃ©quence en lots consÃ©cutifs (contiguous batches): afin que toutes les sÃ©quences d'un batch soient conformes Ã  une longueur standard donnÃ©e, il est nÃ©cessaire de remplir ou de tronquer certaines sÃ©quences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Q6Y5KPFUGh"
      },
      "source": [
        "# engine.py\n",
        "\n",
        "---\n",
        "Le fichier engine.py contient une definition de la fonction loss ainsi que l'implementation des deux fonction:</br>\n",
        "* train : qui permet de mettre le model en mode entrainment\n",
        "* eval: qui permet de mettre le model en mode evaluation \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2UMFZtzFUgB"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "import utils\n",
        "\n",
        "## Definition de la fonction loss\n",
        "def loss_fn(start_logits, end_logits,\n",
        "            start_positions, end_positions):\n",
        "    ## Appliquer la fonction \\log(\\text{Softmax}(x))log(Softmax(x)) Ã  une entrÃ©e \n",
        "    ## n-dimensionnelle Tenseur ici dim = 1\n",
        "    m = torch.nn.LogSoftmax(dim=1)\n",
        "    ## La mesure de la divergence de Kullback-Leibler est une mesure de distance\n",
        "    ## utile pour les distributions continues  \n",
        "    loss_fct = torch.nn.(KLDivLoss)\n",
        "    ## calculer la loss par apport a la prÃ©diction du caractÃ©re de dÃ©but du target(selected_text)\n",
        "    start_loss = loss_fct(m(start_logits), start_positions)\n",
        "    ## calculer la loss par apport a la prÃ©diction du caractÃ©re de fin du target\n",
        "    end_loss = loss_fct(m(end_logits), end_positions)\n",
        "    ## La valeur de loss totale et la somme des deux loss par apprt a la prÃ©diction \n",
        "    ## caractÃ©re de debut et fin du target\n",
        "    total_loss = (start_loss + end_loss)\n",
        "    return total_loss\n",
        "\n",
        "## dÃ©finition de la fonction train\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "    ## model.train() permet de mettre le modÃ¨le en mode train (il calcule les gradients)\n",
        "    model.train()\n",
        "    ## Permet de stocke la valeur moyenne actuelle et applique deux mÃ©thodes :\n",
        "    ## reset : qui remet toutes les valeurs Ã  zÃ©ro \n",
        "    ## update : qui met Ã  jour l'objet en y ajoutant de nouvelles valeurs, ici il s'agit de la valeur de la loss\n",
        "    losses = utils.AverageMeter()\n",
        "   \n",
        "    ## tqdm nous permettre de crÃ©er une progressbar en fonction de la longueur des donnÃ©es\n",
        "    tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "\n",
        "    for bi, d in enumerate(tk0):\n",
        "        ## recupÃ©rer l'id du tweet\n",
        "        ids = d['ids']\n",
        "        ## rÃ©cupÃ©rer les ids des tokens\n",
        "        token_type_ids = d['token_type_ids']\n",
        "        ## rÃ©cupÃ©rer le mask du tweet\n",
        "        mask = d['mask']\n",
        "        ## la valeur du start/end lable calculer en utilisant Jaccard-based labeling\n",
        "        start_labels = d['start_labels']\n",
        "        end_labels = d['end_labels']\n",
        "\n",
        "        ## nn.Module.to function permet de dÃ©placer le modÃ¨le\\tensors vers le GPU\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        start_labels = start_labels.to(device, dtype=torch.float)\n",
        "        end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "        ## mettre les gradients Ã  zÃ©ro avant de commencer Ã  faire de la backpropragation  \n",
        "        model.zero_grad()\n",
        "\n",
        "        ## applique un forward pass et rÃ©cuperer l'output\n",
        "        outputs_start, outputs_end = \\\n",
        "            model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        ## Calculer la valeur de la loss\n",
        "        loss = loss_fn(outputs_start, outputs_end,\n",
        "                       start_labels, end_labels)\n",
        "        ## Calculer les gradiants\n",
        "        loss.backward()\n",
        "        ## Ajuster les poids de notre modele\n",
        "        optimizer.step()\n",
        "        ## un programmateur de taux d'apprentissage basÃ© sur le temps\n",
        "        ## - il est contrÃ´lÃ© par le paramÃ¨tre de dÃ©croissance(decay) de l'optimiser\n",
        "        scheduler.step()\n",
        "        ## mettre a jour la valeur sauvegardÃ© de la loss \n",
        "        losses.update(loss.item(), ids.size(0))\n",
        "        tk0.set_postfix(loss=losses.avg)\n",
        "\n",
        "## dÃ©finition de la fonction de l'Ã©valuation\n",
        "def eval_fn(data_loader, model, device):\n",
        "    ## model.eval() met le modÃ¨le en mode Ã©valuation (il calcule pas les gradients)\n",
        "    model.eval()\n",
        "    ## rÃ©cupÃ©rer la valeur de la loss\n",
        "    losses = utils.AverageMeter()\n",
        "    ## rÃ©cupÃ©rer la valeur de la mÃ©tric de jaccards\n",
        "    jaccards = utils.AverageMeter()\n",
        "    ## Le wrapper \"with torch.no_grad()\" met temporairement tous les tensors avec require_grad Ã  false\n",
        "    with torch.no_grad():\n",
        "        ## passer les donnnÃ©e d'Ã©valuation avec une progressbar\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            start_labels = d['start_labels']\n",
        "            end_labels = d['end_labels']\n",
        "            orig_start = d['orig_start']\n",
        "            orig_end = d['orig_end']\n",
        "            orig_selected = d['orig_selected']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "            \n",
        "            ## nn.Module.to function permet de dÃ©placer le modÃ¨le\\tensors vers le GPU\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            start_labels = start_labels.to(device, dtype=torch.float)\n",
        "            end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs_start, outputs_end = \\\n",
        "                model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "            loss = loss_fn(outputs_start, outputs_end,\n",
        "                           start_labels, end_labels)\n",
        "            ## rÃ©cupÃ©rer les outputs start/stop prÃ©dites\n",
        "            outputs_start = outputs_start.cpu().detach().numpy()\n",
        "            outputs_end = outputs_end.cpu().detach().numpy()\n",
        "            ## lancÃ© le calcul de lindices de jaccard qui permet d'evaluer le modele\n",
        "            jaccard_scores = []\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                ## recupÃ©rer la valeur rÃ©elle du target\n",
        "                selected_tweet = orig_selected[px]\n",
        "                jaccard_score, _ = \\\n",
        "                    utils.calculate_jaccard(original_tweet=tweet,\n",
        "                                            target_string=selected_tweet,\n",
        "                                            start_logits=outputs_start[px, :],\n",
        "                                            end_logits=outputs_end[px, :],\n",
        "                                            orig_start=orig_start[px],\n",
        "                                            orig_end=orig_end[px],\n",
        "                                            offsets=offsets[px])\n",
        "                jaccard_scores.append(jaccard_score)\n",
        "            ## mettre a jour la valeur de jaccard\n",
        "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
        "            ## pareil pour la valeur de la loss\n",
        "            losses.update(loss.item(), ids.size(0))\n",
        "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
        "\n",
        "    print(f'Jaccard = {jaccards.avg}')\n",
        "\n",
        "    return jaccards.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etmylaX2Fb-j"
      },
      "source": [
        "# evaluate.py\n",
        "\n",
        "---\n",
        "La mÃªme implÃ©mentation de la fonction d'Ã©valuation qui a Ã©tÃ© implÃ©mentÃ©e dans le fichier **engin.py**, celle-ci peut Ãªtre utilisÃ©e pour effectuer une Ã©valuation directement en utilisant le fichier **evaluate.py**.**bold text**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oReUS_pFcZN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "2a5a6a4853c647d5ab4e6f2e421c5b21",
            "ea33407f48d84529a3cedce8ff4eb717",
            "86e84d68c27d472b8a7a0d57a6e22c43",
            "a042d53d0d374fbba87c5126bc89edb1",
            "fb2ad4da78f8468f8b5e0bacdfdb6a44",
            "67b4d3d78dee4cc39c7679217f24bca9",
            "f7174c2b850b4684b80adf245f073187",
            "b40d221cc11e42abacb6d79d87b64e15",
            "da3165f8a7bb4f1ba6002a3dd1839b23",
            "ad49480862ce44e696e8ab8d60f4850c",
            "fd76536cf49f4f9e9dcca7b8c6c9c804",
            "97fb8388273247cea7095fce3ccd4789",
            "2fdf7552d81344c6b23bbd1e82f34b80",
            "6991e98fa56846f98fdf918568cafd89",
            "79c265a4eeda434db25543b711583219",
            "c5c53ebd65b84df79429c42c41a456f0",
            "311e02e4ab79455f96a6a69d882cf44c",
            "8fbea1556436405c82e84a37e15ee0c3",
            "be8768226ed74c338a38576cc1639b61",
            "f195b12fa5be48fca00f7c2056222609",
            "d40ab0eeaee6478aa0eec0bc7a5d883f",
            "2f1b9d41b21047ec94130b11e14337d6",
            "71e0c96ecb90475a9767aa517b1ff34d",
            "83643d9c675e43d0adf21bb7e7bb4bd2",
            "e67e719ed34a4b07a0591d376313ceeb",
            "a19299dbe1cb457fb61a2bd60a044123",
            "e2037ef67ba3407e9883a32f1a9ae9e9",
            "ef8f28882f6a4689ac35c8b7dc69dc8a",
            "80baee64c83f4c05b13026fdd6c3928f",
            "95fe9696a2b74d7ea8c85a71ed0ea401",
            "1dd0410fc9704a9caa064a47ee8936bc",
            "ba08cfa1331d47489b03c860ed273728",
            "c649b48206e8461ab986a31eff41663d",
            "de48ecab2e9a43a2984091f852f12b25",
            "d9ccaad734f8466f9c609ba4c19ae320",
            "79deeeeeaa964a06bc9f3ad5462ca312",
            "1790d4b810e6479fb0986a33c7d6d89d",
            "3e0abbd9b372444a9ecb25a616239688",
            "8388209c0eea421a864e786bf0e88db2",
            "6e28785f8a2c4d26b9dedb98f993c35c",
            "6ae593eea4ea4bf29ccb9207bf39a987",
            "0a8fc24b90b944d1ba355ecbb00bfa58",
            "dc414fdaee294c9db8c677b27a81707f",
            "b53ea0fc5b7e42f6961cc98b3b257128",
            "9f73581c6f304a2381a54c3aded4fb52",
            "ad0874d836e3493cb84f49eb88448e72",
            "86d93fca9e4a417187f9512e505ccf8c",
            "0c571a2eff364548b85ad2d1a1ccc4cd",
            "e34c097bd1a8400cab7a702b06a9143c",
            "1eb203e1db144517ae6bf803be68d76b",
            "c555a66b7f44451e82c325428f234bc4",
            "5ac0aaff737641eca49308824bb94603",
            "1ec1aa1825834a7c96fddcafac8ee72b",
            "ae9af73a41084fc2bbf736f4afd9f5dd",
            "24ea29ea46fe45f5876e16e9bbc5daca",
            "806bf2cfe63e4b909522ad2c6b6f6d8c"
          ]
        },
        "outputId": "98e79f68-c3d7-4978-c812-dcd75770c65d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import tqdm.autonotebook as tqdm\n",
        "\n",
        "import utils\n",
        "import config\n",
        "import models\n",
        "import dataset\n",
        "\n",
        "## dÃ©finition de la fonction de l'Ã©valuation\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    ## rÃ©cupÃ©rer la valeur de la mÃ©tric de jaccards\n",
        "    jaccards = utils.AverageMeter()\n",
        "    ## comme j'avais commenter sur le code ci-dessous\n",
        "    ## Le wrapper \"with torch.no_grad()\" met temporairement tous les tensors avec require_grad Ã  false\n",
        "    with torch.no_grad():\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            start_labels = d['start_labels']\n",
        "            end_labels = d['end_labels']\n",
        "            orig_start = d['orig_start']\n",
        "            orig_end = d['orig_end']\n",
        "            orig_selected = d['orig_selected']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "            ## dÃ©placer le modÃ¨le\\tensors vers le GPU/CPU\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            start_labels = start_labels.to(device, dtype=torch.float)\n",
        "            end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs_start, outputs_end = \\\n",
        "                model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            outputs_start = outputs_start.cpu().detach().numpy()\n",
        "            outputs_end = outputs_end.cpu().detach().numpy()\n",
        "\n",
        "            jaccard_scores = []\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                selected_tweet = orig_selected[px]\n",
        "                jaccard_score, _ = \\\n",
        "                    utils.calculate_jaccard(original_tweet=tweet,\n",
        "                                            target_string=selected_tweet,\n",
        "                                            start_logits=outputs_start[px, :],\n",
        "                                            end_logits=outputs_end[px, :],\n",
        "                                            orig_start=orig_start[px],\n",
        "                                            orig_end=orig_end[px],\n",
        "                                            offsets=offsets[px])\n",
        "                jaccard_scores.append(jaccard_score)\n",
        "\n",
        "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
        "            tk0.set_postfix(jaccard=jaccards.avg)\n",
        "\n",
        "    return jaccards.avg\n",
        "\n",
        "\n",
        "def run(fold):\n",
        "    ## Lecture des donnÃ©es de l'entrainement\n",
        "    dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "\n",
        "    ## Lecture des donnÃ©es de la validation\n",
        "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
        "    ## Les types de tenseurs CUDA, qui implÃ©mentent la mÃªme fonction que les \n",
        "    ## tenseurs CPU, mais qui utilisent les GPU pour le calcul\n",
        "    device = torch.device('cuda')\n",
        "    ## le modÃ¨le hÃ©rite de la class PreTrainedModel\n",
        "    ## c'est un modÃ©le prÃ©-entrainÃ© sur Squad2\n",
        "    ## le modÃ©le prÃ©cisÃ© dans la class config c'est bien 'deepset/roberta-base-squad2' \n",
        "    model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_CONFIG)\n",
        "    ##  Pour assurer que le modÃ¨le rendre tous les hidden_state (weights).\n",
        "    model_config.output_hidden_states = True\n",
        "    \n",
        "    ## CrÃ©e une instance de la classe TweetModel avec la config crÃ©e just avant\n",
        "    model = models.TweetModel(conf=model_config)\n",
        "    model.to(device)\n",
        "    ## La fonction load_state_dict() prend un objet du dictionnaire, tet elle\n",
        "    ## charge le state_dict sÃ©rialisÃ© et sauvegardÃ© du modÃ¨le\n",
        "    model.load_state_dict(torch.load(\n",
        "        f'{config.TRAINED_MODEL_PATH}/model_{fold}.bin'))\n",
        "    \n",
        "    ## model.eval() met le modÃ¨le en mode Ã©valuation (il calcule pas les gradients)\n",
        "    model.eval()\n",
        "\n",
        "    ## PrÃ©parÃ© les tweets de validation selon la methode dataset.TweetDataset() qui prÃ©pare toutes les donnÃ©es des tweets\n",
        "    valid_dataset = dataset.TweetDataset(\n",
        "        tweets=df_valid.text.values,\n",
        "        sentiments=df_valid.sentiment.values,\n",
        "        selected_texts=df_valid.selected_text.values)\n",
        "    ## chargement des donnÃ©es de validation en utilisant dataLoader de Pytorch \n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4,\n",
        "        shuffle=False)\n",
        "    ## Le fait de dÃ©finir l'argument num_workers comme un nombre entier positif\n",
        "    ## activera le chargement de donnÃ©es multiprocessus avec le nombre spÃ©cifiÃ© de processus de chargement des travailleurs\n",
        "    ## calculer l'indice de jaccard\n",
        "    jaccard = eval_fn(valid_data_loader, model, device)\n",
        "\n",
        "    return jaccard\n",
        "\n",
        "##  if __name__ == \"main\" ' bloc pour empÃªcher l'exÃ©cution de (certain) code lors\n",
        "##  de l'importation du module. En bref, __name__ est une variable dÃ©finie pour \n",
        "##  chaque script qui dÃ©finit si le script est exÃ©cutÃ© en tant que module principal \n",
        "##  ou s'il est exÃ©cutÃ© en tant que module importÃ©.\n",
        "if __name__ == '__main__':\n",
        "    utils.seed_everything(config.SEED)\n",
        "    ## Lise qui va contenir le score de chaque folds\n",
        "    fold_scores = []\n",
        "    ## N_FOLDS est a 5\n",
        "    for i in range(config.N_FOLDS):\n",
        "        fold_score = run(i)\n",
        "        fold_scores.append(fold_score)\n",
        "    ## Afficher les score de chaque folds et le score moyen\n",
        "    for i in range(config.N_FOLDS):\n",
        "        print(f'Fold={i}, Jaccard = {fold_scores[i]}')\n",
        "    print(f'Mean = {np.mean(fold_scores)}')\n",
        "    print(f'Std = {np.std(fold_scores)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a5a6a4853c647d5ab4e6f2e421c5b21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da3165f8a7bb4f1ba6002a3dd1839b23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=496313727.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "311e02e4ab79455f96a6a69d882cf44c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e67e719ed34a4b07a0591d376313ceeb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c649b48206e8461ab986a31eff41663d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ae593eea4ea4bf29ccb9207bf39a987",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e34c097bd1a8400cab7a702b06a9143c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold=0, Jaccard = 0.7163026420895469\n",
            "Fold=1, Jaccard = 0.7108215431021135\n",
            "Fold=2, Jaccard = 0.7158955035127735\n",
            "Fold=3, Jaccard = 0.7166221978997807\n",
            "Fold=4, Jaccard = 0.7109265704332721\n",
            "Mean = 0.7141136914074974\n",
            "Std = 0.002655369837057321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Eedd3Jg3c6"
      },
      "source": [
        "**TORCH.UTILS.DATA**\n",
        "Au cÅ“ur de l'utilitaire de chargement de donnÃ©es PyTorch se trouve la classe ```torch.utils.data.DataLoader```. Elle reprÃ©sente un Python itÃ©rable sur un ensemble de donnÃ©es, avec le support de:</br>\n",
        "* map-style et iterable-style datasets,\n",
        "\n",
        "* la personnalisation de l'ordre de chargement des donnÃ©es,\n",
        "\n",
        "* le dosage automatique,\n",
        "\n",
        "* chargement de donnÃ©es Ã  un ou plusieurs processus,\n",
        "\n",
        "* Ã©pinglage automatique de la mÃ©moire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrP6RBNKFqd9"
      },
      "source": [
        "# infer.py\n",
        "\n",
        "---\n",
        "Ce code reprÃ©sente l'implÃ©mentation d'une Forward passe pour prÃ©dire le texte sÃ©lectionnÃ© (start/end_labels) des tweets donnÃ©, on peut dire que cela effectue la mÃªme tÃ¢che que la mÃ©thode .predict() en ML puisque ya pas la notion de l'apprentissage c'est just une propagation dans le modele et rÃ©cupÃ©ration de l'output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtO5TLyqFp-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459773e4-c234-4cfb-c1d4-9665f468a2f0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import tqdm\n",
        "\n",
        "import config\n",
        "import models\n",
        "import dataset\n",
        "import utils\n",
        "\n",
        "\n",
        "def run():\n",
        "    df_test = pd.read_csv(config.TEST_FILE)\n",
        "    df_test.loc[:, 'selected_text'] = df_test.text.values\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model_config = transformers.RobertaConfig.from_pretrained(\n",
        "        config.MODEL_CONFIG)\n",
        "    model_config.output_hidden_states = True\n",
        "\n",
        "    fold_models = []\n",
        "    for i in range(config.N_FOLDS):\n",
        "        model = models.TweetModel(conf=model_config)\n",
        "        model.to(device)\n",
        "        model.load_state_dict(torch.load(\n",
        "            f'{config.TRAINED_MODEL_PATH}/model_{i}.bin'),\n",
        "            strict=False)\n",
        "        model.eval()\n",
        "        fold_models.append(model)\n",
        "    ## TweetDataset est un map-style et iterable-style datasets\n",
        "    test_dataset = dataset.TweetDataset(\n",
        "        tweets=df_test.text.values,\n",
        "        sentiments=df_test.sentiment.values,\n",
        "        selected_texts=df_test.selected_text.values)\n",
        "    ## data_loader permet d'automatiser le chargement des donnÃ©es\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4) ## shuffle=False puisuqe on est en mode evaluation donc pas besoin d'un chuffle\n",
        "\n",
        "    char_pred_test_start = []\n",
        "    char_pred_test_end = []\n",
        "    ## Pas de calcu des gradiants, c'est un forward pass de notre modÃ¨le\n",
        "    with torch.no_grad():\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_start_folds = []\n",
        "            outputs_end_folds = []\n",
        "            for i in range(config.N_FOLDS):\n",
        "                outputs_start, outputs_end = \\\n",
        "                    fold_models[i](ids=ids,\n",
        "                                   mask=mask,\n",
        "                                   token_type_ids=token_type_ids)\n",
        "                outputs_start_folds.append(outputs_start)\n",
        "                outputs_end_folds.append(outputs_end)\n",
        "\n",
        "            outputs_start = sum(outputs_start_folds) / config.N_FOLDS\n",
        "            outputs_end = sum(outputs_end_folds) / config.N_FOLDS\n",
        "\n",
        "            outputs_start = torch.softmax(outputs_start, dim=-1).cpu().detach().numpy()\n",
        "            outputs_end = torch.softmax(outputs_end, dim=-1).cpu().detach().numpy()\n",
        "            ## Affecter les prababilitÃ©es de l'output  outputs_start/outputs_end au char\n",
        "            ## pour passer au char level puisque le Transformers sont token level\n",
        "            ## chaque caractÃ©re prends la probavilitÃ©e affectÃ© au token auquel il appartient\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                char_pred_test_start.append(\n",
        "                    utils.token_level_to_char_level(tweet, offsets[px], outputs_start[px]))\n",
        "                char_pred_test_end.append(\n",
        "                    utils.token_level_to_char_level(tweet, offsets[px], outputs_end[px]))\n",
        "    ## Serialiser et sauvegarder les output de la prÃ©diction\n",
        "    with open('/content/drive/MyDrive/very_final/pickles/roberta-char_pred_test_start.pkl', 'wb') as handle:\n",
        "        pickle.dump(char_pred_test_start, handle)\n",
        "    with open('/content/drive/MyDrive/very_final/pickles/roberta-char_pred_test_end.pkl', 'wb') as handle:\n",
        "        pickle.dump(char_pred_test_end, handle)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [01:02<00:00,  1.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUTPKlGDGpj8"
      },
      "source": [
        "# models.py\n",
        "\n",
        "---\n",
        "ce fichier contient une implÃ©mentation de la classe de modÃ¨le **TweetModel** qui hÃ©ritÃ©e des transformateurs **BertPreTrainedModel** et la mÃ©thode forward qui rÃ©cupÃ¨re la sortie logits juste avant la couche des embeddings et effectue un Max-pooling et un Average_pooling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0kVj0sFGo6k"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "import config\n",
        "\n",
        "\n",
        "class TweetModel(transformers.BertPreTrainedModel):\n",
        "    ## Instantaition du modele\n",
        "    def __init__(self, conf):\n",
        "        super(TweetModel, self).__init__(conf)\n",
        "        self.roberta = transformers.RobertaModel.from_pretrained(\n",
        "            config.MODEL_CONFIG,\n",
        "            config=conf)\n",
        "        self.high_dropout = torch.nn.Dropout(config.HIGH_DROPOUT)\n",
        "        self.classifier = torch.nn.Linear(config.HIDDEN_SIZE * 2, 2)\n",
        "\n",
        "        torch.nn.init.normal_(self.classifier.weight, std=0.02)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        # sequence_output of N_LAST_HIDDEN + Embedding states\n",
        "        # (N_LAST_HIDDEN + 1, batch_size, num_tokens, 768)\n",
        "        _, _, out = self.roberta(ids, attention_mask=mask,\n",
        "                                 token_type_ids=token_type_ids)\n",
        "        \n",
        "        ## RÃ©cupÃ©re les valeus de toutes les couches sans la couche des embeddings.\n",
        "        out = torch.stack(\n",
        "            tuple(out[-i - 1] for i in range(config.N_LAST_HIDDEN)), dim=0)\n",
        "        ## Avg pooling\n",
        "        out_mean = torch.mean(out, dim=0)\n",
        "        ## Max pooling\n",
        "        out_max, _ = torch.max(out, dim=0)\n",
        "        out = torch.cat((out_mean, out_max), dim=-1)\n",
        "\n",
        "\n",
        "        # Multisample Dropout: https://arxiv.org/abs/1905.09788 expliquÃ© just en bas\n",
        "        ## logit cÃ©est la couche qui vient just avant la couche Dense\n",
        "        logits = torch.mean(torch.stack([\n",
        "            self.classifier(self.high_dropout(out))\n",
        "            for _ in range(5)\n",
        "        ], dim=0), dim=0)\n",
        "        ## puique on'a deux output dans la loits (start_lable / end_label)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "\n",
        "        # (batch_size, num_tokens)\n",
        "        ## .squeeze() pou applatire (flatteniser) les Nd tensors\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5zCx9T1lqBD"
      },
      "source": [
        "**Multi Sample Dropout (MSD):** C'est l'une des techniques qu'ils ont utilisÃ©es et que je trouve si intÃ©ressante. En fait, il applique un dropout plusieurs fois avec diffÃ©rents masques et ensuite il calcule la moyenne des rÃ©sultats</br>\n",
        "  Le dropout initial crÃ©e un sous-ensemble choisi au hasard (appelÃ© dropout sample) Ã  partir des donnÃ©es d'entrÃ©e de chaque itÃ©ration d'entrainement, tandis que le MSD crÃ©e plusieurs Ã©chantillon de dropout. La loss est calculÃ©e pour chaque Ã©chantillon, puis la moyenne des losses des Ã©chantillons est calculÃ©e pour obtenir la Loss finale [(plus de dÃ©tails ici)](https://arxiv.org/pdf/1905.09788.pdf).</br>\n",
        "  ![alt text](https://github.com/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/Multi-Sample-Dropout.png?raw=true)</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPit1dlVHEIs"
      },
      "source": [
        "# utils.py\n",
        "\n",
        "---\n",
        "\n",
        "le fichier **utils.py**contient toutes les implÃ©mentations de toutes les fonctions qui seront utilisÃ©es dans de nombreux fichiers de code, telle que :\n",
        "* la fonction qui fixe le seed global **seed_everything** \n",
        "la fonction qui calcule les probabilitÃ©s de niveau de caractÃ¨res token_level_to_char_level\n",
        "* la fonction qui calcule la mÃ©trique de l'Ã©valuation mentionnÃ©e dans les Ã©noncÃ©es de la competition, qui est **jaccard**\n",
        "* la fonction qui calcule le score final du Jaccard en utilisant les prÃ©dictions **calculate_jaccard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xc2lgxiHTsQ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "def token_level_to_char_level(text, offsets, preds):\n",
        "    probas_char = np.zeros(len(text))\n",
        "    for i, offset in enumerate(offsets):\n",
        "        if offset[0] or offset[1]:\n",
        "            probas_char[offset[0]:offset[1]] = preds[i]\n",
        "\n",
        "    return probas_char\n",
        "\n",
        "\n",
        "def jaccard(str1, str2):\n",
        "    \"\"\"Original metric implementation.\"\"\"\n",
        "    a = set(str1.lower().split())\n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "\n",
        "def get_best_start_end_idx(start_logits, end_logits,\n",
        "                           orig_start, orig_end):\n",
        "    \"\"\"Return best start and end indices following BERT paper.\"\"\"\n",
        "    best_logit = -np.inf\n",
        "    best_idxs = None\n",
        "    start_logits = start_logits[orig_start:orig_end + 1]\n",
        "    end_logits = end_logits[orig_start:orig_end + 1]\n",
        "    for start_idx, start_logit in enumerate(start_logits):\n",
        "        for end_idx, end_logit in enumerate(end_logits[start_idx:]):\n",
        "            logit_sum = start_logit + end_logit\n",
        "            if logit_sum > best_logit:\n",
        "                best_logit = logit_sum\n",
        "                best_idxs = (orig_start + start_idx,\n",
        "                             orig_start + start_idx + end_idx)\n",
        "    return best_idxs\n",
        "\n",
        "\n",
        "def calculate_jaccard(original_tweet, target_string,\n",
        "                      start_logits, end_logits,\n",
        "                      orig_start, orig_end,\n",
        "                      offsets, \n",
        "                      verbose=False):\n",
        "    \"\"\"Calculates final Jaccard score using predictions.\"\"\"\n",
        "    start_idx, end_idx = get_best_start_end_idx(\n",
        "        start_logits, end_logits, orig_start, orig_end)\n",
        "\n",
        "    filtered_output = ''\n",
        "    for ix in range(start_idx, end_idx + 1):\n",
        "        filtered_output += original_tweet[offsets[ix][0]:offsets[ix][1]]\n",
        "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
        "            filtered_output += ' '\n",
        "\n",
        "    # Return orig tweet if it has less then 2 words\n",
        "    if len(original_tweet.split()) < 2:\n",
        "        filtered_output = original_tweet\n",
        "\n",
        "    if len(filtered_output.split()) == 1:\n",
        "        filtered_output = filtered_output.replace('!!!!', '!')\n",
        "        filtered_output = filtered_output.replace('..', '.')\n",
        "        filtered_output = filtered_output.replace('...', '.')\n",
        "\n",
        "    filtered_output = filtered_output.replace('Ã¯Ã¯', 'Ã¯')\n",
        "    filtered_output = filtered_output.replace('Â¿Â¿', 'Â¿')\n",
        "\n",
        "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
        "    return jac, filtered_output\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
        "    ## Permet de stocke la valeur moyenne actuelle et applique deux mÃ©thodes :\n",
        "    ## reset : qui remet toutes les valeurs Ã  zÃ©ro \n",
        "    ## update : qui met Ã  jour l'objet en y ajoutant de nouvelles valeurs, ici il s'agit de la valeur de la loss\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDzmFycLG6Rc"
      },
      "source": [
        "#train.py\n",
        "\n",
        "---\n",
        "Ce fichier de code exÃ©cute l'entrainement sur les donnÃ©es d'entranement et de la validation sur les donnÃ©es de validation et affiche les valeurs de jaccard et la loss\n",
        "\n",
        "1) Il a utilisÃ© le GPU Colab Pro pour RoBERTa-large et il a fallu environ 6h pour l'entraÃ®ner avec 5 folds et 4 Ã©poques sans optimisation particuliÃ¨re. \n",
        "\n",
        "[Hikkiiii](https://www.kaggle.com/wochidadonggua) a Ã©galement entraÃ®ner RoBERTa-large, 2V100, APEX(O1), il a fallu environ 220s par Ã©poque \n",
        "\n",
        "2) RoBERTa-base-squad2 est disponible prÃ©-entrainÃ© par [HuggingFace.](https://huggingface.co/deepset/roberta-base-squad2)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkXID0zIxpE5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import torch\n",
        "import torchcontrib\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "import models\n",
        "import engine\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HT0b6QoG61j"
      },
      "source": [
        "Une autre technique qui a Ã©tÃ© utilisÃ©e comme **Optimiser** l'est :\n",
        "* **SWA :** la technique SWA [(Stochastic Weight Averaging)](https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/) rÃ©cemment proposÃ©e, et sa nouvelle implÃ©mentation dans torchcontrib. La SWA est une procÃ©dure simple qui amÃ©liore la gÃ©nÃ©ralisation du deep learning sur la Descente de Gradient Stochastique (SGD) sans coÃ»t supplÃ©mentaire, et peut Ãªtre utilisÃ©e en remplacement de tout autre **optimiseur dans PyTorch**. Le SWA a une large gamme d'applications et de fonctionnalitÃ©s.</br>\n",
        "Il a Ã©tÃ© dÃ©montrÃ© que SWA amÃ©liore considÃ©rablement la gÃ©nÃ©ralisation des tÃ¢ches de vision par ordinateur, y compris les VGG, les ResNets, les Wide ResNets et les DenseNets sur ImageNet et les CIFAR benchmarks.\n",
        "\n",
        "En bref, le SWA effectue une moyenne Ã©gale des poids traversÃ©s par le SGD avec un programme d'apprentissage modifiÃ©."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1023bec17f3048f2994587ab2ca923ff",
            "4f836dfd3d614d37a6e12828b9e26dea",
            "0288fee9c3674c198d5e21621aac5273",
            "56eabcc0b14d4fa6a0b5b2323b3a27a5",
            "9c97ceae839b48029d9f89ed8021d1a2",
            "d0732c192a784c53b86a68f3a16254a6",
            "556a4510c3234b38a87c3743b8df9c97",
            "ec4bd0f01be341e88fc41673825fbaca",
            "2d6a2ea3e1454d28bd5a9760e19a4ca7",
            "6cad7320919248cab53cba7a3eb47225",
            "18287140c5324a7e85b01460e5e889f5",
            "fb4870326d1545dcaab261730965bc99",
            "11cd33748ed9445c921d533c922a2128",
            "4ae80b3c967142b1b773b080ed310264",
            "31bf737378c04156a4ced60a3b781572",
            "8344b11a1c42484883bb312ebfa677c6"
          ]
        },
        "id": "xS47DeGUGyt1",
        "outputId": "1bcfe209-c4d3-425e-a5a4-811fac7f4167"
      },
      "source": [
        "## Ce code permet de lancÃ© l'entrainement sur les 5 folds \n",
        "def run(fold):\n",
        "   \n",
        "    dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    train_dataset = dataset.TweetDataset(\n",
        "        tweets=df_train.text.values,\n",
        "        sentiments=df_train.sentiment.values,\n",
        "        selected_texts=df_train.selected_text.values)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TRAIN_BATCH_SIZE,\n",
        "        num_workers=4,\n",
        "        shuffle=True)\n",
        "\n",
        "    valid_dataset = dataset.TweetDataset(\n",
        "        tweets=df_valid.text.values,\n",
        "        sentiments=df_valid.sentiment.values,\n",
        "        selected_texts=df_valid.selected_text.values)\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4,\n",
        "        shuffle=False)\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model_config = transformers.RobertaConfig.from_pretrained(\n",
        "        config.MODEL_CONFIG)\n",
        "    model_config.output_hidden_states = True\n",
        "    model = models.TweetModel(conf=model_config)\n",
        "    model = model.to(device)\n",
        "    print(\"------------------> here\")\n",
        "    \n",
        "    ## Nombre d'iteration c'est le nombre des donnÃ©es d'entrÃ© (tweets) divisÃ© par\n",
        "    ## la taille du batch dans le fichier config.py\n",
        "    num_train_steps = int(\n",
        "        len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "    ## RÃ©cupÃ©rer les paramÃ¨tres de l'optimizer\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "\n",
        "    ## puisqu'il est recommandÃ© d'utiliser cet optimiseur pour le fine tuning\n",
        "    ## (modification sur l'architecture), puisque c'est ainsi que le modÃ¨le a \n",
        "    ## Ã©tÃ© entraÃ®nÃ© et de conserver les mÃªmes comportements que ceux mentionnÃ©s \n",
        "    ## sur le repo git de BERT (https://github.com/google-research/bert/blob/master/optimization.py#L65)\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer\n",
        "                    if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': config.WEIGHT_DECAY},\n",
        "        {'params': [p for n, p in param_optimizer\n",
        "                    if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0}]\n",
        "    ## AdamW: un optimiseur adaptatif avec utilisation d'une Ã©chelle de taux\n",
        "    ## d'apprentissage pour moduler l'Ã©volution du taux d'apprentissage de\n",
        "    ## l'optimiseur en fonction du temps \n",
        "    base_opt = transformers.AdamW(optimizer_parameters,\n",
        "                                  lr=config.LEARNING_RATE)\n",
        "    ## SWA : la technique SWA (Stochastic Weight Averaging) est prÃ©senter au dessus de cette cellule\n",
        "    optimizer = torchcontrib.optim.SWA(\n",
        "        base_opt,\n",
        "        swa_start=int(num_train_steps * config.SWA_RATIO),\n",
        "        swa_freq=config.SWA_FREQ,\n",
        "        swa_lr=None)\n",
        "    \n",
        "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=int(num_train_steps * config.WARMUP_RATIO),\n",
        "        num_training_steps=num_train_steps)\n",
        "\n",
        "    print(f'Training is starting for fold={fold}')\n",
        "\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        engine.train_fn(train_data_loader, model, optimizer,device, scheduler=scheduler)\n",
        "        jaccard = engine.eval_fn(valid_data_loader, model, device)\n",
        "\n",
        "    if config.USE_SWA:\n",
        "        optimizer.swap_swa_sgd()\n",
        "\n",
        "    torch.save(model.state_dict(),\n",
        "               f'{config.MODEL_SAVE_PATH}/model_{fold}.bin')\n",
        "\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    utils.seed_everything(seed=config.SEED)\n",
        "\n",
        "    fold_scores = []\n",
        "    for i in range(config.N_FOLDS):\n",
        "        fold_score = run(i)\n",
        "        fold_scores.append(fold_score)\n",
        "\n",
        "    print('\\nScores without SWA:')\n",
        "    for i in range(config.N_FOLDS):\n",
        "        print(f'Fold={i}, Jaccard = {fold_scores[i]}')\n",
        "    print(f'Mean = {np.mean(fold_scores)}')\n",
        "    print(f'Std = {np.std(fold_scores)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1023bec17f3048f2994587ab2ca923ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6a2ea3e1454d28bd5a9760e19a4ca7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=496313727.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:04<00:00,  1.62it/s, loss=0.0218]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.703, loss=0.01]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7029905612369929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0104]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.712, loss=0.00929]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7118255485009135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00902]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.717, loss=0.00939]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7170824580463284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00808]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.89it/s, jaccard=0.716, loss=0.00943]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7163026420895469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0196]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.696, loss=0.0099]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.6963974280475891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.59it/s, loss=0.01]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.705, loss=0.00921]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7054961819176117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0088]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.711, loss=0.00945]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7110974016990879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.00799]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.711, loss=0.00939]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7108215431021135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0199]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.95it/s, jaccard=0.701, loss=0.0105]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7007900525880214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.59it/s, loss=0.0103]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.707, loss=0.00936]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7070440963345973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00895]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.713, loss=0.00921]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7134881141772793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00821]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.716, loss=0.00934]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7158955035127735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0211]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.694, loss=0.0106]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.6944610752763127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0102]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.709, loss=0.00972]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7094754330307022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00889]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.717, loss=0.00957]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7172411822420536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00803]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.717, loss=0.00964]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7166221978997807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0203]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.695, loss=0.0104]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.694875414018416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0108]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.703, loss=0.0103]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.70296628740658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0094]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.707, loss=0.00943]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7067339098954668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.00862]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.711, loss=0.00943]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7109265704332721\n",
            "\n",
            "Scores without SWA:\n",
            "Fold=0, Jaccard = 0.7163026420895469\n",
            "Fold=1, Jaccard = 0.7108215431021135\n",
            "Fold=2, Jaccard = 0.7158955035127735\n",
            "Fold=3, Jaccard = 0.7166221978997807\n",
            "Fold=4, Jaccard = 0.7109265704332721\n",
            "Mean = 0.7141136914074974\n",
            "Std = 0.002655369837057321\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}