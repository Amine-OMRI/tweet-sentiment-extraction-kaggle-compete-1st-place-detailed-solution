# [Kaggle Tweet Sentiment Extraction Competition](https://www.kaggle.com/c/tweet-sentiment-extraction/leaderboard): 1st place solution (Dark of the Moon team) 

Ce repository contient la solution d√©taill√©e qui ont remport√© la premi√®re place de la comp√©tition kaggle appel√© "Tweet Sentiment Extraction" il y a 5 mois.
  ### l'√©quipe qui a remport√© la comp√©tition, compos√©e de:
   [Heartkilla](https://www.kaggle.com/aruchomu): Artsem Zhyvalkouski Data Scientist</br>
   [Hikkiiii](https://www.kaggle.com/wochidadonggua): Hikkiiii NLP Data scientist Beijing, Beijing, China</br>
   [Theo](https://www.kaggle.com/theoviel): Th√©o Vie Chercheur scientifique √† Paris, √éle-de-France, Franc</br>
   [Cl_ev](https://www.kaggle.com/cl2ev1): Anton travaille dans l'IT London, England, United Kingdom</br>

 ## Pr√©sentation de la comp√©tition 
   La comp√©tition portait sur l'extraction de sentiments, ci-dessous un r√©sum√© sur le sujet :

  "My ridiculous dog is amazing." [sentiment: positive]</br>
  Avec tous les tweets qui circulent √† chaque seconde, il est difficile de dire si le sentiment derri√®re un tweet sp√©cifique aura un impact sur la marque d'une     entreprise ou d'une personne parce qu'il est viral (positif), ou s'il d√©vastera les profits parce qu'il a un ton n√©gatif. Il est important de saisir les           sentiments dans la langue, √† un moment o√π les d√©cisions et les r√©actions sont cr√©√©es et mises √† jour en quelques secondes. Mais quels mots conduisent r√©ellement   √† la description des sentiments ? Dans cette comp√©tition, l'objectif est de choisir la partie du tweet (mot ou phrase) qui refl√®te le sentiment.
  Quels mots des tweets refl√®tent un sentiment positif, n√©gatif ou neutre ? tout en utilisant les outils d'apprentissage automatique ?</br>
  Dans ce concours, ils ont extrait les phrases de la plateforme ["Data for Everyone"](https://appen.com/resources/datasets/). L'ensemble de donn√©es est intitul√©   "Analyse du sentiment": Emotion in Text".</br>
  L'objectif de ce concours est de construire un mod√®le qui peut faire la m√™me chose - examiner le sentiment √©tiquet√© pour un tweet donn√© et d√©terminer quel mot     ou phrase le soutient le mieux.</br>
   ### T√¢che
   - Pour un tweet donn√©, pr√©dire quel mot ou quelle phrase refl√®te le mieux le sentiment √©tiquet√©
   ### Data
  ‚óã Train: 27k tweets</br>
  ‚óã Public / private test: 4k / 8k tweets 
  | Texte (donn√©) | Sentiment (donn√©) | texte_s√©lectionn√© (target) |
  | :---: | :---: | :---: |
  | J'aime beaucoup la chanson Love Story de Taylor Swift | positive | j'aime |
  | je dois r√©cup√©rer mon ordinateur r√©par√© | neutre | je dois r√©cup√©rer mon ordinateur r√©par√© |
  | trop triste, tu vas me manquer ici √† San Diego ! ! | n√©gatif | trop triste |

   ### Evaluation
  La m√©trique utilis√©e dans cette comp√©tition est le [score Jaccard](https://en.wikipedia.org/wiki/Jaccard_index) au niveau des mots. Vous trouverez [ici](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50) une bonne description de la similarit√© de Jaccard pour les cha√Ænes de caract√®res.</br>
  ![alt text](https://neo4j.com/docs/graph-algorithms/current/images/jaccard.png)

  Une impl√©mentation Python bas√©e sur les liens ci-dessus:
  ```ruby
  def jaccard(str1, str2): 
      a = set(str1.lower().split()) 
      b = set(str2.lower().split())
      c = a.intersection(b)
      return float(len(c)) / (len(a) + len(b) - len(c))
  ```
  La similarit√© ou l'intersection Jaccard sur l'union est d√©finie comme la taille de l'intersection divis√©e par la taille de l'union de deux ensembles. Prenons     l'exemple de deux phrases :</br>
  - Phrase 1 : AI is our friend and it has been friendly</br>
  - Phrase 2 : AI and humans have always been friendly</br>
  ![alt text](https://miro.medium.com/max/463/1*u2ZZPh5er5YbmOg7k-s0-A.png)</br>
  ==> Pour les deux phrases ci-dessus, nous obtenons une similarit√© Jaccard de 5/(5+3+2) = 0,5 qui est la taille de l'intersection de l'ensemble divis√©e par la   taille totale de l'ensemble.


 ## Pr√©sentation de la solution 
  Pratiquement toutes les t√¢ches de l'NLP sont maintenant r√©solues √† l'aide des Transformers et Cette solution est aussi bas√©e sur ces derniers.
  - Les transformateurs (Transformers) tels que BERT, RoBERTa, BART, CamemBERT etc. sont devenus l'√©tat de l'art en NLP
  - pr√©-entra√Æn√©s sur une grande quantit√© de textes
  - Un peu long √† entra√Æner
  - Peut √™tre utilis√© pour ces t√¢ches dans le cadre du NER (Reconnaissance d'entit√©s nomm√©es (Named-entity recognition)) ou de l'QA (Question Answering)
  - la solution bas√©e sur la QA a donn√© les meilleurs r√©sultats

   ![alt text](https://raw.githubusercontent.com/huggingface/transformers/master/docs/source/imgs/transformers_logo_name.png)</br>
   
   l'etat de l'art pour le traitement de langage naturel de pour Pytorch et TensorFlow 2.0 </br>
   ü§ó Transformers (anciennement connu sous le nom de pytorch-transformers et pytorch-pretrained-bert) fournit des architectures √† usage g√©n√©ral (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNet...) pour la compr√©hension du langage naturel (TALN / NLP) et la g√©n√©ration du langage naturel (NLG) avec plus de 32 mod√®les pr√©-entra√Æn√©s dans plus de 100 langues et une interop√©rabilit√© profonde entre TensorFlow 2.0 et PyTorch.</br>
   ü§ó Transformers fournit des milliers de mod√®les pr√©-entrain√©s pour effectuer des t√¢ches sur des textes telles que la classification, l'extraction d'informations, la r√©ponse √† des questions (QA), le r√©sum√©, la traduction, la g√©n√©ration de texte, etc. dans plus de 100 langues. </br>
   voici la [documentation](https://github.com/huggingface/transformers) des transformers sur leur repo github.</br>
   Ci-dessous, quelques exemples :
  - [Masked word completion with BERT](https://huggingface.co/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France)
  - [Name Entity Recognition with Electra](https://huggingface.co/dbmdz/electra-large-discriminator-finetuned-conll03-english?text=My+name+is+Sarah+and+I+live+in+London+city)
  - [Text generation with GPT-2](https://huggingface.co/gpt2?text=A+long+time+ago%2C+)
  - [Natural Langugage Inference with RoBERTa](https://huggingface.co/roberta-large-mnli?text=The+dog+was+lost.+Nobody+lost+any+animal)
  - [Summarization with BART](https://huggingface.co/facebook/bart-large-cnn?text=The+tower+is+324+metres+%281%2C063+ft%29+tall%2C+about+the+same+height+as+an+81-storey+building%2C+and+the+tallest+structure+in+Paris.+Its+base+is+square%2C+measuring+125+metres+%28410+ft%29+on+each+side.+During+its+construction%2C+the+Eiffel+Tower+surpassed+the+Washington+Monument+to+become+the+tallest+man-made+structure+in+the+world%2C+a+title+it+held+for+41+years+until+the+Chrysler+Building+in+New+York+City+was+finished+in+1930.+It+was+the+first+structure+to+reach+a+height+of+300+metres.+Due+to+the+addition+of+a+broadcasting+aerial+at+the+top+of+the+tower+in+1957%2C+it+is+now+taller+than+the+Chrysler+Building+by+5.2+metres+%2817+ft%29.+Excluding+transmitters%2C+the+Eiffel+Tower+is+the+second+tallest+free-standing+structure+in+France+after+the+Millau+Viaduct)
  - [Question answering with DistilBERT](https://huggingface.co/distilbert-base-uncased-distilled-squad?text=Which+name+is+also+used+to+describe+the+Amazon+rainforest+in+English%3F&context=The+Amazon+rainforest+%28Portuguese%3A+Floresta+Amaz%C3%B4nica+or+Amaz%C3%B4nia%3B+Spanish%3A+Selva+Amaz%C3%B3nica%2C+Amazon%C3%ADa+or+usually+Amazonia%3B+French%3A+For%C3%AAt+amazonienne%3B+Dutch%3A+Amazoneregenwoud%29%2C+also+known+in+English+as+Amazonia+or+the+Amazon+Jungle%2C+is+a+moist+broadleaf+forest+that+covers+most+of+the+Amazon+basin+of+South+America.+This+basin+encompasses+7%2C000%2C000+square+kilometres+%282%2C700%2C000+sq+mi%29%2C+of+which+5%2C500%2C000+square+kilometres+%282%2C100%2C000+sq+mi%29+are+covered+by+the+rainforest.+This+region+includes+territory+belonging+to+nine+nations.+The+majority+of+the+forest+is+contained+within+Brazil%2C+with+60%25+of+the+rainforest%2C+followed+by+Peru+with+13%25%2C+Colombia+with+10%25%2C+and+with+minor+amounts+in+Venezuela%2C+Ecuador%2C+Bolivia%2C+Guyana%2C+Suriname+and+French+Guiana.+States+or+departments+in+four+nations+contain+%22Amazonas%22+in+their+names.+The+Amazon+represents+over+half+of+the+planet%27s+remaining+rainforests%2C+and+comprises+the+largest+and+most+biodiverse+tract+of+tropical+rainforest+in+the+world%2C+with+an+estimated+390+billion+individual+trees+divided+into+16%2C000+species)
  - [Translation with T5](https://huggingface.co/t5-base?text=My+name+is+Wolfgang+and+I+live+in+Berlin)
   ### Question answering solution
   ![alt text](((https://github.com/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/Question%20answering%20setup.png?raw=true)
   ### Les mod√®les utilis√©s
   ### Tkenisation 
  **Qu'est-ce qu'un tokeniser ?**
  Un tokenizer re√ßoit un flux de caract√®res, le d√©compose en tokens individuels (g√©n√©ralement des mots individuels) et produit un flux de tokens. Par exemple, un   tokenizer d'espacement d√©compose le texte en tokens chaque fois qu'il voit un espacement. Il convertit le texte "Quick brown fox !" en termes ["Quick",  "brown", " fox !"].

 ![alt text](https://camo.githubusercontent.com/541a5e3521cf5b4c84c7ced36628841d8e66d58b7f2e51cded099a18c006d4e9/68747470733a2f2f68756767696e67666163652e636f2f6c616e64696e672f6173736574732f746f6b656e697a6572732f746f6b656e697a6572732d6c6f676f2e706e67)
  D√©velopp√© par huggingdace, propose une impl√©mentation des tokenizers les plus utilis√©s aujourd'hui, en mettant l'accent sur les performances et la polyvalence

  Extr√™mement rapide (√† la fois pour l'entra√Ænement et la tokenisation), gr√¢ce √† l'impl√©mentation de Rust. Il faut moins de 20 secondes pour tokeniser un Go de     texte sur l'unit√© centrale d'un serveur.
    - Facile √† utiliser, mais aussi extr√™mement polyvalent.
    - Con√ßu pour la recherche et la production.
    - La normalisation s'accompagne d'un suivi des alignements. Il est toujours possible d'obtenir la partie de la phrase originale qui correspond √† un jeton donn√©.
    - Effectue tout le pr√©traitement : Tronquer, Tamponner, ajouter les tokens sp√©ciaux dont votre mod√®le a besoin.
  
  
  
  
  
  ## Pour plus de d√©tails sur leur solution
Ils ont fait un discours sur leur solution lors du meetup ODS Paris: [YouTube link](https://www.youtube.com/watch?v=S7soN-y5WMg)<br />
La pr√©sentation de leur solution : [SlideShare link](https://www.slideshare.net/ArtsemZhyvalkouski/kaggle-tweet-sentiment-extraction-1st-place-solution)
