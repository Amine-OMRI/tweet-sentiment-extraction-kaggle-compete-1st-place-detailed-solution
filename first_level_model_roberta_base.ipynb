{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "first_level_model_roberta_base.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "etmylaX2Fb-j",
        "BrP6RBNKFqd9",
        "sPit1dlVHEIs"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a5a6a4853c647d5ab4e6f2e421c5b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea33407f48d84529a3cedce8ff4eb717",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86e84d68c27d472b8a7a0d57a6e22c43",
              "IPY_MODEL_a042d53d0d374fbba87c5126bc89edb1"
            ]
          }
        },
        "ea33407f48d84529a3cedce8ff4eb717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86e84d68c27d472b8a7a0d57a6e22c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fb2ad4da78f8468f8b5e0bacdfdb6a44",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67b4d3d78dee4cc39c7679217f24bca9"
          }
        },
        "a042d53d0d374fbba87c5126bc89edb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f7174c2b850b4684b80adf245f073187",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:49&lt;00:00, 11.6B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b40d221cc11e42abacb6d79d87b64e15"
          }
        },
        "fb2ad4da78f8468f8b5e0bacdfdb6a44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67b4d3d78dee4cc39c7679217f24bca9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7174c2b850b4684b80adf245f073187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b40d221cc11e42abacb6d79d87b64e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da3165f8a7bb4f1ba6002a3dd1839b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad49480862ce44e696e8ab8d60f4850c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd76536cf49f4f9e9dcca7b8c6c9c804",
              "IPY_MODEL_97fb8388273247cea7095fce3ccd4789"
            ]
          }
        },
        "ad49480862ce44e696e8ab8d60f4850c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd76536cf49f4f9e9dcca7b8c6c9c804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2fdf7552d81344c6b23bbd1e82f34b80",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 496313727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 496313727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6991e98fa56846f98fdf918568cafd89"
          }
        },
        "97fb8388273247cea7095fce3ccd4789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_79c265a4eeda434db25543b711583219",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 496M/496M [00:11&lt;00:00, 44.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5c53ebd65b84df79429c42c41a456f0"
          }
        },
        "2fdf7552d81344c6b23bbd1e82f34b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6991e98fa56846f98fdf918568cafd89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79c265a4eeda434db25543b711583219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5c53ebd65b84df79429c42c41a456f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "311e02e4ab79455f96a6a69d882cf44c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8fbea1556436405c82e84a37e15ee0c3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be8768226ed74c338a38576cc1639b61",
              "IPY_MODEL_f195b12fa5be48fca00f7c2056222609"
            ]
          }
        },
        "8fbea1556436405c82e84a37e15ee0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be8768226ed74c338a38576cc1639b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d40ab0eeaee6478aa0eec0bc7a5d883f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f1b9d41b21047ec94130b11e14337d6"
          }
        },
        "f195b12fa5be48fca00f7c2056222609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71e0c96ecb90475a9767aa517b1ff34d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [01:13&lt;00:00,  2.33it/s, jaccard=0.716]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83643d9c675e43d0adf21bb7e7bb4bd2"
          }
        },
        "d40ab0eeaee6478aa0eec0bc7a5d883f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f1b9d41b21047ec94130b11e14337d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71e0c96ecb90475a9767aa517b1ff34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83643d9c675e43d0adf21bb7e7bb4bd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e67e719ed34a4b07a0591d376313ceeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19299dbe1cb457fb61a2bd60a044123",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2037ef67ba3407e9883a32f1a9ae9e9",
              "IPY_MODEL_ef8f28882f6a4689ac35c8b7dc69dc8a"
            ]
          }
        },
        "a19299dbe1cb457fb61a2bd60a044123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2037ef67ba3407e9883a32f1a9ae9e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80baee64c83f4c05b13026fdd6c3928f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95fe9696a2b74d7ea8c85a71ed0ea401"
          }
        },
        "ef8f28882f6a4689ac35c8b7dc69dc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1dd0410fc9704a9caa064a47ee8936bc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [00:29&lt;00:00,  5.74it/s, jaccard=0.711]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba08cfa1331d47489b03c860ed273728"
          }
        },
        "80baee64c83f4c05b13026fdd6c3928f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95fe9696a2b74d7ea8c85a71ed0ea401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1dd0410fc9704a9caa064a47ee8936bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba08cfa1331d47489b03c860ed273728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c649b48206e8461ab986a31eff41663d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_de48ecab2e9a43a2984091f852f12b25",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d9ccaad734f8466f9c609ba4c19ae320",
              "IPY_MODEL_79deeeeeaa964a06bc9f3ad5462ca312"
            ]
          }
        },
        "de48ecab2e9a43a2984091f852f12b25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9ccaad734f8466f9c609ba4c19ae320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1790d4b810e6479fb0986a33c7d6d89d",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e0abbd9b372444a9ecb25a616239688"
          }
        },
        "79deeeeeaa964a06bc9f3ad5462ca312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8388209c0eea421a864e786bf0e88db2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [01:10&lt;00:00,  2.42it/s, jaccard=0.716]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e28785f8a2c4d26b9dedb98f993c35c"
          }
        },
        "1790d4b810e6479fb0986a33c7d6d89d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e0abbd9b372444a9ecb25a616239688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8388209c0eea421a864e786bf0e88db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e28785f8a2c4d26b9dedb98f993c35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ae593eea4ea4bf29ccb9207bf39a987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a8fc24b90b944d1ba355ecbb00bfa58",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc414fdaee294c9db8c677b27a81707f",
              "IPY_MODEL_b53ea0fc5b7e42f6961cc98b3b257128"
            ]
          }
        },
        "0a8fc24b90b944d1ba355ecbb00bfa58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc414fdaee294c9db8c677b27a81707f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9f73581c6f304a2381a54c3aded4fb52",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad0874d836e3493cb84f49eb88448e72"
          }
        },
        "b53ea0fc5b7e42f6961cc98b3b257128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86d93fca9e4a417187f9512e505ccf8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [00:29&lt;00:00,  5.74it/s, jaccard=0.717]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0c571a2eff364548b85ad2d1a1ccc4cd"
          }
        },
        "9f73581c6f304a2381a54c3aded4fb52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad0874d836e3493cb84f49eb88448e72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d93fca9e4a417187f9512e505ccf8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0c571a2eff364548b85ad2d1a1ccc4cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e34c097bd1a8400cab7a702b06a9143c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1eb203e1db144517ae6bf803be68d76b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c555a66b7f44451e82c325428f234bc4",
              "IPY_MODEL_5ac0aaff737641eca49308824bb94603"
            ]
          }
        },
        "1eb203e1db144517ae6bf803be68d76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c555a66b7f44451e82c325428f234bc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ec1aa1825834a7c96fddcafac8ee72b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 172,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 172,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae9af73a41084fc2bbf736f4afd9f5dd"
          }
        },
        "5ac0aaff737641eca49308824bb94603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_24ea29ea46fe45f5876e16e9bbc5daca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 172/172 [29:37&lt;00:00, 10.33s/it, jaccard=0.711]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_806bf2cfe63e4b909522ad2c6b6f6d8c"
          }
        },
        "1ec1aa1825834a7c96fddcafac8ee72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae9af73a41084fc2bbf736f4afd9f5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "24ea29ea46fe45f5876e16e9bbc5daca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "806bf2cfe63e4b909522ad2c6b6f6d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed2e8946b1004d4ca98dfadfa33115f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_983766538d1c4e94b5c1599a68ec02d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_50c37752036240f098ea6979b4f01416",
              "IPY_MODEL_1bcc8d683c504de2a1d2ac53c49b84a0"
            ]
          }
        },
        "983766538d1c4e94b5c1599a68ec02d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50c37752036240f098ea6979b4f01416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b0d52f94b944e74b65b3bbd854e58ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8df86989d6fe4dcdac94e453f03ebc3e"
          }
        },
        "1bcc8d683c504de2a1d2ac53c49b84a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d1ad2c4487d84b8c94a19ce2e53a393a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:00&lt;00:00, 2.33kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41678fc6278e4acc9446a04a5d936445"
          }
        },
        "1b0d52f94b944e74b65b3bbd854e58ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8df86989d6fe4dcdac94e453f03ebc3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1ad2c4487d84b8c94a19ce2e53a393a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41678fc6278e4acc9446a04a5d936445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23007c4d13ba48839736aaa552a33750": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95f23dc7fd694a1aaf802da9e4f697aa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7faab71086174139b707fb5332ea2906",
              "IPY_MODEL_9cf511a065854bfeb286a3ab5d2be7ab"
            ]
          }
        },
        "95f23dc7fd694a1aaf802da9e4f697aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7faab71086174139b707fb5332ea2906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_997ea70e664b4d2aa193ba8d6f3d5569",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 496313727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 496313727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ced557f1d8244f6abaabf8e2011dab49"
          }
        },
        "9cf511a065854bfeb286a3ab5d2be7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cac3e239cfa34eb3b7d6824b92049515",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 496M/496M [00:07&lt;00:00, 67.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_342d70f33ebb469c9f18a9f3cfefb843"
          }
        },
        "997ea70e664b4d2aa193ba8d6f3d5569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ced557f1d8244f6abaabf8e2011dab49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cac3e239cfa34eb3b7d6824b92049515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "342d70f33ebb469c9f18a9f3cfefb843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1023bec17f3048f2994587ab2ca923ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4f836dfd3d614d37a6e12828b9e26dea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0288fee9c3674c198d5e21621aac5273",
              "IPY_MODEL_56eabcc0b14d4fa6a0b5b2323b3a27a5"
            ]
          }
        },
        "4f836dfd3d614d37a6e12828b9e26dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0288fee9c3674c198d5e21621aac5273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c97ceae839b48029d9f89ed8021d1a2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 571,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 571,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0732c192a784c53b86a68f3a16254a6"
          }
        },
        "56eabcc0b14d4fa6a0b5b2323b3a27a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_556a4510c3234b38a87c3743b8df9c97",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 571/571 [00:08&lt;00:00, 69.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec4bd0f01be341e88fc41673825fbaca"
          }
        },
        "9c97ceae839b48029d9f89ed8021d1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0732c192a784c53b86a68f3a16254a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "556a4510c3234b38a87c3743b8df9c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec4bd0f01be341e88fc41673825fbaca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d6a2ea3e1454d28bd5a9760e19a4ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6cad7320919248cab53cba7a3eb47225",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_18287140c5324a7e85b01460e5e889f5",
              "IPY_MODEL_fb4870326d1545dcaab261730965bc99"
            ]
          }
        },
        "6cad7320919248cab53cba7a3eb47225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "18287140c5324a7e85b01460e5e889f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11cd33748ed9445c921d533c922a2128",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 496313727,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 496313727,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ae80b3c967142b1b773b080ed310264"
          }
        },
        "fb4870326d1545dcaab261730965bc99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31bf737378c04156a4ced60a3b781572",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 496M/496M [00:07&lt;00:00, 62.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8344b11a1c42484883bb312ebfa677c6"
          }
        },
        "11cd33748ed9445c921d533c922a2128": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ae80b3c967142b1b773b080ed310264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31bf737378c04156a4ced60a3b781572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8344b11a1c42484883bb312ebfa677c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/first_level_model_roberta_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOeAFVsEAUTq"
      },
      "source": [
        "La solution a Ã©tÃ© implÃ©mentÃ©e en utilisant une version antÃ©rieure des bibliothÃ¨ques \n",
        "\n",
        "1.   tokenizers==0.7.0\n",
        "2.   transformers==2.9.0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mk0dtujy2tO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91641d8b-38a9-42a2-ac40-5fb256387450"
      },
      "source": [
        "!pip install tokenizers==0.7.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8MB 9.4MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnBIJXJjdySa"
      },
      "source": [
        "!pip install transformers==2.9.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhTiLFp1dzyt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a361850c-0d28-4758-89f8-6371287de6dc"
      },
      "source": [
        "!pip install torchcontrib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchcontrib\n",
            "  Downloading https://files.pythonhosted.org/packages/72/36/45d475035ab35353911e72a03c1c1210eba63b71e5a6917a9e78a046aa10/torchcontrib-0.0.2.tar.gz\n",
            "Building wheels for collected packages: torchcontrib\n",
            "  Building wheel for torchcontrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchcontrib: filename=torchcontrib-0.0.2-cp36-none-any.whl size=7531 sha256=b3b8c0c03c872b46b148aa2d40deaa5f449e0aa54839f3c66578743e2a9e6e8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/06/7b/a5f5920bbf4f12a2c927e438fac17d4cd9560f8336b00e9a99\n",
            "Successfully built torchcontrib\n",
            "Installing collected packages: torchcontrib\n",
            "Successfully installed torchcontrib-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Cxkuo8DM_r"
      },
      "source": [
        "[torchcontrib](https://github.com/pytorch/contrib) librairie contient des implÃ©mentations d'idÃ©es issues de rÃ©cents articles sur l'apprentissage machine, ici elle a Ã©tÃ© utilisÃ©e pour rÃ©aliser #Stochastic Weight Averaging (SWA) Que je vous prÃ©senteai ultÃ©rieurement dans le Notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVg2eB1FOZqE",
        "outputId": "be741b19-d382-4daf-d502-f7b8057baf6b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmUw-vAr6c_6"
      },
      "source": [
        "#Pour Commencer\n",
        "**Ce notebook reprÃ©sente l'un des modÃ¨les de premier niveau rÃ©alisÃ© par [Heartkilla](https://www.kaggle.com/aruchomu) : Artsem Zhyvalkouski le code source est sous `src/1st_level/roberta_base/` sur le [repo git](https://github.com/heartkilla/kaggle_tweet/tree/master/src/1st_level/roberta_base) oÃ¹ ils ont mis le code de leur solution**\n",
        "\n",
        "---\n",
        "Pour faire tourner la solution de la compÃ©tition, j'ai chargÃ© quelques fichiers sur mon Gdrive qui sont : \n",
        "\n",
        "\n",
        "*   Les fichiers de donnÃ©es :</br>\n",
        "    TRAINING_FILE = /content/drive/MyDrive/very_final/data/**train_folds.csv**</br>\n",
        "    TEST_FILE = /content/drive/MyDrive/very_final/data/**test.csv**</br>\n",
        " \n",
        "\n",
        "*   Les fichiers de configuration du tokeniser :</br>\n",
        "\n",
        "    /content/drive/MyDrive/very_final/roberta_tokenizer/**vocab.json**</br>\n",
        "    /content/drive/MyDrive/very_final/roberta_tokenizer/**merges.txt**</br>\n",
        "\n",
        "J'ai Ã©galement **importer** les fichiers de **code** directement sur **Colab** en tant que fichiers d'entrÃ©e afin de pouvoir les importer et les utiliser, en mÃªme temps que j'ai copiÃ© leur code afin de pouvoir le commenter et remplir l'objectif de travail demandÃ©.\n",
        "* `config.py`\n",
        "* `dataset.py`\n",
        "* `engine.py`\n",
        "* `evaluate.py`\n",
        "* `infer.py`\n",
        "* `models.py`\n",
        "* `train.py`\n",
        "* `utils.py`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jro8AaTYD78D"
      },
      "source": [
        "#config.py\n",
        "\n",
        "---\n",
        "\n",
        "Le fichier **config.py** (configuration) contient les paramÃ¨tres et les rÃ©glages initiaux des modules et des mÃ©thodes de la solution. L'importation du fichier config.py permet d'utiliser les variables et les fonctions du fichier config.py dans les autres fichiers de la solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljAHrlvLDKkS"
      },
      "source": [
        "import tokenizers\n",
        "\n",
        "# Paths\n",
        "\n",
        "TOKENIZER_PATH = '/content/drive/MyDrive/very_final/roberta_tokenizer'\n",
        "TRAINING_FILE = '/content/drive/MyDrive/very_final/data/train_folds.csv'\n",
        "TEST_FILE = '/content/drive/MyDrive/very_final/data/test.csv'\n",
        "SUB_FILE = '/content/drive/MyDrive/very_final/data/sample_submission.csv'\n",
        "MODEL_SAVE_PATH = '/content/drive/MyDrive/very_final/roberta_base/model_save'\n",
        "TRAINED_MODEL_PATH = '/content/drive/MyDrive/very_final/roberta_base/model_save'\n",
        "\n",
        "# Model config\n",
        "##    Le tout premier modÃ¨le qui a Ã©tÃ© utilisÃ© dans les modÃ¨les de 1er niveau\n",
        "##    est roberta-base pour le modÃ¨le d'AQ par deepset.ai (Squad pretrained \n",
        "##    weights)) prÃ©-entrainÃ© sur la base SQuAD 2.0\n",
        "MODEL_CONFIG = 'deepset/roberta-base-squad2'\n",
        "#---------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# Model params\n",
        "# Global Seed to initialize the pseudo-random number generator\n",
        "# Pour assurer d'avoir les memes resultats d'une lancÃ©e a une autre\n",
        "SEED = 25\n",
        "# Nombre des folds pour l'entrainement par fold\n",
        "N_FOLDS = 5\n",
        "# Nombre d'EPOCHS de lentrainment des modÃ©les \n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 4e-5\n",
        "PATIENCE = None\n",
        "EARLY_STOPPING_DELTA = None\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "MAX_LEN = 96  # actually = 86\n",
        "\n",
        "## ExpliquÃ© ci-dessous\n",
        "TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
        "    vocab_file=f'{TOKENIZER_PATH}/vocab.json',\n",
        "    merges_file=f'{TOKENIZER_PATH}/merges.txt',\n",
        "    lowercase=True,\n",
        "    add_prefix_space=True)\n",
        "# 768 est la dimension des Embeddings \n",
        "HIDDEN_SIZE = 768\n",
        "N_LAST_HIDDEN = 12\n",
        "HIGH_DROPOUT = 0.5\n",
        "SOFT_ALPHA = 0.6\n",
        "WARMUP_RATIO = 0.25\n",
        "WEIGHT_DECAY = 0.001\n",
        "#Stochastic Weight Averaging (SWA) :\n",
        "# les paramÃ©tres de l'optimiser \n",
        "USE_SWA = False\n",
        "SWA_RATIO = 0.9\n",
        "SWA_FREQ = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R42twUwALMX7"
      },
      "source": [
        "Source : **huggingface tokenizers**\n",
        "Fournit une implÃ©mentation des tokenizers les plus utilisÃ©s aujourd'hui, en mettant l'accent sur les performances et la polyvalence.\n",
        "UtilisÃ© pour :\n",
        "* EntraÃ®ner de nouveaux vocabulaires et tokeniser Ã  l'aide de 4 tokenizers pre-made (Bert WordPiece et les 3 versions les plus courantes de BPE).\n",
        "* ExtrÃªmement rapide (tant pour l'entraÃ®nement que pour la tokenisation), grÃ¢ce Ã  l'implÃ©mentation de Rust. Il le faut moins de 20 secondes pour convertir un Go de texte en tokens sur le processeur d'un serveur.\n",
        "* Facile Ã  utiliser, mais aussi extrÃªmement polyvalent.\n",
        "* ConÃ§u pour la recherche et la production.\n",
        "* La normalisation s'accompagne d'un suivi des alignements. Il est toujours possible d'obtenir la partie de la phrase originale qui correspond Ã  un jeton donnÃ©.\n",
        "* Effectue tout le prÃ©traitement : Tronquer, Pad, ajouter les tokens spÃ©ciaux dont votre modÃ¨le a besoin.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lulkLxMkWKEh"
      },
      "source": [
        "\n",
        "Le tokenizer de RoBERTa est basÃ© sur le tokenizer GPT-2, les fichiers vocab/merges sont constituÃ©s lors de l'entrainement du BBPE [(Byte-level Byte-Pair-Encoding)](https://arxiv.org/pdf/1909.03341.pdf) et utilisÃ©s pour encoder les sentences, le tokenizer tokenize d'abord en se basant sur le fichier **merges.txt**.</br>\n",
        "\n",
        "Voici un exemple : sentence = \"What's up with the tokenizer?\"</br>\n",
        "\n",
        "```\n",
        "['What', \"'s\", 'Ä up', 'Ä with', 'Ä the', 'Ä token', 'izer', '?']</br>\n",
        "\n",
        "```\n",
        "le caractÃ¨re ```Ä ``` signifie un espace</br>\n",
        "\n",
        "\n",
        "Et ensuite, selon les valeurs dans le fichier **vocab.json**, ces tokens sont alors remplacÃ©s par leurs indices :</br>\n",
        "```\n",
        "[   'What',     \"'s\",    'Ä up',  'Ä with',   'Ä the', 'Ä token',   'izer',      '?']\n",
        "---- becomes ----\n",
        "[     2061,      338,      510,      351,      262,    11241,     7509,       30]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtM5UFGcEAxb"
      },
      "source": [
        "#dataset.py\n",
        "\n",
        "---\n",
        "le fichier dataset.py pour assurer que toutes les donnÃ©es des tweets soient stockÃ©es au mÃªme endroit et soient utilisÃ©es pour charger les donnÃ©es avec le **dataloader** par la suite.\n",
        "\n",
        "* Il contient Ã©galement une implÃ©mentation d'un  Map-style datasets (the **TweetDataset** class)  qui implÃ©mente les mÃ©thodes **__getitem__()** et **__len__()** et qui reprÃ©sente toutes les propriÃ©tÃ©s : les ids des tweets, les offsets, orig_start/orig_end, start_labels/end_labels, mask, token_type_ids, ...\n",
        "\n",
        "* Egalement une implÃ©mentation de la mÃ©thode **process_data** qui traitera toutes ces propriÃ©tÃ©s et les extraira Ã  partir des donnÃ©es d'entrÃ©e (tweets, selected_text, sentiment) en utilisant le tokeniser crÃ©e dans le fichier config.py.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocl0o4iYUoaa"
      },
      "source": [
        "Voyons voir a quoi ressemblent les donnÃ©es d'entrainement.</br>\n",
        "##DÃ©boguage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "AAihgxQaUp0e",
        "outputId": "1730321e-10ec-4dc1-f9f6-9fde3322a8b3"
      },
      "source": [
        "import config\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(config.TRAINING_FILE)\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d0c214ad3a</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7d093817af</td>\n",
              "      <td>LOL. You know me. I aim to please.</td>\n",
              "      <td>I aim to please.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21eacf7e58</td>\n",
              "      <td>Was at Ruby Skye last night as well! Superb s...</td>\n",
              "      <td>Superb set by Steve.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d0f94d66ab</td>\n",
              "      <td>does not like ups much today...</td>\n",
              "      <td>does not like</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a025e21634</td>\n",
              "      <td>Nothing like In `n` Out and a LOST marathon af...</td>\n",
              "      <td>long day of work.</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... kfold\n",
              "0  d0c214ad3a  ...     0\n",
              "1  7d093817af  ...     0\n",
              "2  21eacf7e58  ...     0\n",
              "3  d0f94d66ab  ...     0\n",
              "4  a025e21634  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvUeziUUXrR6"
      },
      "source": [
        "* **===>  `selected_text` est la valeur Ã  prÃ©dire**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3zseDwveZ9Z",
        "outputId": "fc6583f9-79d4-47cb-dcf9-2d18d730d57c"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27480, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aArwkeaidCEs",
        "outputId": "753bb562-89ca-499b-f48b-0e1eed0985c0"
      },
      "source": [
        "## dÃ©boguer le code et travailler avec le troisiÃ¨me tweet\n",
        "tweet = df_train.text.values[3]\n",
        "selected_text = df_train.selected_text[3]\n",
        "tweet = ' ' + ' '.join(str(tweet).split())\n",
        "selected_text = ' ' + ' '.join(str(selected_text).split())\n",
        "tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like ups much today...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lurbGoDRlWTg",
        "outputId": "78414d10-742f-4be9-c0eb-99b887924dfb"
      },
      "source": [
        "selected_text "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8v8WVUmMUDXW",
        "outputId": "1d3dd874-a829-499e-826d-388eb0ae3e74"
      },
      "source": [
        "selected_text[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhAPoBb1eJ4_",
        "outputId": "f88236c1-061c-41d2-a17f-536741b6b77a"
      },
      "source": [
        "## Ne comptez pas le premier espace provenant du \" ' '.join(), \n",
        "## donc nous faisons -1 pour obtenir la vraie longueur\n",
        "len_sel_text = len(selected_text) - 1\n",
        "## rÃ©cpÃ¨rerl'idice de dÃ©but et de fin de selected_text\n",
        "idx_0 = None\n",
        "idx_1 = None\n",
        "## i : indice du caractÃ©re, e : c'est le caractÃ©re SI 'e' est le caractÃ©re \n",
        "## d'indice 1 (just aprÃ© lespace qu'on a rajoutÃ©)\n",
        "for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
        "  if ' ' + tweet[ind:ind + len_sel_text] == selected_text:\n",
        "    idx_0 = ind\n",
        "    idx_1 = ind + len_sel_text - 1\n",
        "    break\n",
        "print('l\\'indexe de dÃ©but:',idx_0,'l\\'indexe de fin:', idx_1, 'du text sÃ©lÃ©ctionnÃ© qui reprÃ©sente le target')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "l'indexe de dÃ©but: 1 l'indexe de fin: 13 du text sÃ©lÃ©ctionnÃ© qui reprÃ©sente le target\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo9w6FBTzzGV"
      },
      "source": [
        "* Assigner `1` Ã  chaque caractÃ¨re du tweet s'il fait partie du selected_text sinon `0`, comme dans l'exemple ci-dessus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8TAUopaxQwT",
        "outputId": "f42a04f0-ffb4-4b24-93ed-00a73fbe202d"
      },
      "source": [
        "## Attribuez 1 pour chaque caractÃ¨re dans sel_text et des zÃ©ros aux autres caractÃ¨res\n",
        "char_targets = [0] * len(tweet)\n",
        "if idx_0 is not None and idx_1 is not None:\n",
        "  for ct in range(idx_0, idx_1 + 1):\n",
        "    char_targets[ct] = 1\n",
        "char_targets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HSAaSoETzWlq",
        "outputId": "ebd72489-f65f-4093-8fdf-0ec31ea1af15"
      },
      "source": [
        "tweet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not like ups much today...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKrcw3qNzELF",
        "outputId": "a9663b15-e4db-4ff2-a2cb-34131a4e9742"
      },
      "source": [
        "## Utiliser le tokenizer crÃ©Ã© sur le fichier config.py pour tokeniser le tweet\n",
        "tokenized_tweet = TOKENIZER.encode(tweet)\n",
        "input_ids_original = tokenized_tweet.ids\n",
        "input_ids_original\n",
        "## Selon les valeurs dans le fichier vocab.json, ces tokens sont alors remplacÃ©s par leurs indices :"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[473, 45, 101, 12744, 203, 452, 734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKtJb3Hk0t4F"
      },
      "source": [
        "* Une **nouvelle mÃ©thode** pour les tokenizers : **`tokenize_with_offsets`**. En plus de renvoyer les tokens, elle renvoie les intervalles dans le texte original auxquels les tokens correspondent, cette mÃ©thode nous permet de rÃ©cupÃ©rer le token ou le mot qui correspond a un **id** donnÃ©."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIrwQTaSztnP",
        "outputId": "fc5425b2-7bdf-4834-bfab-0fa46be539a2"
      },
      "source": [
        "tweet_offsets = tokenized_tweet.offsets\n",
        "tweet_offsets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 5), (5, 9), (9, 14), (14, 18), (18, 23), (23, 29), (29, 32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7nI3hgd0PAB"
      },
      "source": [
        "* RÃ©cupÃ©rer le texte (les tokens) original en se basant sur les offsets (leur intervalle) : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ar3yFd101EBi",
        "outputId": "5d41d9a9-6f67-4274-c44c-520c6a62d163"
      },
      "source": [
        "tweet[tweet_offsets[0][0]:tweet_offsets[0][1]] + tweet[tweet_offsets[1][0]:tweet_offsets[1][1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' does not'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjfwO6vQ45Pj"
      },
      "source": [
        "* Ce code rÃ©cupÃ¨re les **target_ids** qui sont les id des tokens cibles qui reprÃ©sentent le texte sÃ©lectionnÃ© (chaque caractÃ¨re est reprÃ©sentÃ© (codÃ©) par le chiffre `\"1\"`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUOFWQ1k1GWR",
        "outputId": "5c5225ed-5c77-4fb7-87ce-6de69be4d59d"
      },
      "source": [
        "target_ids = []\n",
        "for i, (offset_0, offset_1) in enumerate(tweet_offsets):\n",
        "  print(i,'offset (',offset_0,',', offset_1,')')\n",
        "  print(char_targets[offset_0:offset_1])\n",
        "  print(sum(char_targets[offset_0:offset_1]))\n",
        "  if sum(char_targets[offset_0:offset_1]) > 0:\n",
        "    target_ids.append(i)\n",
        "print(\"----------------------------------------\")\n",
        "print('target_ids : ',target_ids)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 offset ( 0 , 5 )\n",
            "[0, 1, 1, 1, 1]\n",
            "4\n",
            "1 offset ( 5 , 9 )\n",
            "[1, 1, 1, 1]\n",
            "4\n",
            "2 offset ( 9 , 14 )\n",
            "[1, 1, 1, 1, 1]\n",
            "5\n",
            "3 offset ( 14 , 18 )\n",
            "[0, 0, 0, 0]\n",
            "0\n",
            "4 offset ( 18 , 23 )\n",
            "[0, 0, 0, 0, 0]\n",
            "0\n",
            "5 offset ( 23 , 29 )\n",
            "[0, 0, 0, 0, 0, 0]\n",
            "0\n",
            "6 offset ( 29 , 32 )\n",
            "[0, 0, 0]\n",
            "0\n",
            "----------------------------------------\n",
            "target_ids :  [0, 1, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmpceIfOAIwz"
      },
      "source": [
        "* **Soft Jaccard labels :**</br>\n",
        "Custom loss `Jaccard-based Soft Labels`: Ã‰tant donnÃ© que la Cross Entropy n'optimise pas directement l'indice de Jaccard, **Heartkilla** a essayÃ© diffÃ©rentes fonctions de Loss pour pÃ©naliser davantage les prÃ©dictions lointaines que les prÃ©dictions proches, il a donc trouvÃ© une Loss personnalisÃ©e en calculant l'indice de Jaccard au niveau du token. Il a ensuite utilisÃ© ces nouveaux labels cibles et a optimisÃ© la divergence.</br> \n",
        "Alpha c'est un paramÃ¨tre permettant d'Ã©quilibrer l'Ã©tiquetage habituel basÃ© sur la Cross Entropy et l'indice de Jaccard </br>\n",
        "<img src = 'https://camo.githubusercontent.com/3925753ce615ec71960dad457401aedefc7b611a2b11a3cb86eb060772dce880/68747470733a2f2f7777772e676f6f676c65617069732e636f6d2f646f776e6c6f61642f73746f726167652f76312f622f6b6167676c652d757365722d636f6e74656e742f6f2f696e626f7825324632303030353435253246393334316265646532383236336263663065396262323539616337393033333825324653637265656e25323053686f74253230323032302d30352d3330253230617425323031372e33312e32322e706e673f67656e65726174696f6e3d3135393234303530323835353638343226616c743d6d65646961'></br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5aOqwjyBi6m"
      },
      "source": [
        "## La mesure d'Ã©valuation qui a Ã©tÃ© mentionnÃ©e sur le prÃ©sent de la competition \n",
        "def jaccard_array(a, b):\n",
        "    \"\"\"Calculates Jaccard on arrays.\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCHfYQVO51D_"
      },
      "source": [
        "import numpy as np\n",
        "targets_start = target_ids[0]\n",
        "targets_end = target_ids[-1]\n",
        "n = len(input_ids_original)\n",
        "## id des tokens dans le tweet\n",
        "sentence = np.arange(n)\n",
        "## id  des tokens qui forment le label (le selected_text)\n",
        "answer = sentence[targets_start:targets_end + 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR-6ZPNr6FmR",
        "outputId": "8b115a18-fc34-40b7-86d4-d2f58d423895"
      },
      "source": [
        "sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ecJSNNGiewI"
      },
      "source": [
        "* Le tableaux retournÃ© a ce niveau reprÃ©sente les indices du target (text sÃ©lÃ©ctionnÃ©) dans la sentence orginal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBehZdAO6I1s",
        "outputId": "996ef573-850b-4627-8d59-764093084b34"
      },
      "source": [
        "answer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDUUnvWKjKQb"
      },
      "source": [
        "* C'est bien la target selected_text: '` does not like` '"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alRiyywnGFXw",
        "outputId": "6124bedb-7309-48e1-ae85-7e92bdb9330f"
      },
      "source": [
        "sentence[targets_start:targets_end + 1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QKyPhqaB-sl",
        "outputId": "7885a8f4-43c8-4722-fc4b-360fc35563e1"
      },
      "source": [
        "for i in range(targets_end + 1):\n",
        "  ## calculate the jaccard indexe\n",
        "  ## answer = array([0, 1, 2]) qui est les indice du atrget selected_text: 'does not like'\n",
        "  jac = jaccard_array(answer, sentence[i:targets_end + 1])\n",
        "  print(\"a=\"+str(answer),\"b=\"+str(sentence[i:targets_end + 1]),\"==> jaccard indexe\",jac)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a=[0 1 2] b=[0 1 2] ==> jaccard indexe 1.0\n",
            "a=[0 1 2] b=[1 2] ==> jaccard indexe 0.6666666666666666\n",
            "a=[0 1 2] b=[2] ==> jaccard indexe 0.3333333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijAn528-kDk6"
      },
      "source": [
        "* jaccard indexe du token (0,2) =1.0 puisque le texte correspondant Ã  l'index de **(0)** jusqu'Ã  la target_end **(2)** dans la phrase originale (`' does not like ups much today...'`) est exactement le taget qui est `'does not like'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtoxHWZvBmY9",
        "outputId": "4c456098-050a-46bd-ed2b-2891b3cf533e"
      },
      "source": [
        "start_labels = np.zeros(n)\n",
        "print(str(start_labels))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "for i in range(targets_end + 1):\n",
        "    ## calculate the jaccard indexe \n",
        "    jac = jaccard_array(answer, sentence[i:targets_end + 1])\n",
        "    print('jaccard indexe du tokens dans lintervalle ['+ str(i) +':'+ str(targets_end)+'] = '+ str(jac))\n",
        "    ## le carrÃ© ici est utile pour s'assurer que nous n'obtenons pas de valeurs nÃ©gatives\n",
        "    start_labels[i] = jac + jac ** 2\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(str(start_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------------------\n",
            "jaccard indexe du tokens dans lintervalle [0:2] = 1.0\n",
            "jaccard indexe du tokens dans lintervalle [1:2] = 0.6666666666666666\n",
            "jaccard indexe du tokens dans lintervalle [2:2] = 0.3333333333333333\n",
            "-------------------------------------------------------------\n",
            "[2.         1.11111111 0.44444444 0.         0.         0.\n",
            " 0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMbCpBG5bTeX"
      },
      "source": [
        "* Ã€ ce niveau, nous appliquons simplement la formule des **Jaccard-based Soft Labels** mentionnÃ©e ci-dessus pour crÃ©er nos labels.</br>\n",
        "* **=========>**   On peut remarquer que le score jaccard a Ã©tÃ© **pÃ©nalisÃ©** pour les cas oÃ¹ les index ne correspondent pas au selected_text(notre cible)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKomTTSabjVx",
        "outputId": "c6bd7eb5-bfe9-4d20-9eac-a05986c7aeb2"
      },
      "source": [
        "## Alpha est un paramÃ¨tre d'Ã©quilibre entre la CE (cross-enthropy) et le Jaccard-based labeling\n",
        "start_labels = (1 - config.SOFT_ALPHA) * start_labels / start_labels.sum()\n",
        "print(start_labels)\n",
        "start_labels[targets_start] += config.SOFT_ALPHA\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(start_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.33 0.05 0.02 0.   0.   0.   0.  ]\n",
            "-------------------------------------------------------------\n",
            "[0.93 0.05 0.02 0.   0.   0.   0.  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FCF7h7bhIAW"
      },
      "source": [
        "* **De la mÃªme maniÃ¨re, les labels de fin (`targets_end`) ont Ã©tÃ© codÃ©s**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_7PFUJSezg8",
        "outputId": "cd098baf-8d27-4e10-e00d-407f9ac9efa6"
      },
      "source": [
        "end_labels = np.zeros(n)\n",
        "print(str(end_labels))\n",
        "print(\"-------------------------------------------------------------\")\n",
        "for i in range(targets_start, n):\n",
        "  jac = jaccard_array(answer, sentence[targets_start:i + 1])\n",
        "  end_labels[i] = jac + jac ** 2\n",
        "  print('jaccard indexe du tokens dans lintervalle ['+ str(i) +':'+ str(targets_end)+'] = '+ str(jac))\n",
        "\n",
        "end_labels = (1 - config.SOFT_ALPHA) * end_labels / end_labels.sum()\n",
        "end_labels[targets_end] += config.SOFT_ALPHA\n",
        "print(\"-------------------------------------------------------------\")\n",
        "print(end_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0.]\n",
            "-------------------------------------------------------------\n",
            "jaccard indexe du tokens dans lintervalle [0:2] = 0.3333333333333333\n",
            "jaccard indexe du tokens dans lintervalle [1:2] = 0.6666666666666666\n",
            "jaccard indexe du tokens dans lintervalle [2:2] = 1.0\n",
            "jaccard indexe du tokens dans lintervalle [3:2] = 0.75\n",
            "jaccard indexe du tokens dans lintervalle [4:2] = 0.6\n",
            "jaccard indexe du tokens dans lintervalle [5:2] = 0.5\n",
            "jaccard indexe du tokens dans lintervalle [6:2] = 0.42857142857142855\n",
            "-------------------------------------------------------------\n",
            "[0.02472467 0.06181167 0.711261   0.07301503 0.05340528 0.04172287\n",
            " 0.03405949]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk_Yem83fpJV",
        "outputId": "196bc1b5-20bb-4234-dc4c-eac4b9ea5018"
      },
      "source": [
        "## Les nouveaux labels qui seront utilisÃ©s pour amÃ©liorer et garantir que le modÃ¨le apprendra correctement\n",
        "start_labels = [0, 0, 0, 0] + list(start_labels) + [0]\n",
        "end_labels = [0, 0, 0, 0] + list(end_labels) + [0]\n",
        "print(\"Nouveaux start_labels: \"+str(start_labels)+'\\nNouveaux end_labels: '+\n",
        "      str(end_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nouveaux start_labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.9299999999999999, 0.05000000000000002, 0.020000000000000004, 0.0, 0.0, 0.0, 0.0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Nouveaux end_labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.024724666086919502, 0.06181166521729876, 0.7112609973911377, 0.07301502953793415, 0.05340527874774612, 0.04172287402167666, 0.03405948899728707, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBysJpqttFy6"
      },
      "source": [
        "* Pour rÃ©soudre la compÃ©tition, ils ont dÃ©jÃ  utilisÃ© le concept de **Question Answering `QA`** et le modÃ¨le `Roberta` a Ã©tÃ© utilisÃ© pour cela et il a eu en entrÃ© la concatÃ©nation de listes d'identifiants de tweet et de sentiments **encodÃ©s**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n7MaNnZ9jN8L",
        "outputId": "4e57104e-4b92-4fc6-aa78-da9c49aebf8b"
      },
      "source": [
        "sentiment = df_train.sentiment[3]\n",
        "sentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCCFPOD4rgEG",
        "outputId": "5bd5aa61-90b3-47a3-d588-1beabbb61187"
      },
      "source": [
        "## Encoder le feature de sentiment\n",
        "sentiment_id = {'positive': 1313,\n",
        "                'negative': 2430,\n",
        "                'neutral': 7974}\n",
        "sentiment_id[sentiment]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2430"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuSj33-ortNX",
        "outputId": "d3ed67d8-6bc5-4d60-af3a-18f1dfc4ab4a"
      },
      "source": [
        "input_ids_original"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[473, 45, 101, 12744, 203, 452, 734]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oj7MYLuhiIsP",
        "outputId": "769f6377-426e-4674-da13-e68acf8ebbb9"
      },
      "source": [
        "## l'input pour RoBERTa\n",
        "input_ids = [0] + [sentiment_id[sentiment]] + [2] + \\\n",
        "[2] + input_ids_original + [2]\n",
        "input_ids\n",
        "## Voila a quoi ressemble l'entrÃ© du modeÃ¨le :"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 2430, 2, 2, 473, 45, 101, 12744, 203, 452, 734, 2]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9s9mVCIgVKN"
      },
      "source": [
        "##Le code initial du fichier **`dataset.py`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRAPl9oODntS"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import config\n",
        "\n",
        "## La mesure d'Ã©valuation qui a Ã©tÃ© mentionnÃ©e sur le prÃ©sent de la competition \n",
        "def jaccard_array(a, b):\n",
        "    \"\"\"Calculates Jaccard on arrays.\"\"\"\n",
        "    a = set(a)\n",
        "    b = set(b)\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "\n",
        "def process_data(tweet, selected_text, sentiment,\n",
        "                 tokenizer, max_len):\n",
        "    \"\"\"Preprocesses one data sample and returns a dict\n",
        "    with targets and other useful info.\n",
        "    \"\"\"\n",
        "    ## Pour un tweet donnÃ©:\n",
        "    ## rÃ©cpÃ¨rer le text des tweet sous forme d'une str sÃ©parÃ©e par espace (commence par ' ' dÃ©ja)\n",
        "    tweet = ' ' + ' '.join(str(tweet).split())\n",
        "    ## rÃ©cpÃ¨rer le text des selected_text\n",
        "    selected_text = ' ' + ' '.join(str(selected_text).split())\n",
        "\n",
        "    ## rÃ©cpÃ¨rer le len de selected_text (-1 puisque python commence Ã  partir de 0)\n",
        "    len_sel_text = len(selected_text) - 1\n",
        "\n",
        "    ## rÃ©cpÃ¨rer l'idice de dÃ©but et de fin de selected_text\n",
        "    idx_0 = None\n",
        "    idx_1 = None\n",
        "    ## i : indice du caractÃ©re, e c'est le caractÃ©re SI e est le caractÃ©re \n",
        "    ## d'indice 1 (just aprÃ© lespace qu'ona rajoutÃ© au dÃ©but de selected_text)\n",
        "    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n",
        "        ## rÃ©cupÃ©rer l'idx de dÃ©but et fin du selected_text dans le text du tweet\n",
        "        if ' ' + tweet[ind:ind + len_sel_text] == selected_text:\n",
        "            idx_0 = ind\n",
        "            idx_1 = ind + len_sel_text - 1\n",
        "            break\n",
        "\n",
        "    ## Assignez 1 Ã  chaque caractÃ¨re du tweet s'il fait partie du selected_text\n",
        "    ## sinon 0, comme dans l'exemple ci-dessus.    \n",
        "    char_targets = [0] * len(tweet)\n",
        "    if idx_0 is not None and idx_1 is not None:\n",
        "        for ct in range(idx_0, idx_1 + 1):\n",
        "            char_targets[ct] = 1\n",
        "\n",
        "    ## tokeniser le texte du tweet en utilisant le tokeniser que nous avons \n",
        "    ## crÃ©Ã© sur le fichier config.py\n",
        "    tokenized_tweet = tokenizer.encode(tweet)\n",
        "    ## rÃ©cupÃ©rer les indices affectÃ©s par le tokeniser Ã  chaque jeton\n",
        "    input_ids_original = tokenized_tweet.ids\n",
        "    ## Cette methode \".offsets\" permet de rÃ©cupÃ©rer les intervalles dans le\n",
        "    ## texte original auxquels les tokens correspondent.\n",
        "    tweet_offsets = tokenized_tweet.offsets\n",
        "\n",
        "    ## Ce code rÃ©cupÃ¨re les target_ids qui sont les id des tokens cibles qui\n",
        "    ## reprÃ©sentent le texte sÃ©lectionnÃ© (chaque caractÃ¨re est reprÃ©sentÃ© par 1)\n",
        "    target_ids = []\n",
        "    for i, (offset_0, offset_1) in enumerate(tweet_offsets):\n",
        "        if sum(char_targets[offset_0:offset_1]) > 0:\n",
        "            target_ids.append(i)\n",
        "    ## idx dÃ©but du text du target\n",
        "    targets_start = target_ids[0]\n",
        "    ## idx fin du text du target\n",
        "    targets_end = target_ids[-1]\n",
        "\n",
        "    # Sentimadd_prefix_spaceent 'word' id in vocab\n",
        "    ## Encoder le feature de sentiment\n",
        "    sentiment_id = {'positive': 1313,\n",
        "                    'negative': 2430,\n",
        "                    'neutral': 7974}\n",
        "\n",
        "    # Soft Jaccard labels\n",
        "    #C'est la mÃ©thode d'Ã©tiquetage personnalisÃ©e qui a Ã©tÃ© adoptÃ©e par les compÃ©titeurs. \n",
        "    # ----------------------------------\n",
        "    n = len(input_ids_original)\n",
        "    sentence = np.arange(n)\n",
        "    answer = sentence[targets_start:targets_end + 1]\n",
        "    start_labels = np.zeros(n)\n",
        "    for i in range(targets_end + 1):\n",
        "        jac = jaccard_array(answer, sentence[i:targets_end + 1])\n",
        "        start_labels[i] = jac + jac ** 2\n",
        "        \n",
        "    ## Alpha est un paramÃ¨tre d'Ã©quilibre entre l'Ã©tiquetage (labeling) Cross Enthropy \n",
        "    ## habituel et l'Ã©tiquetage basÃ© sur la carte Jaccard (Jaccard-based labeling).\n",
        "    start_labels = (1 - config.SOFT_ALPHA) * start_labels / start_labels.sum()\n",
        "    start_labels[targets_start] += config.SOFT_ALPHA\n",
        "\n",
        "    end_labels = np.zeros(n)\n",
        "    for i in range(targets_start, n):\n",
        "        jac = jaccard_array(answer, sentence[targets_start:i + 1])\n",
        "        end_labels[i] = jac + jac ** 2\n",
        "    end_labels = (1 - config.SOFT_ALPHA) * end_labels / end_labels.sum()\n",
        "    end_labels[targets_end] += config.SOFT_ALPHA\n",
        "    ## Les nouveaux labels qui seront utilisÃ©s pour amÃ©liorer et garantir que le modÃ¨le apprendra correctement\n",
        "    start_labels = [0, 0, 0, 0] + list(start_labels) + [0]\n",
        "    end_labels = [0, 0, 0, 0] + list(end_labels) + [0]\n",
        "    # ----------------------------------\n",
        "\n",
        "    ## l'input pour RoBERTa\n",
        "    input_ids = [0] + [sentiment_id[sentiment]] + [2] + \\\n",
        "                [2] + input_ids_original + [2]\n",
        "    ## Pas de types de token dans RoBERTa (tous a 0)\n",
        "    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_original) + 1)\n",
        "    ## Mask de l'input sans padding\n",
        "    mask = [1] * len(token_type_ids)\n",
        "    ## Identifiants des caractÃ¨res de dÃ©but et de fin pour chaque mot, y compris les nouveaux tokens\n",
        "    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n",
        "    ## Ids des mots dans le tweet qui ont un caractÃ¨re cible, y compris les nouveaux tokens\n",
        "    targets_start += 4\n",
        "    targets_end += 4\n",
        "    orig_start = 4\n",
        "    orig_end = len(input_ids_original) + 3\n",
        "\n",
        "    ## Avant que RoBERTa puisse traiter ces donnÃ©es en entrÃ©e, nous devrons rendre \n",
        "    ## tous les vecteurs de mÃªme taille en ajoutant (padding ) des phrases plus courtes avec le token id 0. \n",
        "    ## AprÃ¨s le padding, nous avons une matrice / un tenseur qui est prÃªt Ã  Ãªtre passÃ© Ã  RoBERTa.\n",
        "    ## Input padding: new mask, token type ids, tweet offsets\n",
        "    ## s'il y'en Ã  du padding \n",
        "    padding_len = max_len - len(input_ids)\n",
        "    if padding_len > 0:\n",
        "      ## on rÃ©cupÃ¨re les input_ids, mask, token_type_ids, tweet_offsets, end_offsets\n",
        "      input_ids = input_ids + ([1] * padding_len)\n",
        "      mask = mask + ([0] * padding_len)\n",
        "      token_type_ids = token_type_ids + ([0] * padding_len)\n",
        "      tweet_offsets = tweet_offsets + ([(0, 0)] * padding_len)\n",
        "      start_labels = start_labels + ([0] * padding_len)\n",
        "      end_labels = end_labels + ([0] * padding_len)\n",
        "    ## Compute le targets_select\n",
        "    targets_select = [0] * len(token_type_ids)\n",
        "    for i in range(len(targets_select)):\n",
        "        if i in target_ids:\n",
        "            targets_select[i + 4] = 1\n",
        "\n",
        "    ## la sortie pour un tweet donnÃ©\n",
        "    return {'ids': input_ids,\n",
        "            'mask': mask,\n",
        "            'token_type_ids': token_type_ids,\n",
        "            'start_labels': start_labels,\n",
        "            'end_labels': end_labels,\n",
        "            'orig_start': orig_start,\n",
        "            'orig_end': orig_end,\n",
        "            'orig_tweet': tweet,\n",
        "            'orig_selected': selected_text,\n",
        "            'sentiment': sentiment,\n",
        "            'offsets': tweet_offsets,\n",
        "            'targets_select': targets_select}\n",
        "\n",
        "\n",
        "## Une classe de pratique pour que toutes les donnÃ©es des tweets soient stockÃ©es \n",
        "## au mÃªme endroit et qui sera utilisÃ© pour charger les donÃ©Ã©es avec dataloader aprÃ©s\n",
        "\n",
        "## Map-style datasets\n",
        "## A map-style dataset is one that implements the __getitem__() and __len__() \n",
        "## protocols, and represents a map from (possibly non-integral) indices/keys to data samples.\n",
        "class TweetDataset:\n",
        "    '''\n",
        "    dÃ©finir un objet(classe) qui contient toutes les donnÃ©es des tweets et implÃ©menter \n",
        "    la mÃ©thode (pre-buil) _len_  qui retourne le nombre de tweets et la mÃ©thode \n",
        "    __getitem__ qui traite les donnÃ©es des tweets et calcule toutes les  tenseur \n",
        "    (torch.tensor) qui sera alimentÃ© par le modÃ¨le : 'ids', 'mask', 'token_type_ids', \n",
        "    'start_labels', 'end_labels', 'orig_start', 'orig_end', 'orig_tweet', \n",
        "    'orig_selected', 'sentiment', 'offsets', 'targets_select'.\n",
        "    '''\n",
        "    def __init__(self, tweets, sentiments, selected_texts):\n",
        "        ## numpy.ndarray contenant les tweet\n",
        "        self.tweets = tweets\n",
        "        ## numpy.ndarray contenant les sentiments\n",
        "        self.sentiments = sentiments\n",
        "        ## numpy.ndarray contenant les targets (selected_text) qui reflÃ¨tent les sentiments\n",
        "        self.selected_texts = selected_texts\n",
        "        ## max len de linput token au transformer model\n",
        "        self.max_len = config.MAX_LEN\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        \"\"\"Returns preprocessed data sample as dict with\n",
        "        data converted to tensors.\n",
        "        \"\"\"\n",
        "        data = process_data(self.tweets[item],\n",
        "                            self.selected_texts[item],\n",
        "                            self.sentiments[item],\n",
        "                            self.tokenizer,\n",
        "                            self.max_len)\n",
        "        ## toutes les donnÃ©es ont Ã©tÃ© converties (casted) en torche.tensor pour\n",
        "        ## Ãªtre traitÃ©es par le modÃ¨le et pour suivre (subir) l'opÃ©ration pendant le \n",
        "        ## passage en avant et en arriÃ¨re (forward / backward pass)\n",
        "\n",
        "        return {'ids': torch.tensor(data['ids'], dtype=torch.long),\n",
        "                'mask': torch.tensor(data['mask'], dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(data['token_type_ids'],\n",
        "                                               dtype=torch.long),\n",
        "                'start_labels': torch.tensor(data['start_labels'],\n",
        "                                             dtype=torch.float),\n",
        "                'end_labels': torch.tensor(data['end_labels'],\n",
        "                                           dtype=torch.float),\n",
        "                'orig_start': data['orig_start'],\n",
        "                'orig_end': data['orig_end'],\n",
        "                'orig_tweet': data['orig_tweet'],\n",
        "                'orig_selected': data['orig_selected'],\n",
        "                'sentiment': data['sentiment'],\n",
        "                'offsets': torch.tensor(data['offsets'], dtype=torch.long),\n",
        "                'targets_select': torch.tensor(data['targets_select'],\n",
        "                                               dtype=torch.float)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OkiOiOzHEql"
      },
      "source": [
        "deux techniques ont Ã©tÃ© utilisÃ©es afin d'assurer la mÃªme longueur des sÃ©quences d'entrÃ©e:\n",
        "* **Le masquage (Masking):** est un moyen d'indiquer aux couches de traitement des sÃ©quences que certains blocs sont manquants dans une entrÃ©e et qu'ils doivent donc Ãªtre ignorÃ©s lors du traitement des donnÃ©es.\n",
        "\n",
        "* **Le padding** est une forme spÃ©ciale de masquage oÃ¹ les Ã©tapes masquÃ©es se trouvent au au dÃ©but d'une sÃ©quence. Le remplissage (padding) vient de la nÃ©cessitÃ© de coder les donnÃ©es de la sÃ©quence en lots consÃ©cutifs (contiguous batches): afin que toutes les sÃ©quences d'un batch soient conformes Ã  une longueur standard donnÃ©e, il est nÃ©cessaire de remplir ou de tronquer certaines sÃ©quences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_Q6Y5KPFUGh"
      },
      "source": [
        "# engine.py\n",
        "\n",
        "---\n",
        "Le fichier engine.py contient une definition de la fonction **`loss_fn`** qui va Ãªtre utilisÃ©e pour calculer la valeur de la perte pendant l'entrainement et l'Ã©valuation du modÃ¨le. ainsi que l'implementation des deux fonction:</br>\n",
        "* **`train_fn`** : qui permet de mettre le model en mode entrainment\n",
        "* **`eval_fn`**: qui permet de mettre le model en mode evaluation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6q7M3XA5H7F"
      },
      "source": [
        "* **[KLDIVLOSS (The Kullback-Leibler divergence loss measure)](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html):** La divergence de Kullback-Leibler est une mesure de distance utile pour les distributions continues et est souvent utile pour effectuer une rÃ©gression directe sur l'espace des distributions de sortie continues (Ã©chantillonnÃ©es discrÃ¨tement).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2UMFZtzFUgB"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import tqdm\n",
        "\n",
        "import utils\n",
        "\n",
        "## Definition de la fonction loss\n",
        "def loss_fn(start_logits, end_logits,\n",
        "            start_positions, end_positions):\n",
        "    ## Appliquer la fonction \\log(\\text{Softmax}(x))log(Softmax(x)) Ã  une entrÃ©e \n",
        "    ## n-dimensionnelle Tenseur ici dim = 1\n",
        "    ## Softmax : car elle dÃ©terminera les probabilitÃ©s pour chaque ID de token d'Ãªtre start_target et la mÃªme chose pour le end_target\n",
        "    m = torch.nn.LogSoftmax(dim=1)\n",
        "    ## La mesure de la divergence de Kullback-Leibler est une mesure de distance\n",
        "    ## utile pour les distributions continues  \n",
        "    loss_fct = torch.nn.KLDivLoss()\n",
        "    ## calculer la loss par apport a la prÃ©diction du caractÃ©re de dÃ©but du target(selected_text)\n",
        "    start_loss = loss_fct(m(start_logits), start_positions)\n",
        "    ## calculer la loss par apport a la prÃ©diction du caractÃ©re de fin du target\n",
        "    end_loss = loss_fct(m(end_logits), end_positions)\n",
        "    ## La valeur de loss totale et la somme des deux loss par apprt a la prÃ©diction \n",
        "    ## caractÃ©re de debut et fin du target\n",
        "    total_loss = (start_loss + end_loss)\n",
        "    return total_loss\n",
        "\n",
        "## dÃ©finition de la fonction train\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler=None):\n",
        "    ## model.train() permet de mettre le modÃ¨le en mode train (il calcule les gradients)\n",
        "    model.train()\n",
        "    ## Permet de stocke la valeur moyenne actuelle et applique deux mÃ©thodes :\n",
        "    ## reset : qui remet toutes les valeurs Ã  zÃ©ro \n",
        "    ## update : qui met Ã  jour l'objet en y ajoutant de nouvelles valeurs, ici il s'agit de la valeur de la loss\n",
        "    losses = utils.AverageMeter()\n",
        "   \n",
        "    ## tqdm nous permettre de crÃ©er une progressbar en fonction de la longueur des donnÃ©es\n",
        "    tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "    \n",
        "    print(\"-------------------------------------------------------------------\")\n",
        "    print(tk0)\n",
        "    \n",
        "    for bi, d in enumerate(tk0):\n",
        "        ## recupÃ©rer l'id du tweet\n",
        "        ids = d['ids']\n",
        "        ## rÃ©cupÃ©rer les ids des tokens\n",
        "        token_type_ids = d['token_type_ids']\n",
        "        ## rÃ©cupÃ©rer le mask du tweet\n",
        "        mask = d['mask']\n",
        "        ## la valeur du start/end lable calculer en utilisant Jaccard-based labeling\n",
        "        start_labels = d['start_labels']\n",
        "        end_labels = d['end_labels']\n",
        "\n",
        "        ## nn.Module.to function permet de dÃ©placer le modÃ¨le\\tensors vers le GPU\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        start_labels = start_labels.to(device, dtype=torch.float)\n",
        "        end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "        ## mettre les gradients Ã  zÃ©ro avant de commencer Ã  faire de la backpropragation  \n",
        "        model.zero_grad()\n",
        "\n",
        "        ## applique un forward pass et rÃ©cuperer l'output\n",
        "        outputs_start, outputs_end = \\\n",
        "            model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "        ## Calculer la valeur de la loss\n",
        "        loss = loss_fn(outputs_start, outputs_end,\n",
        "                       start_labels, end_labels)\n",
        "        ## Calculer les gradiants\n",
        "        loss.backward()\n",
        "        ## Ajuster les poids de notre modele\n",
        "        optimizer.step()\n",
        "        ## un programmateur de taux d'apprentissage basÃ© sur le temps\n",
        "        ## - il est contrÃ´lÃ© par le paramÃ¨tre de dÃ©croissance(decay) de l'optimiser\n",
        "        scheduler.step()\n",
        "        ## mettre a jour la valeur sauvegardÃ© de la loss \n",
        "        losses.update(loss.item(), ids.size(0))\n",
        "        tk0.set_postfix(loss=losses.avg)\n",
        "\n",
        "## dÃ©finition de la fonction de l'Ã©valuation\n",
        "def eval_fn(data_loader, model, device):\n",
        "    ## model.eval() met le modÃ¨le en mode Ã©valuation (il calcule pas les gradients)\n",
        "    model.eval()\n",
        "    ## rÃ©cupÃ©rer la valeur de la loss\n",
        "    losses = utils.AverageMeter()\n",
        "    ## rÃ©cupÃ©rer la valeur de la mÃ©tric de jaccards\n",
        "    jaccards = utils.AverageMeter()\n",
        "    ## Le wrapper \"with torch.no_grad()\" met temporairement tous les tensors avec require_grad Ã  false\n",
        "    with torch.no_grad():\n",
        "        ## passer les donnnÃ©e d'Ã©valuation avec une progressbar\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            start_labels = d['start_labels']\n",
        "            end_labels = d['end_labels']\n",
        "            orig_start = d['orig_start']\n",
        "            orig_end = d['orig_end']\n",
        "            orig_selected = d['orig_selected']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "            \n",
        "            ## nn.Module.to function permet de dÃ©placer le modÃ¨le\\tensors vers le GPU\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            start_labels = start_labels.to(device, dtype=torch.float)\n",
        "            end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs_start, outputs_end = \\\n",
        "                model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "            loss = loss_fn(outputs_start, outputs_end,\n",
        "                           start_labels, end_labels)\n",
        "            ## rÃ©cupÃ©rer les outputs start/stop prÃ©dites\n",
        "            outputs_start = outputs_start.cpu().detach().numpy()\n",
        "            outputs_end = outputs_end.cpu().detach().numpy()\n",
        "            ## lancÃ© le calcul de lindices de jaccard qui permet d'evaluer le modele\n",
        "            jaccard_scores = []\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                ## recupÃ©rer la valeur rÃ©elle du target\n",
        "                selected_tweet = orig_selected[px]\n",
        "                jaccard_score, _ = \\\n",
        "                    utils.calculate_jaccard(original_tweet=tweet,\n",
        "                                            target_string=selected_tweet,\n",
        "                                            start_logits=outputs_start[px, :],\n",
        "                                            end_logits=outputs_end[px, :],\n",
        "                                            orig_start=orig_start[px],\n",
        "                                            orig_end=orig_end[px],\n",
        "                                            offsets=offsets[px])\n",
        "                jaccard_scores.append(jaccard_score)\n",
        "            ## mettre a jour la valeur de jaccard\n",
        "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
        "            ## pareil pour la valeur de la loss\n",
        "            losses.update(loss.item(), ids.size(0))\n",
        "            tk0.set_postfix(loss=losses.avg, jaccard=jaccards.avg)\n",
        "\n",
        "    print(f'Jaccard = {jaccards.avg}')\n",
        "\n",
        "    return jaccards.avg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etmylaX2Fb-j"
      },
      "source": [
        "# evaluate.py\n",
        "\n",
        "---\n",
        "La mÃªme implÃ©mentation de la fonction d'Ã©valuation qui a Ã©tÃ© implÃ©mentÃ©e dans le fichier **engin.py**, celle-ci peut Ãªtre utilisÃ©e pour effectuer une Ã©valuation directement en utilisant le fichier **evaluate.py**.</br>\n",
        "* L'**`Ã©valuation`** et la classe **`Infer`** qui effectue un forward pass pour prÃ©dir les labels de dÃ©but/fin du selected_text, tous travaillent par **`Folds`** et le nombre de plis (Folds) est initialisÃ© dans la classe config.py, ils ont utilisÃ© **`5`** plis pour faire l'Ã©valuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oReUS_pFcZN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "2a5a6a4853c647d5ab4e6f2e421c5b21",
            "ea33407f48d84529a3cedce8ff4eb717",
            "86e84d68c27d472b8a7a0d57a6e22c43",
            "a042d53d0d374fbba87c5126bc89edb1",
            "fb2ad4da78f8468f8b5e0bacdfdb6a44",
            "67b4d3d78dee4cc39c7679217f24bca9",
            "f7174c2b850b4684b80adf245f073187",
            "b40d221cc11e42abacb6d79d87b64e15",
            "da3165f8a7bb4f1ba6002a3dd1839b23",
            "ad49480862ce44e696e8ab8d60f4850c",
            "fd76536cf49f4f9e9dcca7b8c6c9c804",
            "97fb8388273247cea7095fce3ccd4789",
            "2fdf7552d81344c6b23bbd1e82f34b80",
            "6991e98fa56846f98fdf918568cafd89",
            "79c265a4eeda434db25543b711583219",
            "c5c53ebd65b84df79429c42c41a456f0",
            "311e02e4ab79455f96a6a69d882cf44c",
            "8fbea1556436405c82e84a37e15ee0c3",
            "be8768226ed74c338a38576cc1639b61",
            "f195b12fa5be48fca00f7c2056222609",
            "d40ab0eeaee6478aa0eec0bc7a5d883f",
            "2f1b9d41b21047ec94130b11e14337d6",
            "71e0c96ecb90475a9767aa517b1ff34d",
            "83643d9c675e43d0adf21bb7e7bb4bd2",
            "e67e719ed34a4b07a0591d376313ceeb",
            "a19299dbe1cb457fb61a2bd60a044123",
            "e2037ef67ba3407e9883a32f1a9ae9e9",
            "ef8f28882f6a4689ac35c8b7dc69dc8a",
            "80baee64c83f4c05b13026fdd6c3928f",
            "95fe9696a2b74d7ea8c85a71ed0ea401",
            "1dd0410fc9704a9caa064a47ee8936bc",
            "ba08cfa1331d47489b03c860ed273728",
            "c649b48206e8461ab986a31eff41663d",
            "de48ecab2e9a43a2984091f852f12b25",
            "d9ccaad734f8466f9c609ba4c19ae320",
            "79deeeeeaa964a06bc9f3ad5462ca312",
            "1790d4b810e6479fb0986a33c7d6d89d",
            "3e0abbd9b372444a9ecb25a616239688",
            "8388209c0eea421a864e786bf0e88db2",
            "6e28785f8a2c4d26b9dedb98f993c35c",
            "6ae593eea4ea4bf29ccb9207bf39a987",
            "0a8fc24b90b944d1ba355ecbb00bfa58",
            "dc414fdaee294c9db8c677b27a81707f",
            "b53ea0fc5b7e42f6961cc98b3b257128",
            "9f73581c6f304a2381a54c3aded4fb52",
            "ad0874d836e3493cb84f49eb88448e72",
            "86d93fca9e4a417187f9512e505ccf8c",
            "0c571a2eff364548b85ad2d1a1ccc4cd",
            "e34c097bd1a8400cab7a702b06a9143c",
            "1eb203e1db144517ae6bf803be68d76b",
            "c555a66b7f44451e82c325428f234bc4",
            "5ac0aaff737641eca49308824bb94603",
            "1ec1aa1825834a7c96fddcafac8ee72b",
            "ae9af73a41084fc2bbf736f4afd9f5dd",
            "24ea29ea46fe45f5876e16e9bbc5daca",
            "806bf2cfe63e4b909522ad2c6b6f6d8c"
          ]
        },
        "outputId": "98e79f68-c3d7-4978-c812-dcd75770c65d"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import tqdm.autonotebook as tqdm\n",
        "\n",
        "import utils\n",
        "import config\n",
        "import models\n",
        "import dataset\n",
        "\n",
        "## dÃ©finition de la fonction de l'Ã©valuation\n",
        "def eval_fn(data_loader, model, device):\n",
        "    model.eval()\n",
        "    ## rÃ©cupÃ©rer la valeur de la mÃ©tric de jaccards\n",
        "    jaccards = utils.AverageMeter()\n",
        "    ## comme j'avais commenter sur le code ci-dessous\n",
        "    ## Le wrapper \"with torch.no_grad()\" met temporairement tous les tensors avec require_grad Ã  false\n",
        "    with torch.no_grad():\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            start_labels = d['start_labels']\n",
        "            end_labels = d['end_labels']\n",
        "            orig_start = d['orig_start']\n",
        "            orig_end = d['orig_end']\n",
        "            orig_selected = d['orig_selected']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "            ## dÃ©placer le modÃ¨le\\tensors vers le GPU/CPU\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            start_labels = start_labels.to(device, dtype=torch.float)\n",
        "            end_labels = end_labels.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs_start, outputs_end = \\\n",
        "                model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n",
        "\n",
        "            outputs_start = outputs_start.cpu().detach().numpy()\n",
        "            outputs_end = outputs_end.cpu().detach().numpy()\n",
        "\n",
        "            jaccard_scores = []\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                selected_tweet = orig_selected[px]\n",
        "                jaccard_score, _ = \\\n",
        "                    utils.calculate_jaccard(original_tweet=tweet,\n",
        "                                            target_string=selected_tweet,\n",
        "                                            start_logits=outputs_start[px, :],\n",
        "                                            end_logits=outputs_end[px, :],\n",
        "                                            orig_start=orig_start[px],\n",
        "                                            orig_end=orig_end[px],\n",
        "                                            offsets=offsets[px])\n",
        "                jaccard_scores.append(jaccard_score)\n",
        "\n",
        "            jaccards.update(np.mean(jaccard_scores), ids.size(0))\n",
        "            tk0.set_postfix(jaccard=jaccards.avg)\n",
        "\n",
        "    return jaccards.avg\n",
        "\n",
        "\n",
        "def run(fold):\n",
        "    ## Lecture des donnÃ©es de l'entrainement\n",
        "    dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "\n",
        "    ## Lecture des donnÃ©es de la validation\n",
        "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
        "    ## Les types de tenseurs CUDA, qui implÃ©mentent la mÃªme fonction que les \n",
        "    ## tenseurs CPU, mais qui utilisent les GPU pour le calcul\n",
        "    device = torch.device('cuda')\n",
        "    ## le modÃ¨le hÃ©rite de la class PreTrainedModel\n",
        "    ## c'est un modÃ©le prÃ©-entrainÃ© sur Squad2\n",
        "    ## le modÃ©le prÃ©cisÃ© dans la class config c'est bien 'deepset/roberta-base-squad2' \n",
        "    model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_CONFIG)\n",
        "    ##  Pour assurer que le modÃ¨le rendre tous les hidden_state (weights).\n",
        "    model_config.output_hidden_states = True\n",
        "    \n",
        "    ## CrÃ©e une instance de la classe TweetModel avec la config crÃ©e just avant\n",
        "    model = models.TweetModel(conf=model_config)\n",
        "    model.to(device)\n",
        "    ## La fonction load_state_dict() prend un objet du dictionnaire, tet elle\n",
        "    ## charge le state_dict sÃ©rialisÃ© et sauvegardÃ© du modÃ¨le\n",
        "    model.load_state_dict(torch.load(\n",
        "        f'{config.TRAINED_MODEL_PATH}/model_{fold}.bin'))\n",
        "    \n",
        "    ## model.eval() met le modÃ¨le en mode Ã©valuation (il calcule pas les gradients)\n",
        "    model.eval()\n",
        "\n",
        "    ## PrÃ©parÃ© les tweets de validation selon la methode dataset.TweetDataset() qui prÃ©pare toutes les donnÃ©es des tweets\n",
        "    valid_dataset = dataset.TweetDataset(\n",
        "        tweets=df_valid.text.values,\n",
        "        sentiments=df_valid.sentiment.values,\n",
        "        selected_texts=df_valid.selected_text.values)\n",
        "    ## chargement des donnÃ©es de validation en utilisant dataLoader de Pytorch \n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4,\n",
        "        shuffle=False)\n",
        "    ## Le fait de dÃ©finir l'argument num_workers comme un nombre entier positif\n",
        "    ## activera le chargement de donnÃ©es multiprocessus avec le nombre spÃ©cifiÃ© de processus de chargement des travailleurs\n",
        "    ## calculer l'indice de jaccard\n",
        "    jaccard = eval_fn(valid_data_loader, model, device)\n",
        "\n",
        "    return jaccard\n",
        "\n",
        "##  if __name__ == \"main\" ' bloc pour empÃªcher l'exÃ©cution de (certain) code lors\n",
        "##  de l'importation du module. En bref, __name__ est une variable dÃ©finie pour \n",
        "##  chaque script qui dÃ©finit si le script est exÃ©cutÃ© en tant que module principal \n",
        "##  ou s'il est exÃ©cutÃ© en tant que module importÃ©.\n",
        "if __name__ == '__main__':\n",
        "    utils.seed_everything(config.SEED)\n",
        "    ## Lise qui va contenir le score de chaque folds\n",
        "    fold_scores = []\n",
        "    ## N_FOLDS est a 5\n",
        "    for i in range(config.N_FOLDS):\n",
        "        fold_score = run(i)\n",
        "        fold_scores.append(fold_score)\n",
        "    ## Afficher les score de chaque folds et le score moyen\n",
        "    for i in range(config.N_FOLDS):\n",
        "        print(f'Fold={i}, Jaccard = {fold_scores[i]}')\n",
        "    print(f'Mean = {np.mean(fold_scores)}')\n",
        "    print(f'Std = {np.std(fold_scores)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a5a6a4853c647d5ab4e6f2e421c5b21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da3165f8a7bb4f1ba6002a3dd1839b23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=496313727.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "311e02e4ab79455f96a6a69d882cf44c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e67e719ed34a4b07a0591d376313ceeb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c649b48206e8461ab986a31eff41663d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ae593eea4ea4bf29ccb9207bf39a987",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e34c097bd1a8400cab7a702b06a9143c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=172.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold=0, Jaccard = 0.7163026420895469\n",
            "Fold=1, Jaccard = 0.7108215431021135\n",
            "Fold=2, Jaccard = 0.7158955035127735\n",
            "Fold=3, Jaccard = 0.7166221978997807\n",
            "Fold=4, Jaccard = 0.7109265704332721\n",
            "Mean = 0.7141136914074974\n",
            "Std = 0.002655369837057321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Eedd3Jg3c6"
      },
      "source": [
        "**TORCH.UTILS.DATA**\n",
        "Au cÅ“ur de l'utilitaire de chargement de donnÃ©es PyTorch se trouve la classe ```torch.utils.data.DataLoader```. Elle reprÃ©sente un Python itÃ©rable sur un ensemble de donnÃ©es, avec le support de:</br>\n",
        "* map-style et iterable-style datasets,\n",
        "\n",
        "* la personnalisation de l'ordre de chargement des donnÃ©es,\n",
        "\n",
        "* le dosage automatique,\n",
        "\n",
        "* chargement de donnÃ©es Ã  un ou plusieurs processus,\n",
        "\n",
        "* Ã©pinglage automatique de la mÃ©moire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrP6RBNKFqd9"
      },
      "source": [
        "# infer.py\n",
        "\n",
        "---\n",
        "Ce code reprÃ©sente l'implÃ©mentation d'une Forward passe pour prÃ©dire le texte sÃ©lectionnÃ© (start/end_labels) des tweets donnÃ©, on peut dire que cela effectue la mÃªme tÃ¢che que la mÃ©thode .predict() en ML puisque ya pas la notion de l'apprentissage c'est just une propagation dans le modele et rÃ©cupÃ©ration de l'output.</br>\n",
        "* L'**`Ã©valuation`** et la methode **`run()`** de la classe **`Infer`** qui effectue un forward pass pour prÃ©dir les labels de dÃ©but/fin du selected_text, tous travaillent par **`Folds`** et le nombre de plis (Folds) est initialisÃ© dans la classe config.py, ils ont utilisÃ© **`5`**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlQWmDOcQHvc"
      },
      "source": [
        "**DÃ©bogage**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rma-6txbQF0P"
      },
      "source": [
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import tqdm\n",
        "\n",
        "import config\n",
        "import models\n",
        "import dataset\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHdlXPTWPc_4"
      },
      "source": [
        "## Charger les donnÃ©es de test\n",
        "df_test = pd.read_csv(config.TEST_FILE)\n",
        "df_test.loc[:, 'selected_text'] = df_test.text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ2ekEZbQfrw"
      },
      "source": [
        "* **`TORCH.CUDA`**\n",
        "Ce paquet ajoute la prise en charge des types de tenseurs CUDA, qui implÃ©mentent la mÃªme fonction que les tenseurs CPU, mais qui utilisent les GPU pour le calcul.\n",
        "* En utilisant **`torch.device(\"cuda\")`**, elle permet de prÃ©ciser que le dispositif est un GPU sans spÃ©cifier particuliÃ¨rement le nom ou l'id du dispositif (0,1,2,3)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94B8gmIARzbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "161214af-7730-4ca1-d2d3-ce700f0a46e9"
      },
      "source": [
        "print(\"[INFO]: le nombre de GPU disponibles:\",torch.cuda.device_count(),\"et le nom de dispositif utilisÃ©:\",torch.cuda.get_device_name(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO]: le nombre de GPU disponibles: 1 et le nom de dispositif utilisÃ©: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Reh_TGmqQ3ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120f15c1-40e7-48ad-9d8c-4836cef5d2e5"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_N4QPpQQqQW"
      },
      "source": [
        "## Instancier le modÃ¨le de transformateur avec la configuration dÃ©finie dans le fichier config.py\n",
        "model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_CONFIG)\n",
        "## output_hidden_states (bool, optional, defaults to False) - Indique si le modÃ¨le\n",
        "## doit ou non retourner tous les Ã©tats cachÃ©s.\n",
        "model_config.output_hidden_states = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4Os_p7qUTWd"
      },
      "source": [
        "fold_models = []\n",
        "## Comme l'entrainement et l'Ã©valuation, Infer (forwad pass (equivalent de \n",
        "## la methode .predict()) a Ã©galement Ã©tÃ© fait par des folds qui sont dÃ©finis\n",
        "## dans le fichier de configuration Ã  5\n",
        "for i in range(config.N_FOLDS):\n",
        "  ## Instancier le modÃ¨le TweetModel avec la configuration crÃ©er ci-dessus (model_config)\n",
        "  model = models.TweetModel(conf=model_config)\n",
        "  ## Mettre le modÃ¨le sur le GPU device spÃ©cifiÃ©\n",
        "  model.to(device)\n",
        "  ## Charger le modÃ¨le sauvegardÃ© aprÃ¨s l'entraÃ®nement et l'Ã©valuation.\n",
        "  model.load_state_dict(torch.load(f'{config.TRAINED_MODEL_PATH}/model_{i}.bin'),\n",
        "                        strict=False)\n",
        "  ## Mettre le modÃ¨le en mode d'Ã©valuation afin que nous ignorions l'apprentissage \n",
        "  ## puisque nous prÃ©disons sans avoir besoin de calculs, backprop, grads\n",
        "  model.eval()\n",
        "  ## AprÃ¨s l'entraÃ®nement par plis(folds=5), nous obtenons/sauvegardons un modÃ¨le pour chaque pli\n",
        "  fold_models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtO5TLyqFp-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "459773e4-c234-4cfb-c1d4-9665f468a2f0"
      },
      "source": [
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "import transformers\n",
        "import tqdm\n",
        "\n",
        "import config\n",
        "import models\n",
        "import dataset\n",
        "import utils\n",
        "\n",
        "\n",
        "def run():\n",
        "    df_test = pd.read_csv(config.TEST_FILE)\n",
        "    df_test.loc[:, 'selected_text'] = df_test.text.values\n",
        "    ## prÃ©ciser que le dispositif est un GPU\n",
        "    device = torch.device('cuda')\n",
        "    model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_CONFIG)\n",
        "    model_config.output_hidden_states = True\n",
        "    \n",
        "    fold_models = []\n",
        "    for i in range(config.N_FOLDS):\n",
        "        model = models.TweetModel(conf=model_config)\n",
        "        model.to(device)\n",
        "        model.load_state_dict(torch.load(\n",
        "            f'{config.TRAINED_MODEL_PATH}/model_{i}.bin'),\n",
        "            strict=False)\n",
        "        model.eval()\n",
        "        fold_models.append(model)\n",
        "    ## TweetDataset est un map-style et iterable-style datasets\n",
        "    test_dataset = dataset.TweetDataset(\n",
        "        tweets=df_test.text.values,\n",
        "        sentiments=df_test.sentiment.values,\n",
        "        selected_texts=df_test.selected_text.values)\n",
        "    ## data_loader permet d'automatiser le chargement des donnÃ©es\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        shuffle=False,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4) ## shuffle=False puisuqe on est en mode evaluation donc pas besoin d'un chuffle\n",
        "\n",
        "    char_pred_test_start = []\n",
        "    char_pred_test_end = []\n",
        "    ## Pas de calcu des gradiants, c'est un forward pass de notre modÃ¨le\n",
        "    with torch.no_grad():\n",
        "        ## Faites instantanÃ©ment apparaÃ®tre un indicateur de progression intelligent\n",
        "        ## sur les boucles - il suffit d'envelopper n'importe quel itÃ©rable avec tqdm(iterable)\n",
        "        tk0 = tqdm.tqdm(data_loader, total=len(data_loader))\n",
        "        for bi, d in enumerate(tk0):\n",
        "            ids = d['ids']\n",
        "            token_type_ids = d['token_type_ids']\n",
        "            mask = d['mask']\n",
        "            orig_tweet = d['orig_tweet']\n",
        "            offsets = d['offsets']\n",
        "            \n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "\n",
        "            outputs_start_folds = []\n",
        "            outputs_end_folds = []\n",
        "\n",
        "            for i in range(config.N_FOLDS):\n",
        "                outputs_start, outputs_end = \\\n",
        "                    fold_models[i](ids=ids,\n",
        "                                   mask=mask,\n",
        "                                   token_type_ids=token_type_ids)\n",
        "                outputs_start_folds.append(outputs_start)\n",
        "                outputs_end_folds.append(outputs_end)\n",
        "\n",
        "            outputs_start = sum(outputs_start_folds) / config.N_FOLDS\n",
        "            outputs_end = sum(outputs_end_folds) / config.N_FOLDS\n",
        "            \n",
        "            outputs_start = torch.softmax(outputs_start, dim=-1).cpu().detach().numpy()\n",
        "            outputs_end = torch.softmax(outputs_end, dim=-1).cpu().detach().numpy()\n",
        "            ## Affecter les prababilitÃ©es de l'output (La liste des probabilitÃ©s affectÃ©s aux tokens) outputs_start/outputs_end au char\n",
        "            ## pour passer au char level puisque le Transformers sont token level\n",
        "            ## chaque caractÃ©re prends la probavilitÃ©e affectÃ© au token auquel il appartient\n",
        "            ## La probabilitÃ© corresponde a la possibilitÃ© que ce token et le debut ou la fin du selected_text (target)\n",
        "            for px, tweet in enumerate(orig_tweet):\n",
        "                char_pred_test_start.append(\n",
        "                    utils.token_level_to_char_level(tweet, offsets[px], outputs_start[px]))\n",
        "                char_pred_test_end.append(\n",
        "                    utils.token_level_to_char_level(tweet, offsets[px], outputs_end[px]))\n",
        "    ## Serialiser et sauvegarder les output de la prÃ©diction\n",
        "    with open('/content/drive/MyDrive/very_final/pickles/roberta-char_pred_test_start.pkl', 'wb') as handle:\n",
        "        pickle.dump(char_pred_test_start, handle)\n",
        "    with open('/content/drive/MyDrive/very_final/pickles/roberta-char_pred_test_end.pkl', 'wb') as handle:\n",
        "        pickle.dump(char_pred_test_end, handle)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [01:02<00:00,  1.78it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU3Wq7BkOCRg"
      },
      "source": [
        "* **`token_level_to_char_level`** cette mÃ©thode affectera les probabilitÃ©s prÃ©dites de chaque token Ã  chaque caractÃ¨re lui appartenant et je l'ai dÃ©taillÃ©e et expliquÃ©e sur le notebook **`Character Level Model`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUTPKlGDGpj8"
      },
      "source": [
        "# models.py\n",
        "\n",
        "---\n",
        "ce fichier contient une implÃ©mentation de la classe de modÃ¨le **`TweetModel`** qui hÃ©ritÃ©e des transformateurs **`BertPreTrainedModel`** et la mÃ©thode **`forward`** qui rÃ©cupÃ¨re la sortie logits juste avant la couche des embeddings et effectue un**` Max-pooling`** et un **`Average_pooling`**</br>\n",
        "<img src = 'https://github.com/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/model_architecture.png?raw=true'></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pF7B-M5K210p"
      },
      "source": [
        "\n",
        "* Ici, ils veulent charger le modÃ¨le roberta Ã  partir d'un ensemble donnÃ© de poids (weights) en faisant appel Ã  from_pretrained sur la classe TweetModel ; c'est pourquoi cette classe hÃ©rite de transformers.BertPreTrainedModel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2Ps0RfL406X",
        "outputId": "ca00ec38-3c89-42e3-c511-e010fa91e07a"
      },
      "source": [
        "classifier = torch.nn.Linear(config.HIDDEN_SIZE * 2, 2)\n",
        "classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=1536, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0kVj0sFGo6k"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "import config\n",
        "\n",
        "## Ici, ils veulent charger le modÃ¨le roberta Ã  partir d'un ensemble donnÃ© de poids\n",
        "## (weights) en faisant appel Ã  from_pretrained sur la classe TweetModel ; c'est\n",
        "## pourquoi cette classe hÃ©rite de transformers.BertPreTrainedModel.\n",
        "class TweetModel(transformers.BertPreTrainedModel):\n",
        "    ## Instantaition du modele\n",
        "    def __init__(self, conf):\n",
        "        super(TweetModel, self).__init__(conf)\n",
        "        self.roberta = transformers.RobertaModel.from_pretrained(\n",
        "            config.MODEL_CONFIG,\n",
        "            config=conf)\n",
        "        ## Utiler la valeure spÃ©cifiÃ©e dans le fichier config.py pour un dropout de 0.5\n",
        "        self.high_dropout = torch.nn.Dropout(config.HIGH_DROPOUT)\n",
        "        ## 768 est la dimension des Embeddings \n",
        "        ## 2 par ce que on a un problÃ¨me de classification soit le token c'est le text sÃ©lectionnÃ© (target) soit non\n",
        "        ## HIDDEN_SIZE 768 * 2 par ce que a la sortie de roberta on aura un tensor de 1536\n",
        "        ## Une couche (1536,2): Linear(in_features=1536, out_features=2, bias=True)\n",
        "        self.classifier = torch.nn.Linear(config.HIDDEN_SIZE * 2, 2)\n",
        "        torch.nn.init.normal_(self.classifier.weight, std=0.02)\n",
        "\n",
        "    def forward(self, ids, mask, token_type_ids):\n",
        "        # sequence_output of N_LAST_HIDDEN + Embedding states\n",
        "        # (N_LAST_HIDDEN + 1, batch_size, num_tokens, 768)\n",
        "        _, _, out = self.roberta(ids, attention_mask=mask,\n",
        "                                 token_type_ids=token_type_ids)\n",
        "        \n",
        "        ## RÃ©cupÃ©re les valeus de toutes les couches sans la couche des embeddings.\n",
        "        out = torch.stack(\n",
        "            tuple(out[-i - 1] for i in range(config.N_LAST_HIDDEN)), dim=0)\n",
        "        ## Avg pooling\n",
        "        out_mean = torch.mean(out, dim=0)\n",
        "        ## Max pooling\n",
        "        out_max, _ = torch.max(out, dim=0)\n",
        "        out = torch.cat((out_mean, out_max), dim=-1)\n",
        "\n",
        "\n",
        "        # Multisample Dropout: https://arxiv.org/abs/1905.09788 expliquÃ© just en bas\n",
        "        ## logit cÃ©est la couche qui vient just avant la couche Dense\n",
        "        logits = torch.mean(torch.stack([\n",
        "            self.classifier(self.high_dropout(out))\n",
        "            for _ in range(5)\n",
        "        ], dim=0), dim=0)\n",
        "        ## puique on'a deux output dans la loits (start_lable / end_label)\n",
        "        start_logits, end_logits = logits.split(1, dim=-1)\n",
        "\n",
        "        # (batch_size, num_tokens)\n",
        "        ## .squeeze() pou applatire (flatteniser) les Nd tensors\n",
        "        start_logits = start_logits.squeeze(-1)\n",
        "        end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "        return start_logits, end_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5zCx9T1lqBD"
      },
      "source": [
        "**Multi Sample Dropout (MSD):** C'est l'une des techniques qu'ils ont utilisÃ©es et que je trouve si intÃ©ressante. En fait, il applique un dropout plusieurs fois avec diffÃ©rents masques et ensuite il calcule la moyenne des rÃ©sultats</br>\n",
        "  Le dropout initial crÃ©e un sous-ensemble choisi au hasard (appelÃ© dropout sample) Ã  partir des donnÃ©es d'entrÃ©e de chaque itÃ©ration d'entrainement, tandis que le MSD crÃ©e plusieurs Ã©chantillon de dropout. La loss est calculÃ©e pour chaque Ã©chantillon, puis la moyenne des losses des Ã©chantillons est calculÃ©e pour obtenir la Loss finale [(plus de dÃ©tails ici)](https://arxiv.org/pdf/1905.09788.pdf).</br>\n",
        "  ![alt text](https://github.com/Amine-OMRI/tweet-sentiment-extraction-kaggle-compete-1st-place-detailed-solution/blob/main/Multi-Sample-Dropout.png?raw=true)</br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPit1dlVHEIs"
      },
      "source": [
        "# utils.py\n",
        "\n",
        "---\n",
        "\n",
        "le fichier **utils.py**contient toutes les implÃ©mentations de toutes les fonctions qui seront utilisÃ©es dans de nombreux fichiers de code, telle que :\n",
        "* la fonction qui fixe le seed global **seed_everything** \n",
        "la fonction qui calcule les probabilitÃ©s de niveau de caractÃ¨res token_level_to_char_level\n",
        "* la fonction qui calcule la mÃ©trique de l'Ã©valuation mentionnÃ©e dans les Ã©noncÃ©es de la competition, qui est **jaccard**\n",
        "* la fonction qui calcule le score final du Jaccard en utilisant les prÃ©dictions **calculate_jaccard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xc2lgxiHTsQ"
      },
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "\n",
        "def token_level_to_char_level(text, offsets, preds):\n",
        "    probas_char = np.zeros(len(text))\n",
        "    for i, offset in enumerate(offsets):\n",
        "        if offset[0] or offset[1]:\n",
        "            probas_char[offset[0]:offset[1]] = preds[i]\n",
        "\n",
        "    return probas_char\n",
        "\n",
        "\n",
        "def jaccard(str1, str2):\n",
        "    \"\"\"Original metric implementation.\"\"\"\n",
        "    a = set(str1.lower().split())\n",
        "    b = set(str2.lower().split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "\n",
        "\n",
        "def get_best_start_end_idx(start_logits, end_logits,\n",
        "                           orig_start, orig_end):\n",
        "    \"\"\"Return best start and end indices following BERT paper.\"\"\"\n",
        "    best_logit = -np.inf\n",
        "    best_idxs = None\n",
        "    start_logits = start_logits[orig_start:orig_end + 1]\n",
        "    end_logits = end_logits[orig_start:orig_end + 1]\n",
        "    for start_idx, start_logit in enumerate(start_logits):\n",
        "        for end_idx, end_logit in enumerate(end_logits[start_idx:]):\n",
        "            logit_sum = start_logit + end_logit\n",
        "            if logit_sum > best_logit:\n",
        "                best_logit = logit_sum\n",
        "                best_idxs = (orig_start + start_idx,\n",
        "                             orig_start + start_idx + end_idx)\n",
        "    return best_idxs\n",
        "\n",
        "\n",
        "def calculate_jaccard(original_tweet, target_string,\n",
        "                      start_logits, end_logits,\n",
        "                      orig_start, orig_end,\n",
        "                      offsets, \n",
        "                      verbose=False):\n",
        "    \"\"\"Calculates final Jaccard score using predictions.\"\"\"\n",
        "    start_idx, end_idx = get_best_start_end_idx(\n",
        "        start_logits, end_logits, orig_start, orig_end)\n",
        "\n",
        "    filtered_output = ''\n",
        "    for ix in range(start_idx, end_idx + 1):\n",
        "        filtered_output += original_tweet[offsets[ix][0]:offsets[ix][1]]\n",
        "        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n",
        "            filtered_output += ' '\n",
        "\n",
        "    # Return orig tweet if it has less then 2 words\n",
        "    if len(original_tweet.split()) < 2:\n",
        "        filtered_output = original_tweet\n",
        "\n",
        "    if len(filtered_output.split()) == 1:\n",
        "        filtered_output = filtered_output.replace('!!!!', '!')\n",
        "        filtered_output = filtered_output.replace('..', '.')\n",
        "        filtered_output = filtered_output.replace('...', '.')\n",
        "\n",
        "    filtered_output = filtered_output.replace('Ã¯Ã¯', 'Ã¯')\n",
        "    filtered_output = filtered_output.replace('Â¿Â¿', 'Â¿')\n",
        "\n",
        "    jac = jaccard(target_string.strip(), filtered_output.strip())\n",
        "    return jac, filtered_output\n",
        "\n",
        "\n",
        "class AverageMeter:\n",
        "    \"\"\"Computes and stores the average and current value.\"\"\"\n",
        "    ## Permet de stocke la valeur moyenne actuelle et applique deux mÃ©thodes :\n",
        "    ## reset : qui remet toutes les valeurs Ã  zÃ©ro \n",
        "    ## update : qui met Ã  jour l'objet en y ajoutant de nouvelles valeurs, ici il s'agit de la valeur de la loss\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDzmFycLG6Rc"
      },
      "source": [
        "#train.py\n",
        "\n",
        "---\n",
        "Ce fichier de code exÃ©cute l'entrainement sur les donnÃ©es d'entranement et de la validation sur les donnÃ©es de validation et affiche les valeurs de jaccard et la loss\n",
        "\n",
        "1) Il a utilisÃ© le GPU Colab Pro pour RoBERTa-large et il a fallu environ 6h pour l'entraÃ®ner avec 5 folds et 4 Ã©poques sans optimisation particuliÃ¨re. \n",
        "\n",
        "[Hikkiiii](https://www.kaggle.com/wochidadonggua) a Ã©galement entraÃ®ner RoBERTa-large, 2V100, APEX(O1), il a fallu environ 220s par Ã©poque \n",
        "\n",
        "2) RoBERTa-base-squad2 est disponible prÃ©-entrainÃ© par [HuggingFace.](https://huggingface.co/deepset/roberta-base-squad2)\n",
        "\n",
        "\n",
        "\n",
        "* L'**`apprentissage`**, l'**`Ã©valuation`** et la classe **`Infer`** qui effectue un forward pass pour prÃ©dir les labels de dÃ©but/fin du selected_text, tous travaillent par **`Folds`** et le nombre de plis (Folds) est initialisÃ© dans la classe config.py, ils ont utilisÃ© **`5`** plis pour chaque processus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0lwwdVZgxBo"
      },
      "source": [
        "##DÃ©boguage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkXID0zIxpE5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import torch\n",
        "import torchcontrib\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "import models\n",
        "import engine\n",
        "import utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HT0b6QoG61j"
      },
      "source": [
        "Une autre technique qui a Ã©tÃ© utilisÃ©e comme **Optimiser** l'est :\n",
        "* **SWA :** la technique SWA [(Stochastic Weight Averaging)](https://pytorch.org/blog/stochastic-weight-averaging-in-pytorch/) rÃ©cemment proposÃ©e, et sa nouvelle implÃ©mentation dans torchcontrib. La SWA est une procÃ©dure simple qui amÃ©liore la gÃ©nÃ©ralisation du deep learning sur la Descente de Gradient Stochastique (SGD) sans coÃ»t supplÃ©mentaire, et peut Ãªtre utilisÃ©e en remplacement de tout autre **optimiseur dans PyTorch**. Le SWA a une large gamme d'applications et de fonctionnalitÃ©s.</br>\n",
        "Il a Ã©tÃ© dÃ©montrÃ© que SWA amÃ©liore considÃ©rablement la gÃ©nÃ©ralisation des tÃ¢ches de vision par ordinateur, y compris les VGG, les ResNets, les Wide ResNets et les DenseNets sur ImageNet et les CIFAR benchmarks.\n",
        "\n",
        "En bref, le SWA effectue une moyenne Ã©gale des poids traversÃ©s par le SGD avec un programme d'apprentissage modifiÃ©."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCEBaXLxemvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7296cf24-a9a0-4ad3-91ef-ec82750a81df"
      },
      "source": [
        "for i in range(config.N_FOLDS):\n",
        "  print(\"fold %s\"%i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "fold 1\n",
            "fold 2\n",
            "fold 3\n",
            "fold 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhejMuHRezCN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "221d73b9-61ae-4990-e866-328ab058f1bf"
      },
      "source": [
        "print(config.TRAINING_FILE)\n",
        "dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "dfx.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/very_final/data/train_folds.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>d0c214ad3a</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>good mornig to everone... it`s a great morning...</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7d093817af</td>\n",
              "      <td>LOL. You know me. I aim to please.</td>\n",
              "      <td>I aim to please.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21eacf7e58</td>\n",
              "      <td>Was at Ruby Skye last night as well! Superb s...</td>\n",
              "      <td>Superb set by Steve.</td>\n",
              "      <td>positive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>d0f94d66ab</td>\n",
              "      <td>does not like ups much today...</td>\n",
              "      <td>does not like</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a025e21634</td>\n",
              "      <td>Nothing like In `n` Out and a LOST marathon af...</td>\n",
              "      <td>long day of work.</td>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... kfold\n",
              "0  d0c214ad3a  ...     0\n",
              "1  7d093817af  ...     0\n",
              "2  21eacf7e58  ...     0\n",
              "3  d0f94d66ab  ...     0\n",
              "4  a025e21634  ...     0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35AXIHbqhOLo"
      },
      "source": [
        "* L'entrainement et l'Ã©valuation ont Ã©tÃ© faites par Folds (**5 folds**) Le jeu de donnÃ©es a Ã©galement Ã©tÃ© Ã©tiquetÃ© avec un numÃ©ro de rÃ©fÃ©rence a un fold entre 0 et 4 et tous les plis contiennent le mÃªme nombre de lignes (5496)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S85v7ZLfTDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e9c588-fa3b-4324-e916-60cb7e21e829"
      },
      "source": [
        "dfx[['kfold']].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "kfold\n",
              "4        5496\n",
              "3        5496\n",
              "2        5496\n",
              "1        5496\n",
              "0        5496\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMn1oGkJhgrb"
      },
      "source": [
        "* Tout comme la validation croisÃ©e, ils ont 5 folds, ils en gardent un (fold) pour la validation et les 4 autres fold pour l'entrainement du modÃ¨le et chacun des 5 fold sera utilisÃ© une fois comme un fold de validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBFc09taeVJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c06bef7-4789-411d-8e09-de705aea01cf"
      },
      "source": [
        "## Pour le fold 0, les autre folds (1,2,3,4) vont etre utilisÃ©s pour l'entrainement\n",
        "df_train = dfx[dfx.kfold != 0].reset_index(drop=True)\n",
        "## Le fold 0 sera pour la validation\n",
        "df_valid = dfx[dfx.kfold == 0].reset_index(drop=True)\n",
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21984, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IZPnqSGlQEn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3e3bdf4-32c1-432d-a537-7771543fb896"
      },
      "source": [
        "## les tweets\n",
        "type(df_train.text.values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCui4AOsjE3x"
      },
      "source": [
        "## CrÃ©er un Map-style datasets (class TweetDataset) sur les donnÃ©es d'entrainement\n",
        "train_dataset = dataset.TweetDataset(\n",
        "    tweets=df_train.text.values, ## Text du tweet (numpy.ndarray de string)\n",
        "    sentiments=df_train.sentiment.values, ## Sentiment\n",
        "    selected_texts=df_train.selected_text.values) ## Le target: texte sÃ©lÃ©ctionnÃ© "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrxYii-8jOH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84620de6-71aa-4795-beb6-1f9b13fd4b77"
      },
      "source": [
        "print(\"Map-style datasets:\",train_dataset,\"de longeure\",len(train_dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Map-style datasets: <dataset.TweetDataset object at 0x7f09a61f25f8> de longeure 21984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRK5sknouPHy"
      },
      "source": [
        "* En principe, le DataLoader fonctionne avec l'objet Dataset (objet itÃ©rable). Dans notre cas, cet objet est TweetDataset. Pour utiliser le DataLoader, nous devons faire entrer nos donnÃ©es dans l'enveloppe du Dataset. Pour ce faire, il faut implÃ©menter deux mÃ©thodes : __getitem__ et __len__. La __getitem__ prend un index et renvoie un objet dictionnaire de `{'ids', 'mask', 'token_type_ids', 'start_labels', 'end_labels', 'orig_start', 'orig_end', 'orig_tweet', 'orig_selected', 'sentiment', 'offsets', 'targets_select'}`. Ids. Le __len__ est juste le __len habituel qui renvoie la taille du tweet numpy.ndarray ces deux mÃ©thodes sont implÃ©mentÃ©es dans le fichier **`dataset.py`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdHtGdc8aX8l"
      },
      "source": [
        "## batch_size (Taille du lot): \n",
        "## Cette option permet de dÃ©terminer le nombre de documents traitÃ©s dans chaque lot (32).\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.TRAIN_BATCH_SIZE,\n",
        "    num_workers=4,  ## Ils ont utilisÃ© le multiprocessing pour charger les donnÃ©es et les injecter au GPU.\n",
        "    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "ed2e8946b1004d4ca98dfadfa33115f5",
            "983766538d1c4e94b5c1599a68ec02d5",
            "50c37752036240f098ea6979b4f01416",
            "1bcc8d683c504de2a1d2ac53c49b84a0",
            "1b0d52f94b944e74b65b3bbd854e58ee",
            "8df86989d6fe4dcdac94e453f03ebc3e",
            "d1ad2c4487d84b8c94a19ce2e53a393a",
            "41678fc6278e4acc9446a04a5d936445",
            "23007c4d13ba48839736aaa552a33750",
            "95f23dc7fd694a1aaf802da9e4f697aa",
            "7faab71086174139b707fb5332ea2906",
            "9cf511a065854bfeb286a3ab5d2be7ab",
            "997ea70e664b4d2aa193ba8d6f3d5569",
            "ced557f1d8244f6abaabf8e2011dab49",
            "cac3e239cfa34eb3b7d6824b92049515",
            "342d70f33ebb469c9f18a9f3cfefb843"
          ]
        },
        "id": "_tS4Y1MxakhE",
        "outputId": "eaec372d-cecd-461f-e3da-a4c902ce915d"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "## Instantiation du model da ce cas c'est le Roberta Base(786 embedding dim) \n",
        "## comme il est configurÃ© dans le fichier config.py 'deepset/roberta-base-squad2', \n",
        "## ce modÃ¨le est prÃ©-entrainÃ© su la base de donnÃ©es Sqaud2\n",
        "model_config = transformers.RobertaConfig.from_pretrained(config.MODEL_CONFIG)\n",
        "## Activez le retour des statuts cachÃ©s de toutes les couches\n",
        "model_config.output_hidden_states = True\n",
        "## \n",
        "model = models.TweetModel(conf=model_config)\n",
        "model = model.to(device)\n",
        "print(\"------------------> here\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed2e8946b1004d4ca98dfadfa33115f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23007c4d13ba48839736aaa552a33750",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=496313727.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------------------> here\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QtDUC2J76qo"
      },
      "source": [
        "num_train_steps = int(len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_5F6jmA7_Ij",
        "outputId": "4aff0f9f-e324-4f20-ad85-3c56c24a4f62"
      },
      "source": [
        "print(\"Nombre ditÃ©ration pour lentrainement %s = la longeur de la base \\nd'entrainemet %s  divisÃ© par la taille du batch %s multupliÃ© \\npar le nombre depoches %s\"%(num_train_steps,len(df_train),config.TRAIN_BATCH_SIZE,config.EPOCHS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre ditÃ©ration pour lentrainement 2748 = la longeur de la base \n",
            "d'entrainemet 21984  divisÃ© par la taille du batch 32 multupliÃ© \n",
            "par le nombre depoches 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzG9ibn79Clb"
      },
      "source": [
        "## RÃ©cupÃ©rer les paramÃ¨tres (weights) de l'optimizer\n",
        "param_optimizer = list(model.named_parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7qd60f59EDw"
      },
      "source": [
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "## Initialistion des parametres de loptemizer puis on les rÃ©cupÃ¨re du modÃ¨le prÃ©-entrainÃ© sur SQuad2\n",
        "optimizer_parameters = [\n",
        "                        {'params': [p for n, p in param_optimizer\n",
        "                                    if not any(nd in n for nd in no_decay)],\n",
        "                         'weight_decay': config.WEIGHT_DECAY},\n",
        "                        {'params': [p for n, p in param_optimizer\n",
        "                                    if any(nd in n for nd in no_decay)],\n",
        "                         'weight_decay': 0.0}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbFG9itN-Hhx",
        "outputId": "8e27b890-1278-45a9-f147-07a85322fff8"
      },
      "source": [
        "## l'optimiseur en fonction du temps \n",
        "base_opt = transformers.AdamW(optimizer_parameters,\n",
        "                              lr=config.LEARNING_RATE)\n",
        "base_opt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdamW (\n",
              "Parameter Group 0\n",
              "    betas: (0.9, 0.999)\n",
              "    correct_bias: True\n",
              "    eps: 1e-06\n",
              "    lr: 4e-05\n",
              "    weight_decay: 0.001\n",
              "\n",
              "Parameter Group 1\n",
              "    betas: (0.9, 0.999)\n",
              "    correct_bias: True\n",
              "    eps: 1e-06\n",
              "    lr: 4e-05\n",
              "    weight_decay: 0.0\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS6v-r94aqRO"
      },
      "source": [
        "## SWA : la technique SWA (Stochastic Weight Averaging) est prÃ©senter au dessus avant le dÃ©boguage\n",
        "optimizer = torchcontrib.optim.SWA(\n",
        "    base_opt,\n",
        "    swa_start=int(num_train_steps * config.SWA_RATIO),\n",
        "    swa_freq=config.SWA_FREQ,\n",
        "    swa_lr=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eGaNRj3ayOR"
      },
      "source": [
        "## Scheduler permet de contrÃ´ler automatiquement les taux d'apprentissage\n",
        "scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=int(num_train_steps * config.WARMUP_RATIO),\n",
        "    num_training_steps=num_train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gdUwXcXa1Z_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cb7c2e-6b14-4207-fff9-8c5992f2e8d2"
      },
      "source": [
        "engine.train_fn(train_data_loader, model, optimizer,device, scheduler=scheduler)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.59it/s, loss=0.0219]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rQoVdMKESFy"
      },
      "source": [
        "Deboguage de la mÃ©thode **`train_fn`** du fichier **`engine.py`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF0L-7hoB2_b"
      },
      "source": [
        "import tqdm\n",
        "tk0 = tqdm.tqdm(train_data_loader, total=len(train_data_loader))\n",
        "for bi, d in enumerate(tk0):\n",
        "  print(\"-------------------------------------------------------------\")\n",
        "  print(bi)\n",
        "  print(\"-------------------------------------------------------------\")\n",
        "  print(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDT_UCrGF4dn"
      },
      "source": [
        "##Le code initial du fichier **`train.py`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1023bec17f3048f2994587ab2ca923ff",
            "4f836dfd3d614d37a6e12828b9e26dea",
            "0288fee9c3674c198d5e21621aac5273",
            "56eabcc0b14d4fa6a0b5b2323b3a27a5",
            "9c97ceae839b48029d9f89ed8021d1a2",
            "d0732c192a784c53b86a68f3a16254a6",
            "556a4510c3234b38a87c3743b8df9c97",
            "ec4bd0f01be341e88fc41673825fbaca",
            "2d6a2ea3e1454d28bd5a9760e19a4ca7",
            "6cad7320919248cab53cba7a3eb47225",
            "18287140c5324a7e85b01460e5e889f5",
            "fb4870326d1545dcaab261730965bc99",
            "11cd33748ed9445c921d533c922a2128",
            "4ae80b3c967142b1b773b080ed310264",
            "31bf737378c04156a4ced60a3b781572",
            "8344b11a1c42484883bb312ebfa677c6"
          ]
        },
        "id": "xS47DeGUGyt1",
        "outputId": "1bcfe209-c4d3-425e-a5a4-811fac7f4167"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import transformers\n",
        "import torch\n",
        "import torchcontrib\n",
        "\n",
        "import config\n",
        "import dataset\n",
        "import models\n",
        "import engine\n",
        "import utils\n",
        "\n",
        "## Ce code permet de lancÃ© l'entrainement sur les 5 folds \n",
        "def run(fold):\n",
        "   \n",
        "    dfx = pd.read_csv(config.TRAINING_FILE)\n",
        "    df_train = dfx[dfx.kfold != fold].reset_index(drop=True)\n",
        "    df_valid = dfx[dfx.kfold == fold].reset_index(drop=True)\n",
        "\n",
        "    ## CrÃ©er un Map-style datasets sur les donnÃ©es d'entrainement\n",
        "    train_dataset = dataset.TweetDataset(\n",
        "        tweets=df_train.text.values,\n",
        "        sentiments=df_train.sentiment.values,\n",
        "        selected_texts=df_train.selected_text.values)\n",
        "    \n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TRAIN_BATCH_SIZE,\n",
        "        num_workers=4,  ## Ils ont utilisÃ© le multiprocessing pour charger les donnÃ©es et les injecter au GPU.\n",
        "        shuffle=True)\n",
        "    \n",
        "    ## CrÃ©er un Map-style datasets sur les donnÃ©es d'entrainement \n",
        "    valid_dataset = dataset.TweetDataset(\n",
        "        tweets=df_valid.text.values,\n",
        "        sentiments=df_valid.sentiment.values,\n",
        "        selected_texts=df_valid.selected_text.values)\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        num_workers=4,  ## Ils ont utilisÃ© le multiprocessing pour charger les donnÃ©es et les injecter au GPU.\n",
        "        shuffle=False)\n",
        "\n",
        "    device = torch.device('cuda')\n",
        "    model_config = transformers.RobertaConfig.from_pretrained(\n",
        "        config.MODEL_CONFIG)\n",
        "    model_config.output_hidden_states = True\n",
        "    model = models.TweetModel(conf=model_config)\n",
        "    model = model.to(device)\n",
        "    print(\"------------------> here\")\n",
        "    \n",
        "    ## Nombre d'iteration c'est le nombre des donnÃ©es d'entrÃ© (tweets) divisÃ© par\n",
        "    ## la taille du batch dans le fichier config.py\n",
        "    num_train_steps = int(\n",
        "        len(df_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n",
        "    ## RÃ©cupÃ©rer les paramÃ¨tres (les poids) de l'optimizer\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "\n",
        "    ## puisqu'il est recommandÃ© d'utiliser cet optimiseur pour le fine tuning\n",
        "    ## (modification sur l'architecture), puisque c'est ainsi que le modÃ¨le a \n",
        "    ## Ã©tÃ© entraÃ®nÃ© et de conserver les mÃªmes comportements que ceux mentionnÃ©s \n",
        "    ## sur le repo git de BERT (https://github.com/google-research/bert/blob/master/optimization.py#L65)\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    optimizer_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer\n",
        "                    if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': config.WEIGHT_DECAY},\n",
        "        {'params': [p for n, p in param_optimizer\n",
        "                    if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay': 0.0}]\n",
        "    ## AdamW: un optimiseur adaptatif avec utilisation d'une Ã©chelle de taux\n",
        "    ## d'apprentissage pour moduler l'Ã©volution du taux d'apprentissage de\n",
        "    ## l'optimiseur en fonction du temps \n",
        "    base_opt = transformers.AdamW(optimizer_parameters,\n",
        "                                  lr=config.LEARNING_RATE)\n",
        "    ## SWA : la technique SWA (Stochastic Weight Averaging) est prÃ©senter au dessus de cette cellule\n",
        "    optimizer = torchcontrib.optim.SWA(\n",
        "        base_opt,\n",
        "        swa_start=int(num_train_steps * config.SWA_RATIO),\n",
        "        swa_freq=config.SWA_FREQ,\n",
        "        swa_lr=None)\n",
        "    ## Scheduler permet de contrÃ´ler automatiquement les taux d'apprentissage\n",
        "    scheduler = transformers.get_linear_schedule_with_warmup(\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=int(num_train_steps * config.WARMUP_RATIO),\n",
        "        num_training_steps=num_train_steps)\n",
        "\n",
        "    print(f'Training is starting for fold={fold}')\n",
        "    ## chaque process (l'entrainement, l'Ã©valuation et la prÃ©diction) sont fait sur 5 folds\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        ## Lancer l'entrainement\n",
        "        engine.train_fn(train_data_loader, model, optimizer,device, scheduler=scheduler)\n",
        "        ## Lancer l'Ã©valuation\n",
        "        jaccard = engine.eval_fn(valid_data_loader, model, device)\n",
        "\n",
        "    if config.USE_SWA:\n",
        "        ## Utiliser l'optimiseur SWA\n",
        "        ## Le SWA effectue une moyenne Ã©gale des poids traversÃ©s par le SGD\n",
        "        optimizer.swap_swa_sgd()\n",
        "    ## SauvegardÃ© le modÃ¨le aprÃ¨s l'entraÃ®nement et l'valuation de chaque fold model_0 ==> fold 0,...\n",
        "    torch.save(model.state_dict(),\n",
        "               f'{config.MODEL_SAVE_PATH}/model_{fold}.bin')\n",
        "    ## Renvoie le rÃ©sultat de la mÃ©trique utilisÃ©e qui est le score jaccard modifiÃ©\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    utils.seed_everything(seed=config.SEED)\n",
        "\n",
        "    fold_scores = []\n",
        "    for i in range(config.N_FOLDS):\n",
        "        fold_score = run(i)\n",
        "        fold_scores.append(fold_score)\n",
        "\n",
        "    print('\\nScores without SWA:')\n",
        "    for i in range(config.N_FOLDS):\n",
        "        print(f'Fold={i}, Jaccard = {fold_scores[i]}')\n",
        "    print(f'Mean = {np.mean(fold_scores)}')\n",
        "    print(f'Std = {np.std(fold_scores)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1023bec17f3048f2994587ab2ca923ff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=571.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d6a2ea3e1454d28bd5a9760e19a4ca7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=496313727.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:04<00:00,  1.62it/s, loss=0.0218]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.703, loss=0.01]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7029905612369929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0104]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.712, loss=0.00929]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7118255485009135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00902]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.717, loss=0.00939]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7170824580463284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00808]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.89it/s, jaccard=0.716, loss=0.00943]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7163026420895469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0196]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.696, loss=0.0099]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.6963974280475891\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.59it/s, loss=0.01]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.705, loss=0.00921]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7054961819176117\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0088]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.711, loss=0.00945]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7110974016990879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.00799]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.711, loss=0.00939]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7108215431021135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0199]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.95it/s, jaccard=0.701, loss=0.0105]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7007900525880214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.59it/s, loss=0.0103]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.707, loss=0.00936]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7070440963345973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00895]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.713, loss=0.00921]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7134881141772793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00821]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.716, loss=0.00934]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7158955035127735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0211]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.694, loss=0.0106]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.6944610752763127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0102]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.709, loss=0.00972]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7094754330307022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00889]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.717, loss=0.00957]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7172411822420536\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.00803]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.91it/s, jaccard=0.717, loss=0.00964]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7166221978997807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "------------------> here\n",
            "Training is starting for fold=4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2398: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.0203]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:35<00:00,  4.90it/s, jaccard=0.695, loss=0.0104]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.694875414018416\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0108]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.93it/s, jaccard=0.703, loss=0.0103]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.70296628740658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:13<00:00,  1.58it/s, loss=0.0094]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.92it/s, jaccard=0.707, loss=0.00943]\n",
            "  0%|          | 0/687 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7067339098954668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 687/687 [07:14<00:00,  1.58it/s, loss=0.00862]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 172/172 [00:34<00:00,  4.94it/s, jaccard=0.711, loss=0.00943]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Jaccard = 0.7109265704332721\n",
            "\n",
            "Scores without SWA:\n",
            "Fold=0, Jaccard = 0.7163026420895469\n",
            "Fold=1, Jaccard = 0.7108215431021135\n",
            "Fold=2, Jaccard = 0.7158955035127735\n",
            "Fold=3, Jaccard = 0.7166221978997807\n",
            "Fold=4, Jaccard = 0.7109265704332721\n",
            "Mean = 0.7141136914074974\n",
            "Std = 0.002655369837057321\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qYuhGoYmRuQ"
      },
      "source": [
        "# create_folds.py \n",
        "Voici le code qui correspond au fichier create_folds.py sous leur dÃ©pÃ´t sur [github](https://github.com/heartkilla/kaggle_tweet/blob/master/src/create_folds.py).\n",
        "\n",
        "* Ce code est utilisÃ© pour Ã©chantillonner les donnÃ©es sur 5 plis (de 0 Ã  4) Ã  chaque fois qu'un pli sera utilisÃ© comme donnÃ©e de validation et les 4 autres plis seront utilisÃ©s comme donnÃ©es d'entrainement.\n",
        "* On crÃ©e une nouvelle colonne **`kfol`** ajoutÃ©e Ã  l'ensemble de donnÃ©es **`train.csv`** contenant le fold correspondant.\n",
        "* Tous les plis contiennent **`50898`** ligne de donnÃ©es."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jGYheYomREa"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import model_selection\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"./data/train.csv\")\n",
        "    df = df.dropna().reset_index(drop=True)\n",
        "    df[\"kfold\"] = -1\n",
        "\n",
        "    df = df.sample(frac=1, random_state=50898).reset_index(drop=True)\n",
        "\n",
        "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "\n",
        "    for fold, (trn_, val_) in enumerate(kf.split(X=df, y=df.sentiment.values)):\n",
        "        print(len(trn_), len(val_))\n",
        "        df.loc[val_, 'kfold'] = fold\n",
        "\n",
        "    df.to_csv(\"./data/train_folds.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}